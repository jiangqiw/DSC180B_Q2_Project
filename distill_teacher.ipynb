{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bREGbUT_Y8F"
      },
      "source": [
        "### Import required packages and limit GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcqwxR8_Y8I",
        "outputId": "26140e84-9279-479e-cc80-7c9a0b1a8fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/KD')\n",
        "# Import the module\n",
        "import networks\n",
        "import utils\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-oA_QyhO4a8",
        "outputId": "29dd6fc3-2f22-4515-e537-40850024271f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n73sKlgl_Y8K"
      },
      "outputs": [],
      "source": [
        "use_gpu = False    # set use_gpu to True if system has gpu\n",
        "gpu_id = 0        # id of gpu to be used\n",
        "cpu_device = torch.device('cpu')\n",
        "# fast_device is where computation (training, inference) happens\n",
        "fast_device = torch.device('cpu')\n",
        "if use_gpu:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
        "    fast_device = torch.device('cuda:' + str(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAfPa7mw_Y8L"
      },
      "outputs": [],
      "source": [
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    if use_gpu:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0sxuxkJbUEI"
      },
      "outputs": [],
      "source": [
        "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
        "checkpoints_path_student = 'checkpoints_student/'\n",
        "if not os.path.exists(checkpoints_path_student):\n",
        "    os.makedirs(checkpoints_path_student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCz4Pup_Y8M"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8vAtxV_Y8N",
        "outputId": "797e7d9e-fa75-47c3-977a-22b6ef78b28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set up transformations for CIFAR-10\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
        "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "# Split the training dataset into training and validation\n",
        "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
        "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jywk1DS_Y8O"
      },
      "source": [
        "### Train teacher network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wDSA64C_Y8R"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "print_every = 100    # Interval size for which to print statistics of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEnJ1A1_Y8T",
        "scrolled": true,
        "outputId": "3d5687b1-f814-41bf-9be6-8bd6d3c86577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100/  391] train loss: 0.882 train accuracy: 0.711\n",
            "[1,   200/  391] train loss: 0.764 train accuracy: 0.711\n",
            "[1,   300/  391] train loss: 0.610 train accuracy: 0.805\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'checkpoints_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ef9db6c900bb>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                         fast_device=fast_device)\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoints_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparamToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_final.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     torch.save({'results' : results[hparam_tuple],\n\u001b[1;32m     35\u001b[0m                 \u001b[0;34m'model_state_dict'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mteacher_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpoints_path' is not defined"
          ]
        }
      ],
      "source": [
        "# Hyperparamters can be tuned by setting required range below\n",
        "# learning_rates = list(np.logspace(-4, -2, 3))\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]    # learning rate decays at every epoch\n",
        "# weight_decays = [0.0] + list(np.logspace(-5, -1, 5))\n",
        "weight_decays = [1e-5]           # regularization weight\n",
        "momentums = [0.9]\n",
        "# dropout_probabilities = [(0.2, 0.5), (0.0, 0.0)]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays,\n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['dropout_input'] = hparam_tuple[0][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[0][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[1]\n",
        "    hparam['lr_decay'] = hparam_tuple[2]\n",
        "    hparam['momentum'] = hparam_tuple[3]\n",
        "    hparam['lr'] = hparam_tuple[4]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results = {}\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    teacher_net = networks.TeacherNetworkVGG()\n",
        "    teacher_net = teacher_net.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "    results[hparam_tuple] = utils.trainTeacherOnHparam(teacher_net, hparam, num_epochs,\n",
        "                                                        train_val_loader, None,\n",
        "                                                        print_every=print_every,\n",
        "                                                        fast_device=fast_device)\n",
        "    save_path = checkpoints_path + utils.hparamToString(hparam) + '_final.tar'\n",
        "    torch.save({'results' : results[hparam_tuple],\n",
        "                'model_state_dict' : teacher_net.state_dict(),\n",
        "                'epoch' : num_epochs}, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ1FDGdf_Y8V",
        "outputId": "3a93e599-0022-49e4-bc77-fe4ff3c03e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.8654\n"
          ]
        }
      ],
      "source": [
        "# Calculate test accuracy\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayk6sDh7UXz"
      },
      "source": [
        "Student Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlvtw4Xkxhoh"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30\n",
        "print_every = 100    #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkNCEsPpk0nd",
        "outputId": "87add0a6-13a8-459c-8539-6a22d3db24de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.03125"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAXvRE-7a9bC",
        "outputId": "86382da5-7836-4b1f-e4e2-a1dd2ec8f8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.03125\n",
            "3.1168690456815966\n",
            "[1,   100/  391] train loss: 7.448 train accuracy: 0.578\n",
            "[1,   200/  391] train loss: 4.315 train accuracy: 0.672\n",
            "[1,   300/  391] train loss: 5.264 train accuracy: 0.602\n",
            "[2,   100/  391] train loss: 4.616 train accuracy: 0.727\n",
            "[2,   200/  391] train loss: 6.824 train accuracy: 0.531\n",
            "[2,   300/  391] train loss: 5.004 train accuracy: 0.648\n",
            "[3,   100/  391] train loss: 3.450 train accuracy: 0.805\n",
            "[3,   200/  391] train loss: 3.186 train accuracy: 0.758\n",
            "[3,   300/  391] train loss: 3.757 train accuracy: 0.734\n",
            "[4,   100/  391] train loss: 2.790 train accuracy: 0.805\n",
            "[4,   200/  391] train loss: 3.134 train accuracy: 0.805\n",
            "[4,   300/  391] train loss: 2.854 train accuracy: 0.797\n",
            "[5,   100/  391] train loss: 2.686 train accuracy: 0.773\n",
            "[5,   200/  391] train loss: 2.679 train accuracy: 0.805\n",
            "[5,   300/  391] train loss: 2.345 train accuracy: 0.844\n",
            "[6,   100/  391] train loss: 2.436 train accuracy: 0.820\n",
            "[6,   200/  391] train loss: 2.532 train accuracy: 0.805\n",
            "[6,   300/  391] train loss: 2.527 train accuracy: 0.812\n",
            "[7,   100/  391] train loss: 2.487 train accuracy: 0.852\n",
            "[7,   200/  391] train loss: 2.309 train accuracy: 0.828\n",
            "[7,   300/  391] train loss: 2.072 train accuracy: 0.828\n",
            "[8,   100/  391] train loss: 1.932 train accuracy: 0.859\n",
            "[8,   200/  391] train loss: 1.634 train accuracy: 0.836\n",
            "[8,   300/  391] train loss: 2.059 train accuracy: 0.844\n",
            "[9,   100/  391] train loss: 1.533 train accuracy: 0.922\n",
            "[9,   200/  391] train loss: 1.933 train accuracy: 0.898\n",
            "[9,   300/  391] train loss: 1.940 train accuracy: 0.875\n",
            "[10,   100/  391] train loss: 1.516 train accuracy: 0.883\n",
            "[10,   200/  391] train loss: 1.623 train accuracy: 0.891\n",
            "[10,   300/  391] train loss: 1.746 train accuracy: 0.875\n",
            "[11,   100/  391] train loss: 1.318 train accuracy: 0.883\n",
            "[11,   200/  391] train loss: 1.317 train accuracy: 0.938\n",
            "[11,   300/  391] train loss: 1.543 train accuracy: 0.891\n",
            "[12,   100/  391] train loss: 1.488 train accuracy: 0.898\n",
            "[12,   200/  391] train loss: 1.495 train accuracy: 0.867\n",
            "[12,   300/  391] train loss: 1.406 train accuracy: 0.914\n",
            "[13,   100/  391] train loss: 1.535 train accuracy: 0.906\n",
            "[13,   200/  391] train loss: 1.359 train accuracy: 0.875\n",
            "[13,   300/  391] train loss: 1.777 train accuracy: 0.867\n",
            "[14,   100/  391] train loss: 1.457 train accuracy: 0.898\n",
            "[14,   200/  391] train loss: 1.194 train accuracy: 0.914\n",
            "[14,   300/  391] train loss: 1.244 train accuracy: 0.906\n",
            "[15,   100/  391] train loss: 1.039 train accuracy: 0.914\n",
            "[15,   200/  391] train loss: 1.342 train accuracy: 0.898\n",
            "[15,   300/  391] train loss: 1.154 train accuracy: 0.938\n",
            "[16,   100/  391] train loss: 0.917 train accuracy: 0.977\n",
            "[16,   200/  391] train loss: 1.341 train accuracy: 0.891\n",
            "[16,   300/  391] train loss: 1.187 train accuracy: 0.930\n",
            "[17,   100/  391] train loss: 2.047 train accuracy: 0.836\n",
            "[17,   200/  391] train loss: 1.186 train accuracy: 0.922\n",
            "[17,   300/  391] train loss: 1.203 train accuracy: 0.922\n",
            "[18,   100/  391] train loss: 2.009 train accuracy: 0.844\n",
            "[18,   200/  391] train loss: 1.859 train accuracy: 0.867\n",
            "[18,   300/  391] train loss: 1.382 train accuracy: 0.922\n",
            "[19,   100/  391] train loss: 1.515 train accuracy: 0.891\n",
            "[19,   200/  391] train loss: 5.002 train accuracy: 0.703\n",
            "[19,   300/  391] train loss: 3.428 train accuracy: 0.758\n",
            "[20,   100/  391] train loss: 2.211 train accuracy: 0.836\n",
            "[20,   200/  391] train loss: 2.132 train accuracy: 0.867\n",
            "[20,   300/  391] train loss: 1.881 train accuracy: 0.859\n",
            "[21,   100/  391] train loss: 1.860 train accuracy: 0.852\n",
            "[21,   200/  391] train loss: 1.511 train accuracy: 0.891\n",
            "[21,   300/  391] train loss: 1.810 train accuracy: 0.875\n",
            "[22,   100/  391] train loss: 1.657 train accuracy: 0.883\n",
            "[22,   200/  391] train loss: 1.895 train accuracy: 0.820\n",
            "[22,   300/  391] train loss: 1.589 train accuracy: 0.875\n",
            "[23,   100/  391] train loss: 1.313 train accuracy: 0.906\n",
            "[23,   200/  391] train loss: 1.382 train accuracy: 0.898\n",
            "[23,   300/  391] train loss: 1.457 train accuracy: 0.930\n",
            "[24,   100/  391] train loss: 1.167 train accuracy: 0.914\n",
            "[24,   200/  391] train loss: 1.629 train accuracy: 0.891\n",
            "[24,   300/  391] train loss: 1.477 train accuracy: 0.852\n",
            "[25,   100/  391] train loss: 0.967 train accuracy: 0.930\n",
            "[25,   200/  391] train loss: 1.143 train accuracy: 0.898\n",
            "[25,   300/  391] train loss: 1.110 train accuracy: 0.930\n",
            "[26,   100/  391] train loss: 1.380 train accuracy: 0.898\n",
            "[26,   200/  391] train loss: 1.454 train accuracy: 0.891\n",
            "[26,   300/  391] train loss: 1.314 train accuracy: 0.906\n",
            "[27,   100/  391] train loss: 1.073 train accuracy: 0.945\n",
            "[27,   200/  391] train loss: 1.158 train accuracy: 0.922\n",
            "[27,   300/  391] train loss: 1.158 train accuracy: 0.961\n",
            "[28,   100/  391] train loss: 1.176 train accuracy: 0.906\n",
            "[28,   200/  391] train loss: 0.825 train accuracy: 0.953\n",
            "[28,   300/  391] train loss: 1.083 train accuracy: 0.898\n",
            "[29,   100/  391] train loss: 0.953 train accuracy: 0.945\n",
            "[29,   200/  391] train loss: 1.347 train accuracy: 0.922\n",
            "[29,   300/  391] train loss: 1.069 train accuracy: 0.938\n",
            "[30,   100/  391] train loss: 0.914 train accuracy: 0.938\n",
            "[30,   200/  391] train loss: 1.070 train accuracy: 0.930\n",
            "[30,   300/  391] train loss: 1.008 train accuracy: 0.953\n",
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.0625\n",
            "6.233727775756874\n",
            "[1,   100/  391] train loss: 5.923 train accuracy: 0.625\n",
            "[1,   200/  391] train loss: 5.068 train accuracy: 0.625\n",
            "[1,   300/  391] train loss: 9.103 train accuracy: 0.359\n",
            "[2,   100/  391] train loss: 5.153 train accuracy: 0.703\n",
            "[2,   200/  391] train loss: 4.733 train accuracy: 0.648\n",
            "[2,   300/  391] train loss: 3.749 train accuracy: 0.773\n",
            "[3,   100/  391] train loss: 3.500 train accuracy: 0.789\n",
            "[3,   200/  391] train loss: 2.871 train accuracy: 0.773\n",
            "[3,   300/  391] train loss: 3.322 train accuracy: 0.789\n",
            "[4,   100/  391] train loss: 3.010 train accuracy: 0.805\n",
            "[4,   200/  391] train loss: 3.085 train accuracy: 0.773\n",
            "[4,   300/  391] train loss: 2.725 train accuracy: 0.812\n",
            "[5,   100/  391] train loss: 2.619 train accuracy: 0.742\n",
            "[5,   200/  391] train loss: 2.790 train accuracy: 0.805\n",
            "[5,   300/  391] train loss: 2.285 train accuracy: 0.820\n",
            "[6,   100/  391] train loss: 2.710 train accuracy: 0.820\n",
            "[6,   200/  391] train loss: 3.119 train accuracy: 0.766\n",
            "[6,   300/  391] train loss: 5.141 train accuracy: 0.664\n",
            "[7,   100/  391] train loss: 3.760 train accuracy: 0.758\n",
            "[7,   200/  391] train loss: 3.206 train accuracy: 0.734\n",
            "[7,   300/  391] train loss: 2.924 train accuracy: 0.797\n",
            "[8,   100/  391] train loss: 2.651 train accuracy: 0.820\n",
            "[8,   200/  391] train loss: 2.151 train accuracy: 0.812\n",
            "[8,   300/  391] train loss: 2.598 train accuracy: 0.820\n",
            "[9,   100/  391] train loss: 2.100 train accuracy: 0.867\n",
            "[9,   200/  391] train loss: 2.228 train accuracy: 0.844\n",
            "[9,   300/  391] train loss: 2.340 train accuracy: 0.820\n",
            "[10,   100/  391] train loss: 1.970 train accuracy: 0.859\n",
            "[10,   200/  391] train loss: 1.687 train accuracy: 0.875\n",
            "[10,   300/  391] train loss: 2.006 train accuracy: 0.898\n",
            "[11,   100/  391] train loss: 1.557 train accuracy: 0.891\n",
            "[11,   200/  391] train loss: 1.568 train accuracy: 0.891\n",
            "[11,   300/  391] train loss: 1.687 train accuracy: 0.891\n",
            "[12,   100/  391] train loss: 1.693 train accuracy: 0.922\n",
            "[12,   200/  391] train loss: 1.843 train accuracy: 0.836\n",
            "[12,   300/  391] train loss: 1.786 train accuracy: 0.852\n",
            "[13,   100/  391] train loss: 1.706 train accuracy: 0.859\n",
            "[13,   200/  391] train loss: 1.569 train accuracy: 0.898\n",
            "[13,   300/  391] train loss: 1.819 train accuracy: 0.867\n",
            "[14,   100/  391] train loss: 1.613 train accuracy: 0.898\n",
            "[14,   200/  391] train loss: 1.762 train accuracy: 0.875\n",
            "[14,   300/  391] train loss: 1.382 train accuracy: 0.883\n",
            "[15,   100/  391] train loss: 1.230 train accuracy: 0.875\n",
            "[15,   200/  391] train loss: 1.515 train accuracy: 0.898\n",
            "[15,   300/  391] train loss: 1.407 train accuracy: 0.898\n",
            "[16,   100/  391] train loss: 1.159 train accuracy: 0.945\n",
            "[16,   200/  391] train loss: 1.346 train accuracy: 0.898\n",
            "[16,   300/  391] train loss: 1.267 train accuracy: 0.922\n",
            "[17,   100/  391] train loss: 1.230 train accuracy: 0.883\n",
            "[17,   200/  391] train loss: 1.177 train accuracy: 0.906\n",
            "[17,   300/  391] train loss: 1.088 train accuracy: 0.914\n",
            "[18,   100/  391] train loss: 0.961 train accuracy: 0.938\n",
            "[18,   200/  391] train loss: 1.337 train accuracy: 0.906\n",
            "[18,   300/  391] train loss: 1.426 train accuracy: 0.883\n",
            "[19,   100/  391] train loss: 1.056 train accuracy: 0.930\n",
            "[19,   200/  391] train loss: 1.037 train accuracy: 0.938\n",
            "[19,   300/  391] train loss: 1.087 train accuracy: 0.938\n",
            "[20,   100/  391] train loss: 0.980 train accuracy: 0.914\n",
            "[20,   200/  391] train loss: 1.143 train accuracy: 0.914\n",
            "[20,   300/  391] train loss: 1.078 train accuracy: 0.898\n",
            "[21,   100/  391] train loss: 0.913 train accuracy: 0.953\n",
            "[21,   200/  391] train loss: 0.919 train accuracy: 0.922\n",
            "[21,   300/  391] train loss: 2.694 train accuracy: 0.820\n",
            "[22,   100/  391] train loss: 1.178 train accuracy: 0.938\n",
            "[22,   200/  391] train loss: 1.175 train accuracy: 0.922\n",
            "[22,   300/  391] train loss: 1.160 train accuracy: 0.914\n",
            "[23,   100/  391] train loss: 0.767 train accuracy: 0.977\n",
            "[23,   200/  391] train loss: 0.914 train accuracy: 0.930\n",
            "[23,   300/  391] train loss: 1.133 train accuracy: 0.930\n",
            "[24,   100/  391] train loss: 0.923 train accuracy: 0.945\n",
            "[24,   200/  391] train loss: 1.105 train accuracy: 0.922\n",
            "[24,   300/  391] train loss: 1.005 train accuracy: 0.914\n",
            "[25,   100/  391] train loss: 0.707 train accuracy: 0.984\n",
            "[25,   200/  391] train loss: 0.832 train accuracy: 0.945\n",
            "[25,   300/  391] train loss: 0.884 train accuracy: 0.930\n",
            "[26,   100/  391] train loss: 0.935 train accuracy: 0.930\n",
            "[26,   200/  391] train loss: 0.675 train accuracy: 0.977\n",
            "[26,   300/  391] train loss: 0.873 train accuracy: 0.945\n",
            "[27,   100/  391] train loss: 0.750 train accuracy: 0.953\n",
            "[27,   200/  391] train loss: 0.877 train accuracy: 0.930\n",
            "[27,   300/  391] train loss: 0.865 train accuracy: 0.961\n",
            "[28,   100/  391] train loss: 0.741 train accuracy: 0.961\n",
            "[28,   200/  391] train loss: 0.671 train accuracy: 0.961\n",
            "[28,   300/  391] train loss: 0.872 train accuracy: 0.922\n",
            "[29,   100/  391] train loss: 0.752 train accuracy: 0.961\n",
            "[29,   200/  391] train loss: 1.026 train accuracy: 0.914\n",
            "[29,   300/  391] train loss: 0.713 train accuracy: 0.961\n",
            "[30,   100/  391] train loss: 0.688 train accuracy: 0.969\n",
            "[30,   200/  391] train loss: 0.818 train accuracy: 0.969\n",
            "[30,   300/  391] train loss: 0.739 train accuracy: 0.969\n",
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.09375\n",
            "9.350591663635312\n",
            "[1,   100/  391] train loss: 6.418 train accuracy: 0.586\n",
            "[1,   200/  391] train loss: 4.240 train accuracy: 0.727\n",
            "[1,   300/  391] train loss: 3.954 train accuracy: 0.711\n",
            "[2,   100/  391] train loss: 2.870 train accuracy: 0.836\n",
            "[2,   200/  391] train loss: 2.329 train accuracy: 0.820\n",
            "[2,   300/  391] train loss: 2.720 train accuracy: 0.812\n",
            "[3,   100/  391] train loss: 2.453 train accuracy: 0.820\n",
            "[3,   200/  391] train loss: 2.079 train accuracy: 0.836\n",
            "[3,   300/  391] train loss: 2.439 train accuracy: 0.820\n",
            "[4,   100/  391] train loss: 1.783 train accuracy: 0.891\n",
            "[4,   200/  391] train loss: 2.052 train accuracy: 0.859\n",
            "[4,   300/  391] train loss: 1.696 train accuracy: 0.844\n",
            "[5,   100/  391] train loss: 1.660 train accuracy: 0.828\n",
            "[5,   200/  391] train loss: 1.882 train accuracy: 0.867\n",
            "[5,   300/  391] train loss: 1.618 train accuracy: 0.898\n",
            "[6,   100/  391] train loss: 1.418 train accuracy: 0.898\n",
            "[6,   200/  391] train loss: 1.795 train accuracy: 0.859\n",
            "[6,   300/  391] train loss: 1.645 train accuracy: 0.875\n",
            "[7,   100/  391] train loss: 1.602 train accuracy: 0.891\n",
            "[7,   200/  391] train loss: 1.415 train accuracy: 0.852\n",
            "[7,   300/  391] train loss: 1.515 train accuracy: 0.867\n",
            "[8,   100/  391] train loss: 1.208 train accuracy: 0.914\n",
            "[8,   200/  391] train loss: 0.955 train accuracy: 0.938\n",
            "[8,   300/  391] train loss: 1.329 train accuracy: 0.898\n",
            "[9,   100/  391] train loss: 1.063 train accuracy: 0.938\n",
            "[9,   200/  391] train loss: 1.140 train accuracy: 0.938\n",
            "[9,   300/  391] train loss: 1.258 train accuracy: 0.875\n",
            "[10,   100/  391] train loss: 1.084 train accuracy: 0.922\n",
            "[10,   200/  391] train loss: 0.961 train accuracy: 0.930\n",
            "[10,   300/  391] train loss: 1.069 train accuracy: 0.953\n",
            "[11,   100/  391] train loss: 0.725 train accuracy: 0.953\n",
            "[11,   200/  391] train loss: 0.849 train accuracy: 0.953\n",
            "[11,   300/  391] train loss: 0.892 train accuracy: 0.945\n",
            "[12,   100/  391] train loss: 0.866 train accuracy: 0.961\n",
            "[12,   200/  391] train loss: 0.867 train accuracy: 0.945\n",
            "[12,   300/  391] train loss: 0.946 train accuracy: 0.945\n",
            "[13,   100/  391] train loss: 0.773 train accuracy: 0.938\n",
            "[13,   200/  391] train loss: 0.788 train accuracy: 0.945\n",
            "[13,   300/  391] train loss: 1.071 train accuracy: 0.914\n",
            "[14,   100/  391] train loss: 0.862 train accuracy: 0.953\n",
            "[14,   200/  391] train loss: 0.707 train accuracy: 0.953\n",
            "[14,   300/  391] train loss: 0.768 train accuracy: 0.953\n",
            "[15,   100/  391] train loss: 0.645 train accuracy: 0.961\n",
            "[15,   200/  391] train loss: 0.616 train accuracy: 0.969\n",
            "[15,   300/  391] train loss: 0.650 train accuracy: 0.977\n",
            "[16,   100/  391] train loss: 0.645 train accuracy: 0.977\n",
            "[16,   200/  391] train loss: 0.738 train accuracy: 0.945\n",
            "[16,   300/  391] train loss: 0.597 train accuracy: 0.953\n",
            "[17,   100/  391] train loss: 0.665 train accuracy: 0.953\n",
            "[17,   200/  391] train loss: 0.544 train accuracy: 0.953\n",
            "[17,   300/  391] train loss: 0.549 train accuracy: 0.977\n",
            "[18,   100/  391] train loss: 0.487 train accuracy: 0.977\n",
            "[18,   200/  391] train loss: 0.614 train accuracy: 0.984\n",
            "[18,   300/  391] train loss: 0.601 train accuracy: 0.977\n",
            "[19,   100/  391] train loss: 0.527 train accuracy: 0.977\n",
            "[19,   200/  391] train loss: 0.560 train accuracy: 0.992\n",
            "[19,   300/  391] train loss: 0.555 train accuracy: 0.977\n",
            "[20,   100/  391] train loss: 0.500 train accuracy: 0.984\n",
            "[20,   200/  391] train loss: 0.522 train accuracy: 0.977\n",
            "[20,   300/  391] train loss: 0.509 train accuracy: 0.984\n",
            "[21,   100/  391] train loss: 0.534 train accuracy: 0.961\n",
            "[21,   200/  391] train loss: 0.520 train accuracy: 0.969\n",
            "[21,   300/  391] train loss: 0.652 train accuracy: 0.953\n",
            "[22,   100/  391] train loss: 0.528 train accuracy: 0.984\n",
            "[22,   200/  391] train loss: 0.626 train accuracy: 0.969\n",
            "[22,   300/  391] train loss: 0.544 train accuracy: 0.969\n",
            "[23,   100/  391] train loss: 0.454 train accuracy: 0.992\n",
            "[23,   200/  391] train loss: 0.460 train accuracy: 0.992\n",
            "[23,   300/  391] train loss: 0.532 train accuracy: 0.984\n",
            "[24,   100/  391] train loss: 0.432 train accuracy: 0.992\n",
            "[24,   200/  391] train loss: 0.556 train accuracy: 0.969\n",
            "[24,   300/  391] train loss: 0.516 train accuracy: 0.969\n",
            "[25,   100/  391] train loss: 0.369 train accuracy: 1.000\n",
            "[25,   200/  391] train loss: 0.403 train accuracy: 0.984\n",
            "[25,   300/  391] train loss: 0.486 train accuracy: 0.961\n",
            "[26,   100/  391] train loss: 0.458 train accuracy: 0.992\n",
            "[26,   200/  391] train loss: 0.382 train accuracy: 0.992\n",
            "[26,   300/  391] train loss: 0.460 train accuracy: 0.992\n",
            "[27,   100/  391] train loss: 0.413 train accuracy: 0.984\n",
            "[27,   200/  391] train loss: 0.412 train accuracy: 0.992\n",
            "[27,   300/  391] train loss: 0.402 train accuracy: 1.000\n",
            "[28,   100/  391] train loss: 0.419 train accuracy: 0.992\n",
            "[28,   200/  391] train loss: 0.340 train accuracy: 0.992\n",
            "[28,   300/  391] train loss: 0.402 train accuracy: 0.984\n",
            "[29,   100/  391] train loss: 0.409 train accuracy: 0.984\n",
            "[29,   200/  391] train loss: 0.452 train accuracy: 0.984\n",
            "[29,   300/  391] train loss: 0.382 train accuracy: 0.977\n",
            "[30,   100/  391] train loss: 0.411 train accuracy: 0.992\n",
            "[30,   200/  391] train loss: 0.447 train accuracy: 0.984\n",
            "[30,   300/  391] train loss: 0.394 train accuracy: 0.992\n",
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.125\n",
            "12.467458990049188\n",
            "[1,   100/  391] train loss: 6.083 train accuracy: 0.594\n",
            "[1,   200/  391] train loss: 4.062 train accuracy: 0.734\n",
            "[1,   300/  391] train loss: 4.288 train accuracy: 0.680\n",
            "[2,   100/  391] train loss: 3.174 train accuracy: 0.828\n",
            "[2,   200/  391] train loss: 2.748 train accuracy: 0.773\n",
            "[2,   300/  391] train loss: 2.589 train accuracy: 0.805\n",
            "[3,   100/  391] train loss: 2.396 train accuracy: 0.844\n",
            "[3,   200/  391] train loss: 2.081 train accuracy: 0.836\n",
            "[3,   300/  391] train loss: 2.420 train accuracy: 0.820\n",
            "[4,   100/  391] train loss: 1.994 train accuracy: 0.859\n",
            "[4,   200/  391] train loss: 2.562 train accuracy: 0.828\n",
            "[4,   300/  391] train loss: 2.056 train accuracy: 0.867\n",
            "[5,   100/  391] train loss: 1.904 train accuracy: 0.812\n",
            "[5,   200/  391] train loss: 1.897 train accuracy: 0.867\n",
            "[5,   300/  391] train loss: 2.910 train accuracy: 0.758\n",
            "[6,   100/  391] train loss: 2.367 train accuracy: 0.812\n",
            "[6,   200/  391] train loss: 4.563 train accuracy: 0.688\n",
            "[6,   300/  391] train loss: 3.177 train accuracy: 0.766\n",
            "[7,   100/  391] train loss: 2.919 train accuracy: 0.797\n",
            "[7,   200/  391] train loss: 3.736 train accuracy: 0.695\n",
            "[7,   300/  391] train loss: 3.008 train accuracy: 0.773\n",
            "[8,   100/  391] train loss: 2.360 train accuracy: 0.828\n",
            "[8,   200/  391] train loss: 1.680 train accuracy: 0.875\n",
            "[8,   300/  391] train loss: 2.238 train accuracy: 0.836\n",
            "[9,   100/  391] train loss: 1.738 train accuracy: 0.898\n",
            "[9,   200/  391] train loss: 2.413 train accuracy: 0.844\n",
            "[9,   300/  391] train loss: 2.219 train accuracy: 0.781\n",
            "[10,   100/  391] train loss: 1.540 train accuracy: 0.875\n",
            "[10,   200/  391] train loss: 1.675 train accuracy: 0.859\n",
            "[10,   300/  391] train loss: 1.769 train accuracy: 0.898\n",
            "[11,   100/  391] train loss: 1.580 train accuracy: 0.867\n",
            "[11,   200/  391] train loss: 1.833 train accuracy: 0.891\n",
            "[11,   300/  391] train loss: 1.671 train accuracy: 0.883\n",
            "[12,   100/  391] train loss: 1.605 train accuracy: 0.867\n",
            "[12,   200/  391] train loss: 1.702 train accuracy: 0.859\n",
            "[12,   300/  391] train loss: 1.489 train accuracy: 0.914\n",
            "[13,   100/  391] train loss: 1.350 train accuracy: 0.906\n",
            "[13,   200/  391] train loss: 1.263 train accuracy: 0.883\n",
            "[13,   300/  391] train loss: 1.420 train accuracy: 0.898\n",
            "[14,   100/  391] train loss: 1.305 train accuracy: 0.898\n",
            "[14,   200/  391] train loss: 1.268 train accuracy: 0.891\n",
            "[14,   300/  391] train loss: 1.026 train accuracy: 0.906\n",
            "[15,   100/  391] train loss: 0.891 train accuracy: 0.938\n",
            "[15,   200/  391] train loss: 1.049 train accuracy: 0.930\n",
            "[15,   300/  391] train loss: 0.994 train accuracy: 0.961\n",
            "[16,   100/  391] train loss: 0.941 train accuracy: 0.938\n",
            "[16,   200/  391] train loss: 1.156 train accuracy: 0.922\n",
            "[16,   300/  391] train loss: 1.008 train accuracy: 0.938\n",
            "[17,   100/  391] train loss: 1.088 train accuracy: 0.891\n",
            "[17,   200/  391] train loss: 0.991 train accuracy: 0.953\n",
            "[17,   300/  391] train loss: 0.930 train accuracy: 0.953\n",
            "[18,   100/  391] train loss: 0.699 train accuracy: 0.953\n",
            "[18,   200/  391] train loss: 0.933 train accuracy: 0.922\n",
            "[18,   300/  391] train loss: 0.908 train accuracy: 0.938\n",
            "[19,   100/  391] train loss: 0.872 train accuracy: 0.961\n",
            "[19,   200/  391] train loss: 0.865 train accuracy: 0.953\n",
            "[19,   300/  391] train loss: 0.811 train accuracy: 0.961\n",
            "[20,   100/  391] train loss: 0.649 train accuracy: 0.961\n",
            "[20,   200/  391] train loss: 0.724 train accuracy: 0.961\n",
            "[20,   300/  391] train loss: 0.646 train accuracy: 0.969\n",
            "[21,   100/  391] train loss: 0.821 train accuracy: 0.961\n",
            "[21,   200/  391] train loss: 0.641 train accuracy: 0.969\n",
            "[21,   300/  391] train loss: 0.906 train accuracy: 0.914\n",
            "[22,   100/  391] train loss: 0.697 train accuracy: 0.969\n",
            "[22,   200/  391] train loss: 0.884 train accuracy: 0.945\n",
            "[22,   300/  391] train loss: 0.717 train accuracy: 0.961\n",
            "[23,   100/  391] train loss: 0.606 train accuracy: 0.969\n",
            "[23,   200/  391] train loss: 0.701 train accuracy: 0.977\n",
            "[23,   300/  391] train loss: 0.727 train accuracy: 0.961\n",
            "[24,   100/  391] train loss: 0.589 train accuracy: 0.984\n",
            "[24,   200/  391] train loss: 0.762 train accuracy: 0.961\n",
            "[24,   300/  391] train loss: 0.705 train accuracy: 0.953\n",
            "[25,   100/  391] train loss: 0.573 train accuracy: 0.977\n",
            "[25,   200/  391] train loss: 0.564 train accuracy: 0.977\n",
            "[25,   300/  391] train loss: 0.578 train accuracy: 0.969\n",
            "[26,   100/  391] train loss: 0.613 train accuracy: 0.984\n",
            "[26,   200/  391] train loss: 0.605 train accuracy: 0.961\n",
            "[26,   300/  391] train loss: 0.667 train accuracy: 0.969\n",
            "[27,   100/  391] train loss: 0.594 train accuracy: 0.984\n",
            "[27,   200/  391] train loss: 0.525 train accuracy: 0.953\n",
            "[27,   300/  391] train loss: 0.548 train accuracy: 0.992\n",
            "[28,   100/  391] train loss: 0.621 train accuracy: 0.984\n",
            "[28,   200/  391] train loss: 0.517 train accuracy: 0.984\n",
            "[28,   300/  391] train loss: 0.513 train accuracy: 0.984\n",
            "[29,   100/  391] train loss: 0.515 train accuracy: 0.984\n",
            "[29,   200/  391] train loss: 0.632 train accuracy: 0.953\n",
            "[29,   300/  391] train loss: 0.554 train accuracy: 0.961\n",
            "[30,   100/  391] train loss: 0.505 train accuracy: 0.969\n",
            "[30,   200/  391] train loss: 0.710 train accuracy: 0.961\n",
            "[30,   300/  391] train loss: 0.502 train accuracy: 0.992\n",
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.15625\n",
            "15.584321158659906\n",
            "[1,   100/  391] train loss: 6.992 train accuracy: 0.578\n",
            "[1,   200/  391] train loss: 7.453 train accuracy: 0.492\n",
            "[1,   300/  391] train loss: 6.485 train accuracy: 0.539\n",
            "[2,   100/  391] train loss: 3.951 train accuracy: 0.773\n",
            "[2,   200/  391] train loss: 3.416 train accuracy: 0.742\n",
            "[2,   300/  391] train loss: 3.812 train accuracy: 0.734\n",
            "[3,   100/  391] train loss: 3.568 train accuracy: 0.773\n",
            "[3,   200/  391] train loss: 3.199 train accuracy: 0.766\n",
            "[3,   300/  391] train loss: 3.355 train accuracy: 0.734\n",
            "[4,   100/  391] train loss: 3.126 train accuracy: 0.812\n",
            "[4,   200/  391] train loss: 3.167 train accuracy: 0.773\n",
            "[4,   300/  391] train loss: 3.836 train accuracy: 0.734\n",
            "[5,   100/  391] train loss: 3.073 train accuracy: 0.734\n",
            "[5,   200/  391] train loss: 2.906 train accuracy: 0.773\n",
            "[5,   300/  391] train loss: 2.612 train accuracy: 0.766\n",
            "[6,   100/  391] train loss: 2.837 train accuracy: 0.805\n",
            "[6,   200/  391] train loss: 2.824 train accuracy: 0.789\n",
            "[6,   300/  391] train loss: 2.236 train accuracy: 0.852\n",
            "[7,   100/  391] train loss: 2.557 train accuracy: 0.867\n",
            "[7,   200/  391] train loss: 2.765 train accuracy: 0.773\n",
            "[7,   300/  391] train loss: 2.568 train accuracy: 0.805\n",
            "[8,   100/  391] train loss: 9.315 train accuracy: 0.445\n",
            "[8,   200/  391] train loss: 5.648 train accuracy: 0.578\n",
            "[8,   300/  391] train loss: 5.647 train accuracy: 0.602\n",
            "[9,   100/  391] train loss: 3.990 train accuracy: 0.750\n",
            "[9,   200/  391] train loss: 3.822 train accuracy: 0.719\n",
            "[9,   300/  391] train loss: 3.292 train accuracy: 0.766\n",
            "[10,   100/  391] train loss: 3.121 train accuracy: 0.773\n",
            "[10,   200/  391] train loss: 2.849 train accuracy: 0.797\n",
            "[10,   300/  391] train loss: 3.118 train accuracy: 0.781\n",
            "[11,   100/  391] train loss: 2.197 train accuracy: 0.836\n",
            "[11,   200/  391] train loss: 2.266 train accuracy: 0.852\n",
            "[11,   300/  391] train loss: 2.313 train accuracy: 0.797\n",
            "[12,   100/  391] train loss: 2.389 train accuracy: 0.836\n",
            "[12,   200/  391] train loss: 2.430 train accuracy: 0.812\n",
            "[12,   300/  391] train loss: 2.520 train accuracy: 0.797\n",
            "[13,   100/  391] train loss: 2.070 train accuracy: 0.859\n",
            "[13,   200/  391] train loss: 2.291 train accuracy: 0.844\n",
            "[13,   300/  391] train loss: 2.494 train accuracy: 0.828\n",
            "[14,   100/  391] train loss: 2.549 train accuracy: 0.789\n",
            "[14,   200/  391] train loss: 2.167 train accuracy: 0.828\n",
            "[14,   300/  391] train loss: 1.883 train accuracy: 0.820\n",
            "[15,   100/  391] train loss: 1.753 train accuracy: 0.859\n",
            "[15,   200/  391] train loss: 1.878 train accuracy: 0.867\n",
            "[15,   300/  391] train loss: 1.943 train accuracy: 0.852\n",
            "[16,   100/  391] train loss: 1.677 train accuracy: 0.883\n",
            "[16,   200/  391] train loss: 1.753 train accuracy: 0.891\n",
            "[16,   300/  391] train loss: 1.923 train accuracy: 0.859\n",
            "[17,   100/  391] train loss: 1.572 train accuracy: 0.875\n",
            "[17,   200/  391] train loss: 1.804 train accuracy: 0.852\n",
            "[17,   300/  391] train loss: 1.519 train accuracy: 0.914\n",
            "[18,   100/  391] train loss: 1.353 train accuracy: 0.898\n",
            "[18,   200/  391] train loss: 1.606 train accuracy: 0.906\n",
            "[18,   300/  391] train loss: 1.727 train accuracy: 0.875\n",
            "[19,   100/  391] train loss: 1.738 train accuracy: 0.891\n",
            "[19,   200/  391] train loss: 1.372 train accuracy: 0.961\n",
            "[19,   300/  391] train loss: 1.564 train accuracy: 0.906\n",
            "[20,   100/  391] train loss: 1.179 train accuracy: 0.938\n",
            "[20,   200/  391] train loss: 1.454 train accuracy: 0.898\n",
            "[20,   300/  391] train loss: 1.462 train accuracy: 0.891\n",
            "[21,   100/  391] train loss: 1.410 train accuracy: 0.898\n",
            "[21,   200/  391] train loss: 1.380 train accuracy: 0.891\n",
            "[21,   300/  391] train loss: 1.414 train accuracy: 0.914\n",
            "[22,   100/  391] train loss: 1.380 train accuracy: 0.906\n",
            "[22,   200/  391] train loss: 1.524 train accuracy: 0.891\n",
            "[22,   300/  391] train loss: 1.390 train accuracy: 0.898\n",
            "[23,   100/  391] train loss: 1.139 train accuracy: 0.938\n",
            "[23,   200/  391] train loss: 1.240 train accuracy: 0.922\n",
            "[23,   300/  391] train loss: 1.629 train accuracy: 0.898\n",
            "[24,   100/  391] train loss: 1.201 train accuracy: 0.922\n",
            "[24,   200/  391] train loss: 1.425 train accuracy: 0.898\n",
            "[24,   300/  391] train loss: 1.346 train accuracy: 0.875\n",
            "[25,   100/  391] train loss: 0.969 train accuracy: 0.953\n",
            "[25,   200/  391] train loss: 1.163 train accuracy: 0.930\n",
            "[25,   300/  391] train loss: 1.353 train accuracy: 0.891\n",
            "[26,   100/  391] train loss: 1.226 train accuracy: 0.914\n",
            "[26,   200/  391] train loss: 1.059 train accuracy: 0.922\n",
            "[26,   300/  391] train loss: 1.312 train accuracy: 0.914\n",
            "[27,   100/  391] train loss: 1.086 train accuracy: 0.953\n",
            "[27,   200/  391] train loss: 1.108 train accuracy: 0.938\n",
            "[27,   300/  391] train loss: 1.209 train accuracy: 0.906\n",
            "[28,   100/  391] train loss: 1.109 train accuracy: 0.969\n",
            "[28,   200/  391] train loss: 1.005 train accuracy: 0.930\n",
            "[28,   300/  391] train loss: 1.265 train accuracy: 0.883\n",
            "[29,   100/  391] train loss: 1.058 train accuracy: 0.938\n",
            "[29,   200/  391] train loss: 1.258 train accuracy: 0.930\n",
            "[29,   300/  391] train loss: 0.933 train accuracy: 0.938\n",
            "[30,   100/  391] train loss: 0.906 train accuracy: 0.938\n",
            "[30,   200/  391] train loss: 1.142 train accuracy: 0.914\n",
            "[30,   300/  391] train loss: 0.970 train accuracy: 0.945\n",
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05 and pruning factor 0.1875\n",
            "18.701185046538342\n",
            "[1,   100/  391] train loss: 7.737 train accuracy: 0.562\n",
            "[1,   200/  391] train loss: 4.904 train accuracy: 0.656\n",
            "[1,   300/  391] train loss: 5.271 train accuracy: 0.625\n",
            "[2,   100/  391] train loss: 3.711 train accuracy: 0.719\n",
            "[2,   200/  391] train loss: 7.116 train accuracy: 0.461\n",
            "[2,   300/  391] train loss: 4.556 train accuracy: 0.695\n",
            "[3,   100/  391] train loss: 3.012 train accuracy: 0.781\n",
            "[3,   200/  391] train loss: 3.140 train accuracy: 0.758\n",
            "[3,   300/  391] train loss: 3.218 train accuracy: 0.742\n",
            "[4,   100/  391] train loss: 4.469 train accuracy: 0.695\n",
            "[4,   200/  391] train loss: 3.787 train accuracy: 0.789\n",
            "[4,   300/  391] train loss: 3.036 train accuracy: 0.773\n",
            "[5,   100/  391] train loss: 2.920 train accuracy: 0.766\n",
            "[5,   200/  391] train loss: 2.506 train accuracy: 0.812\n",
            "[5,   300/  391] train loss: 2.477 train accuracy: 0.812\n",
            "[6,   100/  391] train loss: 2.353 train accuracy: 0.812\n",
            "[6,   200/  391] train loss: 2.548 train accuracy: 0.805\n",
            "[6,   300/  391] train loss: 2.282 train accuracy: 0.797\n",
            "[7,   100/  391] train loss: 2.732 train accuracy: 0.812\n",
            "[7,   200/  391] train loss: 2.394 train accuracy: 0.805\n",
            "[7,   300/  391] train loss: 2.254 train accuracy: 0.812\n",
            "[8,   100/  391] train loss: 1.718 train accuracy: 0.914\n",
            "[8,   200/  391] train loss: 1.555 train accuracy: 0.867\n",
            "[8,   300/  391] train loss: 2.303 train accuracy: 0.828\n",
            "[9,   100/  391] train loss: 1.788 train accuracy: 0.914\n",
            "[9,   200/  391] train loss: 1.807 train accuracy: 0.883\n",
            "[9,   300/  391] train loss: 1.818 train accuracy: 0.867\n",
            "[10,   100/  391] train loss: 1.677 train accuracy: 0.898\n",
            "[10,   200/  391] train loss: 1.851 train accuracy: 0.867\n",
            "[10,   300/  391] train loss: 1.654 train accuracy: 0.898\n",
            "[11,   100/  391] train loss: 1.264 train accuracy: 0.883\n",
            "[11,   200/  391] train loss: 1.145 train accuracy: 0.938\n",
            "[11,   300/  391] train loss: 1.391 train accuracy: 0.898\n",
            "[12,   100/  391] train loss: 1.496 train accuracy: 0.875\n",
            "[12,   200/  391] train loss: 1.422 train accuracy: 0.883\n",
            "[12,   300/  391] train loss: 1.399 train accuracy: 0.883\n",
            "[13,   100/  391] train loss: 1.376 train accuracy: 0.883\n",
            "[13,   200/  391] train loss: 1.085 train accuracy: 0.906\n",
            "[13,   300/  391] train loss: 1.486 train accuracy: 0.906\n",
            "[14,   100/  391] train loss: 1.337 train accuracy: 0.891\n",
            "[14,   200/  391] train loss: 1.386 train accuracy: 0.891\n",
            "[14,   300/  391] train loss: 1.064 train accuracy: 0.922\n",
            "[15,   100/  391] train loss: 0.979 train accuracy: 0.914\n",
            "[15,   200/  391] train loss: 1.331 train accuracy: 0.914\n",
            "[15,   300/  391] train loss: 1.245 train accuracy: 0.922\n",
            "[16,   100/  391] train loss: 0.929 train accuracy: 0.945\n",
            "[16,   200/  391] train loss: 1.051 train accuracy: 0.945\n",
            "[16,   300/  391] train loss: 1.023 train accuracy: 0.914\n",
            "[17,   100/  391] train loss: 1.042 train accuracy: 0.930\n",
            "[17,   200/  391] train loss: 0.977 train accuracy: 0.945\n",
            "[17,   300/  391] train loss: 0.995 train accuracy: 0.938\n",
            "[18,   100/  391] train loss: 0.937 train accuracy: 0.945\n",
            "[18,   200/  391] train loss: 1.132 train accuracy: 0.945\n",
            "[18,   300/  391] train loss: 1.141 train accuracy: 0.891\n",
            "[19,   100/  391] train loss: 0.908 train accuracy: 0.945\n",
            "[19,   200/  391] train loss: 0.901 train accuracy: 0.969\n",
            "[19,   300/  391] train loss: 0.866 train accuracy: 0.953\n",
            "[20,   100/  391] train loss: 0.760 train accuracy: 0.969\n",
            "[20,   200/  391] train loss: 0.831 train accuracy: 0.969\n",
            "[20,   300/  391] train loss: 0.796 train accuracy: 0.961\n",
            "[21,   100/  391] train loss: 0.833 train accuracy: 0.961\n",
            "[21,   200/  391] train loss: 0.859 train accuracy: 0.961\n",
            "[21,   300/  391] train loss: 0.935 train accuracy: 0.930\n",
            "[22,   100/  391] train loss: 0.847 train accuracy: 0.945\n",
            "[22,   200/  391] train loss: 0.900 train accuracy: 0.930\n",
            "[22,   300/  391] train loss: 0.836 train accuracy: 0.953\n",
            "[23,   100/  391] train loss: 0.636 train accuracy: 1.000\n",
            "[23,   200/  391] train loss: 0.681 train accuracy: 0.984\n"
          ]
        }
      ],
      "source": [
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [10]\n",
        "alphas = [0.5]\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "pruning_factors = [i/32 for i in range(1, 33)]\n",
        "#pruning_factors = [0.2]  # Define desired pruning factors\n",
        "\n",
        "for pruning_factor in pruning_factors:\n",
        "    for hparam in hparams_list:\n",
        "        print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "        reproducibilitySeed()\n",
        "        student_net = networks.StudentNetwork(pruning_factor)\n",
        "        student_net = student_net.to(fast_device)\n",
        "        teacher_net = teacher_net.to(fast_device)\n",
        "        hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "        student_zero_params = count_zero_parameters(student_net)\n",
        "        student_total_params = count_parameters(student_net)\n",
        "        print(100 * student_zero_params / student_total_params)\n",
        "\n",
        "        results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs,\n",
        "                                                                                    train_val_loader, None,\n",
        "                                                                                    print_every=print_every,\n",
        "                                                                                    fast_device=fast_device)\n",
        "        save_path = checkpoints_path_student + utils.hparamToString(hparam) + f'_pruning_{pruning_factor}_final.tar'\n",
        "        torch.save({'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "                    'model_state_dict': student_net.state_dict(),\n",
        "                    'epoch': num_epochs}, save_path)\n",
        "\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As7YIX7D-5Eb"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of trainable parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def count_zero_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters that are exactly zero.\n",
        "    \"\"\"\n",
        "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xldxEKE-yrL",
        "outputId": "44246a9a-04a8-49e5-d2eb-09212a14f020"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Network: 58164298 total parameters, 0 are zero.\n",
            "Student Network: 58164298 total parameters, 5801373 are zero.\n",
            "Percentage of zero parameters in Teacher Network: 0.00%\n",
            "Percentage of zero parameters in Student Network: 9.97%\n"
          ]
        }
      ],
      "source": [
        "# Assuming teacher_net and student_net are instances of TeacherNetwork and StudentNetwork, respectively\n",
        "teacher_net = networks.TeacherNetwork()\n",
        "student_net = networks.StudentNetwork(0.1)\n",
        "\n",
        "# Calculate and print the total number of parameters for both models\n",
        "teacher_total_params = count_parameters(teacher_net)\n",
        "student_total_params = count_parameters(student_net)\n",
        "\n",
        "# Calculate and print the number of zero parameters for both models\n",
        "teacher_zero_params = count_zero_parameters(teacher_net)\n",
        "student_zero_params = count_zero_parameters(student_net)\n",
        "\n",
        "print(f\"Teacher Network: {teacher_total_params} total parameters, {teacher_zero_params} are zero.\")\n",
        "print(f\"Student Network: {student_total_params} total parameters, {student_zero_params} are zero.\")\n",
        "\n",
        "# Optionally, calculate the percentage of zero parameters in each model\n",
        "teacher_zero_percent = 100 * teacher_zero_params / teacher_total_params\n",
        "student_zero_percent = 100 * student_zero_params / student_total_params\n",
        "\n",
        "print(f\"Percentage of zero parameters in Teacher Network: {teacher_zero_percent:.2f}%\")\n",
        "print(f\"Percentage of zero parameters in Student Network: {student_zero_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5BDrMOwNI1i"
      },
      "outputs": [],
      "source": [
        "teacher_total_params = count_parameters(teacher_net)\n",
        "teacher_zero_params = count_zero_parameters(teacher_net)\n",
        "teacher_zero_percent = 100 * teacher_zero_params / teacher_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqOQ_vv4flkh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "result = pd.DataFrame(columns=['Pruning Factor', 'Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iActiWzaIgPY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import networks  # Ensure the correct import of your networks module\n",
        "import utils  # Utilities for hyperparameter string conversion and more\n",
        "\n",
        "\n",
        "# Define your hyperparameters\n",
        "t = [10]\n",
        "alpha = [0.5]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "weight_decays = [1e-5]\n",
        "learning_rate_decays = [0.95]\n",
        "momentums = [0.9]\n",
        "learning_rates = [1e-2]\n",
        "pruning_factors = [i/32 for i in range(1, 33)]\n",
        "#pruning_factors = [0.1, 0.2]  # Example pruning factors\n",
        "\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(t, alpha, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {\n",
        "        'T': hparam_tuple[0],\n",
        "        'alpha': hparam_tuple[1],\n",
        "        'dropout_input': hparam_tuple[2][0],\n",
        "        'dropout_hidden': hparam_tuple[2][1],\n",
        "        'weight_decay': hparam_tuple[3],\n",
        "        'lr_decay': hparam_tuple[4],\n",
        "        'momentum': hparam_tuple[5],\n",
        "        'lr': hparam_tuple[6]\n",
        "    }\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "# Define the path to your checkpoints\n",
        "checkpoints_path_student = \"../content/checkpoints_student/\"\n",
        "\n",
        "# Load and set up each student model based on hyperparameters and pruning factor\n",
        "for hparam in hparams_list:\n",
        "    for prune_factor in pruning_factors:\n",
        "        filename = utils.hparamToString(hparam) + f'_pruning_{prune_factor}_final.tar'\n",
        "        load_path = checkpoints_path_student + filename\n",
        "\n",
        "        # Load the student network\n",
        "        student_net = networks.StudentNetwork(prune_amount=prune_factor)\n",
        "        student_net.load_state_dict(torch.load(load_path, map_location=fast_device, weights_only=True)['model_state_dict'])\n",
        "        student_net = student_net.to(fast_device)  # Move to the appropriate device, again adjust as needed\n",
        "\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "\n",
        "        # Create a new DataFrame from the data to be added\n",
        "        new_data = pd.DataFrame({'Pruning Factor': [prune_factor], 'Accuracy': [test_accuracy]})\n",
        "        # Use concat to add the new data to the existing DataFrame\n",
        "        result = pd.concat([result, new_data], ignore_index=True)\n",
        "        print('student test accuracy for ' + f'pruning factor = {prune_factor}:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "dBh4uVqoeAno",
        "outputId": "b721ad18-ccd4-45cb-adc9-21cd1d549150"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d3956de329d1>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pruning Factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy vs Pruning Factor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pruning Factor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(result['Pruning Factor'], result['Accuracy'], marker='o')\n",
        "plt.title('Accuracy vs Pruning Factor')\n",
        "plt.xlabel('Pruning Factor')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq2518KJeA5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8QIxar6eBGE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdENhUOdeBSo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VZ89F7hMfnc",
        "outputId": "276e914c-e088-4363-90a2-1db91be81b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Network: 58164298 total parameters, 0 are zero.\n",
            "Student Network: 58164298 total parameters, 11602625 are zero.\n",
            "Percentage of zero parameters in Teacher Network: 0.00%\n",
            "Percentage of zero parameters in Student Network: 19.95%\n"
          ]
        }
      ],
      "source": [
        "# Assuming teacher_net and student_net are instances of TeacherNetwork and StudentNetwork, respectively\n",
        "teacher_net = networks.TeacherNetwork()\n",
        "student_net = networks.StudentNetwork(0.2)\n",
        "\n",
        "# Calculate and print the total number of parameters for both models\n",
        "teacher_total_params = count_parameters(teacher_net)\n",
        "student_total_params = count_parameters(student_net)\n",
        "\n",
        "# Calculate and print the number of zero parameters for both models\n",
        "teacher_zero_params = count_zero_parameters(teacher_net)\n",
        "student_zero_params = count_zero_parameters(student_net)\n",
        "\n",
        "print(f\"Teacher Network: {teacher_total_params} total parameters, {teacher_zero_params} are zero.\")\n",
        "print(f\"Student Network: {student_total_params} total parameters, {student_zero_params} are zero.\")\n",
        "\n",
        "# Optionally, calculate the percentage of zero parameters in each model\n",
        "teacher_zero_percent = 100 * teacher_zero_params / teacher_total_params\n",
        "student_zero_percent = 100 * student_zero_params / student_total_params\n",
        "\n",
        "print(f\"Percentage of zero parameters in Teacher Network: {teacher_zero_percent:.2f}%\")\n",
        "print(f\"Percentage of zero parameters in Student Network: {student_zero_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L97WQ1QFOQkM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}