{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bREGbUT_Y8F"
      },
      "source": [
        "### Import required packages and limit GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcqwxR8_Y8I",
        "outputId": "26140e84-9279-479e-cc80-7c9a0b1a8fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import csv\n",
        "\n",
        "# Import the module\n",
        "import networks\n",
        "import utils\n",
        "from quantize_neural_net import QuantizeNeuralNet\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "n73sKlgl_Y8K"
      },
      "outputs": [],
      "source": [
        "use_gpu = True    # set use_gpu to True if system has gpu\n",
        "gpu_id = 0        # id of gpu to be used\n",
        "cpu_device = torch.device('cpu')\n",
        "# fast_device is where computation (training, inference) happens\n",
        "fast_device = torch.device('cpu')\n",
        "if use_gpu:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
        "    fast_device = torch.device('cuda:' + str(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DAfPa7mw_Y8L"
      },
      "outputs": [],
      "source": [
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    if use_gpu:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0sxuxkJbUEI"
      },
      "outputs": [],
      "source": [
        "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
        "checkpoints_path_student_nokd = 'checkpoints_student/checkpoints_student_NoKD/'\n",
        "checkpoints_path_student_van = 'checkpoints_student/checkpoints_student_VAN/'\n",
        "checkpoints_path_student_qat = 'checkpoints_student/checkpoints_student_QAT/'\n",
        "checkpoints_path_student_dml = 'checkpoints_student/checkpoints_student_DML/'\n",
        "if not os.path.exists(checkpoints_path_teacher):\n",
        "    os.makedirs(checkpoints_path_teacher)\n",
        "if not os.path.exists(checkpoints_path_student_nokd):\n",
        "    os.makedirs(checkpoints_path_student_nokd)\n",
        "if not os.path.exists(checkpoints_path_student_van):\n",
        "    os.makedirs(checkpoints_path_student_van)\n",
        "if not os.path.exists(checkpoints_path_student_qat):\n",
        "    os.makedirs(checkpoints_path_student_qat)\n",
        "if not os.path.exists(checkpoints_path_student_dml):\n",
        "    os.makedirs(checkpoints_path_student_dml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCz4Pup_Y8M"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import PIL\n",
        "\n",
        "# Set up transformations for CIFAR-10\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        #transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
        "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "import torchvision as tv\n",
        "preprocess_train = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((160, 160), interpolation=PIL.Image.BILINEAR),  # It's the default, just being explicit for the reader.\n",
        "    tv.transforms.RandomCrop((128, 128)),\n",
        "    tv.transforms.RandomHorizontalFlip(),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "preprocess_eval = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((128, 128), interpolation=PIL.Image.BILINEAR),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "# Split the training dataset into training and validation\n",
        "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
        "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of trainable parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters.\n",
        "    \"\"\"\n",
        "    return sum((p.data != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def count_zero_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters that are exactly zero.\n",
        "    \"\"\"\n",
        "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teacher Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load pre-trained teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9225\n"
          ]
        }
      ],
      "source": [
        "import detectors\n",
        "import timm\n",
        "\n",
        "teacher_net = timm.create_model(\"resnet50_cifar10\", pretrained=True)\n",
        "\n",
        "teacher_net = teacher_net.to(fast_device)\n",
        "# pre-trained teacher accuracy\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_19444\\1025170478.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9225\n"
          ]
        }
      ],
      "source": [
        "# another way load teacher\n",
        "teacher_net = networks.TeacherNetwork50()\n",
        "\n",
        "checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n",
        "\n",
        "teacher_net.model.load_state_dict(checkpoint)\n",
        "teacher_net.to(fast_device)\n",
        "\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantized Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_teacher/results_teacher_quantization.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 63.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 74.75141906738281.\n",
            "The relative quantization error of layer 0 is 0.3043535351753235.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 162.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 35.41629409790039.\n",
            "The relative quantization error of layer 1 is 0.32139432430267334.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2190.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 15.934301376342773.\n",
            "The relative quantization error of layer 2 is 0.25553348660469055.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 177.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 32.39619445800781.\n",
            "The relative quantization error of layer 3 is 0.34422844648361206.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 179.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 49.3100700378418.\n",
            "The relative quantization error of layer 4 is 0.29755058884620667.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 412.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.44031524658203.\n",
            "The relative quantization error of layer 5 is 0.2817111909389496.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2742.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.435423851013184.\n",
            "The relative quantization error of layer 6 is 0.25495684146881104.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 171.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 19.194000244140625.\n",
            "The relative quantization error of layer 7 is 0.31453484296798706.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 350.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 28.050264358520508.\n",
            "The relative quantization error of layer 8 is 0.2791241407394409.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2198.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.500819683074951.\n",
            "The relative quantization error of layer 9 is 0.23217202723026276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 167.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 13.657468795776367.\n",
            "The relative quantization error of layer 10 is 0.3084966540336609.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 197.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 46.16700744628906.\n",
            "The relative quantization error of layer 11 is 0.2789711654186249.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1885.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 14.17356014251709.\n",
            "The relative quantization error of layer 12 is 0.22044014930725098.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 627.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 12.79133415222168.\n",
            "The relative quantization error of layer 13 is 0.2584977149963379.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 62.22951889038086.\n",
            "The relative quantization error of layer 14 is 0.26193684339523315.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1537.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.716611862182617.\n",
            "The relative quantization error of layer 15 is 0.2560330927371979.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2723.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 4.128220558166504.\n",
            "The relative quantization error of layer 16 is 0.18778859078884125.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 615.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 7.703878402709961.\n",
            "The relative quantization error of layer 17 is 0.29582053422927856.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1588.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 16.03752326965332.\n",
            "The relative quantization error of layer 18 is 0.2705574035644531.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3143.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.815471172332764.\n",
            "The relative quantization error of layer 19 is 0.21051625907421112.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 598.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 7.015102863311768.\n",
            "The relative quantization error of layer 20 is 0.3418448567390442.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1651.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 16.831050872802734.\n",
            "The relative quantization error of layer 21 is 0.28919970989227295.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3000.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 3.6421430110931396.\n",
            "The relative quantization error of layer 22 is 0.23563769459724426.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 658.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 6.332967281341553.\n",
            "The relative quantization error of layer 23 is 0.3809968829154968.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1021.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 28.348047256469727.\n",
            "The relative quantization error of layer 24 is 0.28598836064338684.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2651.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 7.760924339294434.\n",
            "The relative quantization error of layer 25 is 0.19425258040428162.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 992.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 9.241960525512695.\n",
            "The relative quantization error of layer 26 is 0.24000994861125946.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 320.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 30.841838836669922.\n",
            "The relative quantization error of layer 27 is 0.2819196283817291.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2255.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 7.24064826965332.\n",
            "The relative quantization error of layer 28 is 0.20368382334709167.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3015.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 1.2102839946746826.\n",
            "The relative quantization error of layer 29 is 0.11046106368303299.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1127.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 3.1943657398223877.\n",
            "The relative quantization error of layer 30 is 0.2461012452840805.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2120.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 7.6700119972229.\n",
            "The relative quantization error of layer 31 is 0.22331516444683075.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3035.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 1.3028006553649902.\n",
            "The relative quantization error of layer 32 is 0.10552302747964859.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1103.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 3.5631821155548096.\n",
            "The relative quantization error of layer 33 is 0.2698371410369873.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2172.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 9.077886581420898.\n",
            "The relative quantization error of layer 34 is 0.23386691510677338.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2597.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 1.5034607648849487.\n",
            "The relative quantization error of layer 35 is 0.1180219054222107.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1117.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 4.175963401794434.\n",
            "The relative quantization error of layer 36 is 0.3467108905315399.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2043.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 10.177363395690918.\n",
            "The relative quantization error of layer 37 is 0.2850300371646881.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2624.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 1.7196729183197021.\n",
            "The relative quantization error of layer 38 is 0.1327645629644394.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 944.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 3.991440773010254.\n",
            "The relative quantization error of layer 39 is 0.41265568137168884.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1914.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 9.7926607131958.\n",
            "The relative quantization error of layer 40 is 0.3102896511554718.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3113.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 1.609020471572876.\n",
            "The relative quantization error of layer 41 is 0.12733599543571472.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 927.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 3.821528196334839.\n",
            "The relative quantization error of layer 42 is 0.39679470658302307.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1346.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 12.961925506591797.\n",
            "The relative quantization error of layer 43 is 0.30996158719062805.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2901.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 1.4532700777053833.\n",
            "The relative quantization error of layer 44 is 0.07794291526079178.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1484.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 3.5765187740325928.\n",
            "The relative quantization error of layer 45 is 0.28158098459243774.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 592.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 7.641849517822266.\n",
            "The relative quantization error of layer 46 is 0.3641355037689209.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2473.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 9.225818634033203.\n",
            "The relative quantization error of layer 47 is 0.2368202954530716.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2358.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.3827952444553375.\n",
            "The relative quantization error of layer 48 is 0.07053051888942719.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1479.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.4206205606460571.\n",
            "The relative quantization error of layer 49 is 0.3241168260574341.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2701.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 13.575316429138184.\n",
            "The relative quantization error of layer 50 is 0.23417633771896362.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3011.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.35849595069885254.\n",
            "The relative quantization error of layer 51 is 0.07326318323612213.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1501.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.9614585638046265.\n",
            "The relative quantization error of layer 52 is 0.34178441762924194.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2515.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 19.970745086669922.\n",
            "The relative quantization error of layer 53 is 0.14428873360157013.\n",
            "\n",
            "Bits 2, Effective Quantized Bit Size: 3.0149168979579897\n",
            "Bits 2, Quantized Test Accuracy: 0.9088\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 329.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 66.9831314086914.\n",
            "The relative quantization error of layer 0 is 0.27934136986732483.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.345476150512695.\n",
            "The relative quantization error of layer 1 is 0.2853984236717224.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2548.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.60810661315918.\n",
            "The relative quantization error of layer 2 is 0.23284433782100677.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.91997528076172.\n",
            "The relative quantization error of layer 3 is 0.2969741225242615.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.58095169067383.\n",
            "The relative quantization error of layer 4 is 0.27014508843421936.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 373.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.683794021606445.\n",
            "The relative quantization error of layer 5 is 0.26558050513267517.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2565.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.566462516784668.\n",
            "The relative quantization error of layer 6 is 0.2604098618030548.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 183.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.952857971191406.\n",
            "The relative quantization error of layer 7 is 0.2774997651576996.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 419.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.79037094116211.\n",
            "The relative quantization error of layer 8 is 0.2448756992816925.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2679.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.465322971343994.\n",
            "The relative quantization error of layer 9 is 0.19772538542747498.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.67727279663086.\n",
            "The relative quantization error of layer 10 is 0.2627602219581604.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 218.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.697296142578125.\n",
            "The relative quantization error of layer 11 is 0.22841599583625793.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1500.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.57330322265625.\n",
            "The relative quantization error of layer 12 is 0.19529446959495544.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 524.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.506060600280762.\n",
            "The relative quantization error of layer 13 is 0.2120474874973297.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 58.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 52.717529296875.\n",
            "The relative quantization error of layer 14 is 0.2208581119775772.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1380.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.722126007080078.\n",
            "The relative quantization error of layer 15 is 0.22234870493412018.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2509.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.5605199337005615.\n",
            "The relative quantization error of layer 16 is 0.16209672391414642.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 533.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 6.127151966094971.\n",
            "The relative quantization error of layer 17 is 0.23414677381515503.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1442.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.181510925292969.\n",
            "The relative quantization error of layer 18 is 0.22514641284942627.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2403.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.913954496383667.\n",
            "The relative quantization error of layer 19 is 0.1678055077791214.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 549.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.34153938293457.\n",
            "The relative quantization error of layer 20 is 0.25933006405830383.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1438.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 13.088384628295898.\n",
            "The relative quantization error of layer 21 is 0.2257148027420044.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2654.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.745035171508789.\n",
            "The relative quantization error of layer 22 is 0.175448477268219.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 656.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.4061503410339355.\n",
            "The relative quantization error of layer 23 is 0.26359686255455017.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1045.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 21.228530883789062.\n",
            "The relative quantization error of layer 24 is 0.21430204808712006.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2816.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 6.075514793395996.\n",
            "The relative quantization error of layer 25 is 0.153832346200943.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1075.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.806357383728027.\n",
            "The relative quantization error of layer 26 is 0.1776019036769867.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 336.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.622976303100586.\n",
            "The relative quantization error of layer 27 is 0.2169083058834076.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2111.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.91540002822876.\n",
            "The relative quantization error of layer 28 is 0.16936631500720978.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2916.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9008159637451172.\n",
            "The relative quantization error of layer 29 is 0.08203240483999252.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1084.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.4729950428009033.\n",
            "The relative quantization error of layer 30 is 0.19021473824977875.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2285.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 6.006417751312256.\n",
            "The relative quantization error of layer 31 is 0.17598018050193787.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2654.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 1.0303001403808594.\n",
            "The relative quantization error of layer 32 is 0.08288659900426865.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1179.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.613196849822998.\n",
            "The relative quantization error of layer 33 is 0.1962519884109497.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2410.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.540392875671387.\n",
            "The relative quantization error of layer 34 is 0.16850869357585907.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3555.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9705906510353088.\n",
            "The relative quantization error of layer 35 is 0.07759780436754227.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1185.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.794811487197876.\n",
            "The relative quantization error of layer 36 is 0.23317022621631622.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1850.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.936887264251709.\n",
            "The relative quantization error of layer 37 is 0.19653195142745972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3286.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 1.0342133045196533.\n",
            "The relative quantization error of layer 38 is 0.0802331194281578.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1213.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.6538960933685303.\n",
            "The relative quantization error of layer 39 is 0.2801872789859772.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2295.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.480883598327637.\n",
            "The relative quantization error of layer 40 is 0.20542004704475403.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3149.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9996687769889832.\n",
            "The relative quantization error of layer 41 is 0.07693099975585938.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1179.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.6643011569976807.\n",
            "The relative quantization error of layer 42 is 0.27525609731674194.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1437.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.402486801147461.\n",
            "The relative quantization error of layer 43 is 0.20150607824325562.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2574.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 1.0286734104156494.\n",
            "The relative quantization error of layer 44 is 0.05270499736070633.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1729.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.8772552013397217.\n",
            "The relative quantization error of layer 45 is 0.22234606742858887.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 614.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.58685302734375.\n",
            "The relative quantization error of layer 46 is 0.26341477036476135.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2263.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.7573981285095215.\n",
            "The relative quantization error of layer 47 is 0.19215263426303864.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3437.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.28867965936660767.\n",
            "The relative quantization error of layer 48 is 0.05077618733048439.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1723.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3013784885406494.\n",
            "The relative quantization error of layer 49 is 0.29586061835289.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2946.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.078422546386719.\n",
            "The relative quantization error of layer 50 is 0.19239911437034607.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2393.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.28552839159965515.\n",
            "The relative quantization error of layer 51 is 0.0600602887570858.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1312.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7021747827529907.\n",
            "The relative quantization error of layer 52 is 0.30030357837677.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3385.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.228706359863281.\n",
            "The relative quantization error of layer 53 is 0.10727124661207199.\n",
            "\n",
            "Bits 4, Effective Quantized Bit Size: 5.010399202545555\n",
            "Bits 4, Quantized Test Accuracy: 0.9139\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 300.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 67.4151382446289.\n",
            "The relative quantization error of layer 0 is 0.27905702590942383.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 195.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.21977996826172.\n",
            "The relative quantization error of layer 1 is 0.2817882299423218.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2306.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.50682544708252.\n",
            "The relative quantization error of layer 2 is 0.22832253575325012.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 181.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.3410587310791.\n",
            "The relative quantization error of layer 3 is 0.29040244221687317.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 179.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.124237060546875.\n",
            "The relative quantization error of layer 4 is 0.26754480600357056.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 417.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.586013793945312.\n",
            "The relative quantization error of layer 5 is 0.2620031535625458.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2709.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.501262664794922.\n",
            "The relative quantization error of layer 6 is 0.2566608488559723.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.854856491088867.\n",
            "The relative quantization error of layer 7 is 0.27561789751052856.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 405.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 23.929779052734375.\n",
            "The relative quantization error of layer 8 is 0.23605795204639435.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 3051.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.500518321990967.\n",
            "The relative quantization error of layer 9 is 0.19976122677326202.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.594869613647461.\n",
            "The relative quantization error of layer 10 is 0.2615126073360443.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 223.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.444313049316406.\n",
            "The relative quantization error of layer 11 is 0.2261487990617752.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2092.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.689505577087402.\n",
            "The relative quantization error of layer 12 is 0.19672594964504242.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 639.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.377237319946289.\n",
            "The relative quantization error of layer 13 is 0.21029460430145264.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 50.84135437011719.\n",
            "The relative quantization error of layer 14 is 0.2133982628583908.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1505.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.336895942687988.\n",
            "The relative quantization error of layer 15 is 0.21337690949440002.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2917.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.440180540084839.\n",
            "The relative quantization error of layer 16 is 0.15761323273181915.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 644.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.867945671081543.\n",
            "The relative quantization error of layer 17 is 0.22582750022411346.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1635.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.966320991516113.\n",
            "The relative quantization error of layer 18 is 0.21873781085014343.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3146.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8707644939422607.\n",
            "The relative quantization error of layer 19 is 0.16731208562850952.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 646.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.1576385498046875.\n",
            "The relative quantization error of layer 20 is 0.2504446506500244.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1595.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.708144187927246.\n",
            "The relative quantization error of layer 21 is 0.21903879940509796.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3217.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.622819185256958.\n",
            "The relative quantization error of layer 22 is 0.16786251962184906.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 657.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.250904083251953.\n",
            "The relative quantization error of layer 23 is 0.25576311349868774.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 901.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.9106388092041.\n",
            "The relative quantization error of layer 24 is 0.21216467022895813.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2792.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.889051914215088.\n",
            "The relative quantization error of layer 25 is 0.14675016701221466.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1135.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.597007751464844.\n",
            "The relative quantization error of layer 26 is 0.17017975449562073.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 338.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.231475830078125.\n",
            "The relative quantization error of layer 27 is 0.21402175724506378.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2270.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.8523125648498535.\n",
            "The relative quantization error of layer 28 is 0.16516700387001038.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3310.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.894136905670166.\n",
            "The relative quantization error of layer 29 is 0.08099999278783798.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1152.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.370112657546997.\n",
            "The relative quantization error of layer 30 is 0.18085749447345734.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2213.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.760120868682861.\n",
            "The relative quantization error of layer 31 is 0.1708884835243225.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3270.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.937648594379425.\n",
            "The relative quantization error of layer 32 is 0.07743415981531143.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1149.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.579735517501831.\n",
            "The relative quantization error of layer 33 is 0.1956048160791397.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2111.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.475790977478027.\n",
            "The relative quantization error of layer 34 is 0.16429376602172852.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3051.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9198211431503296.\n",
            "The relative quantization error of layer 35 is 0.07234805822372437.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1050.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.6593177318573.\n",
            "The relative quantization error of layer 36 is 0.22428856790065765.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2057.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.7529826164245605.\n",
            "The relative quantization error of layer 37 is 0.18790408968925476.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3198.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9671808481216431.\n",
            "The relative quantization error of layer 38 is 0.07361818104982376.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1188.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4557199478149414.\n",
            "The relative quantization error of layer 39 is 0.26048743724823.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2257.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.05305814743042.\n",
            "The relative quantization error of layer 40 is 0.19392620027065277.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3160.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9446326494216919.\n",
            "The relative quantization error of layer 41 is 0.07502715289592743.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1165.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.445124864578247.\n",
            "The relative quantization error of layer 42 is 0.2532714605331421.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1696.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.19128704071045.\n",
            "The relative quantization error of layer 43 is 0.19703683257102966.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3027.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9882463812828064.\n",
            "The relative quantization error of layer 44 is 0.05360652506351471.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1635.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.9544875621795654.\n",
            "The relative quantization error of layer 45 is 0.22759570181369781.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 608.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.608595848083496.\n",
            "The relative quantization error of layer 46 is 0.2617287337779999.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2909.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.753566741943359.\n",
            "The relative quantization error of layer 47 is 0.18899013102054596.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3079.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.29289454221725464.\n",
            "The relative quantization error of layer 48 is 0.053601399064064026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1609.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3506920337677002.\n",
            "The relative quantization error of layer 49 is 0.29725778102874756.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2793.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.597183227539062.\n",
            "The relative quantization error of layer 50 is 0.18240322172641754.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3338.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.286957710981369.\n",
            "The relative quantization error of layer 51 is 0.05996713414788246.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1719.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7267590761184692.\n",
            "The relative quantization error of layer 52 is 0.2972990572452545.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3416.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 14.138864517211914.\n",
            "The relative quantization error of layer 53 is 0.09980128705501556.\n",
            "\n",
            "Bits 6, Effective Quantized Bit Size: 6.994736327891663\n",
            "Bits 6, Quantized Test Accuracy: 0.9135\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 308.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 69.11631774902344.\n",
            "The relative quantization error of layer 0 is 0.27631664276123047.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 158.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.72626495361328.\n",
            "The relative quantization error of layer 1 is 0.2795521318912506.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2243.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.12448501586914.\n",
            "The relative quantization error of layer 2 is 0.22660326957702637.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 159.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 28.03328514099121.\n",
            "The relative quantization error of layer 3 is 0.2970427870750427.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.20784378051758.\n",
            "The relative quantization error of layer 4 is 0.26882633566856384.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 424.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.450395584106445.\n",
            "The relative quantization error of layer 5 is 0.26111817359924316.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2894.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.435869216918945.\n",
            "The relative quantization error of layer 6 is 0.25605687499046326.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 165.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.76761245727539.\n",
            "The relative quantization error of layer 7 is 0.27511054277420044.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 384.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.387771606445312.\n",
            "The relative quantization error of layer 8 is 0.24303188920021057.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2022.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.53599739074707.\n",
            "The relative quantization error of layer 9 is 0.2016976773738861.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.605195045471191.\n",
            "The relative quantization error of layer 10 is 0.2623780369758606.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 220.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.03408432006836.\n",
            "The relative quantization error of layer 11 is 0.22441966831684113.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2189.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.889605522155762.\n",
            "The relative quantization error of layer 12 is 0.19956830143928528.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 580.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.425821304321289.\n",
            "The relative quantization error of layer 13 is 0.21022477746009827.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 58.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 52.16693878173828.\n",
            "The relative quantization error of layer 14 is 0.21866758167743683.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1642.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.794857025146484.\n",
            "The relative quantization error of layer 15 is 0.221403568983078.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2510.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.4022679328918457.\n",
            "The relative quantization error of layer 16 is 0.15605409443378448.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 645.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.832431793212891.\n",
            "The relative quantization error of layer 17 is 0.2214699536561966.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1656.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.147205352783203.\n",
            "The relative quantization error of layer 18 is 0.22078514099121094.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2620.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.887561559677124.\n",
            "The relative quantization error of layer 19 is 0.16980768740177155.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 579.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.243291854858398.\n",
            "The relative quantization error of layer 20 is 0.25600865483283997.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1486.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 13.062746047973633.\n",
            "The relative quantization error of layer 21 is 0.2238575518131256.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2528.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.673910617828369.\n",
            "The relative quantization error of layer 22 is 0.17168974876403809.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 653.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.237071990966797.\n",
            "The relative quantization error of layer 23 is 0.2489970624446869.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 796.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.590045928955078.\n",
            "The relative quantization error of layer 24 is 0.20762094855308533.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2178.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.9700608253479.\n",
            "The relative quantization error of layer 25 is 0.1502462923526764.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 974.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.530475616455078.\n",
            "The relative quantization error of layer 26 is 0.16808845102787018.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 258.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.043560028076172.\n",
            "The relative quantization error of layer 27 is 0.21119336783885956.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2259.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.860672473907471.\n",
            "The relative quantization error of layer 28 is 0.1667652428150177.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2927.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.949493944644928.\n",
            "The relative quantization error of layer 29 is 0.08727141469717026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1048.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.4153401851654053.\n",
            "The relative quantization error of layer 30 is 0.18479615449905396.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2118.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.828490734100342.\n",
            "The relative quantization error of layer 31 is 0.17189103364944458.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3019.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9952928423881531.\n",
            "The relative quantization error of layer 32 is 0.07889802753925323.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 915.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.5700113773345947.\n",
            "The relative quantization error of layer 33 is 0.19599232077598572.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1816.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.461388111114502.\n",
            "The relative quantization error of layer 34 is 0.16870494186878204.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2953.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9312578439712524.\n",
            "The relative quantization error of layer 35 is 0.07355241477489471.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 925.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.707246780395508.\n",
            "The relative quantization error of layer 36 is 0.22302067279815674.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2057.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.80889368057251.\n",
            "The relative quantization error of layer 37 is 0.1893104910850525.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3086.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9761892557144165.\n",
            "The relative quantization error of layer 38 is 0.07499618083238602.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 994.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4607083797454834.\n",
            "The relative quantization error of layer 39 is 0.2570689916610718.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2048.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.141964435577393.\n",
            "The relative quantization error of layer 40 is 0.19772064685821533.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2818.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9321746230125427.\n",
            "The relative quantization error of layer 41 is 0.07198654860258102.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1109.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4676547050476074.\n",
            "The relative quantization error of layer 42 is 0.25677981972694397.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1613.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.492868423461914.\n",
            "The relative quantization error of layer 43 is 0.20769797265529633.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3040.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9685949683189392.\n",
            "The relative quantization error of layer 44 is 0.05095415934920311.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1699.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.8892643451690674.\n",
            "The relative quantization error of layer 45 is 0.2236357480287552.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 615.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.520124912261963.\n",
            "The relative quantization error of layer 46 is 0.2572712004184723.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2253.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 8.22743034362793.\n",
            "The relative quantization error of layer 47 is 0.21038226783275604.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2439.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.27975815534591675.\n",
            "The relative quantization error of layer 48 is 0.0502958670258522.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1415.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3181146383285522.\n",
            "The relative quantization error of layer 49 is 0.29030609130859375.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2320.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.69991397857666.\n",
            "The relative quantization error of layer 50 is 0.18282341957092285.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2969.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.2717467248439789.\n",
            "The relative quantization error of layer 51 is 0.05730096250772476.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1583.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7281209230422974.\n",
            "The relative quantization error of layer 52 is 0.3007306456565857.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3288.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 16.76236343383789.\n",
            "The relative quantization error of layer 53 is 0.1200394481420517.\n",
            "\n",
            "Bits 8, Effective Quantized Bit Size: 8.89506285531785\n",
            "Bits 8, Quantized Test Accuracy: 0.9143\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 349.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 67.5791015625.\n",
            "The relative quantization error of layer 0 is 0.2783629596233368.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 149.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.893993377685547.\n",
            "The relative quantization error of layer 1 is 0.28075116872787476.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2686.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.481158256530762.\n",
            "The relative quantization error of layer 2 is 0.23356477916240692.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.823747634887695.\n",
            "The relative quantization error of layer 3 is 0.2956250011920929.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 182.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.735294342041016.\n",
            "The relative quantization error of layer 4 is 0.26998376846313477.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 418.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.41802406311035.\n",
            "The relative quantization error of layer 5 is 0.26406580209732056.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2728.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.407072067260742.\n",
            "The relative quantization error of layer 6 is 0.25258055329322815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 173.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.770540237426758.\n",
            "The relative quantization error of layer 7 is 0.27432504296302795.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 362.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.23208236694336.\n",
            "The relative quantization error of layer 8 is 0.23862722516059875.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2557.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.534883975982666.\n",
            "The relative quantization error of layer 9 is 0.2022222876548767.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 164.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.446812629699707.\n",
            "The relative quantization error of layer 10 is 0.2584906220436096.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 200.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 36.987213134765625.\n",
            "The relative quantization error of layer 11 is 0.22347749769687653.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2077.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.624211311340332.\n",
            "The relative quantization error of layer 12 is 0.1965578943490982.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 543.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.300722122192383.\n",
            "The relative quantization error of layer 13 is 0.20810319483280182.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 58.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 50.98981857299805.\n",
            "The relative quantization error of layer 14 is 0.21410128474235535.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1594.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.535849571228027.\n",
            "The relative quantization error of layer 15 is 0.21626634895801544.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3131.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.374582290649414.\n",
            "The relative quantization error of layer 16 is 0.15380597114562988.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 626.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.8374104499816895.\n",
            "The relative quantization error of layer 17 is 0.2237870693206787.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1444.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.876378059387207.\n",
            "The relative quantization error of layer 18 is 0.21733170747756958.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2547.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.890535831451416.\n",
            "The relative quantization error of layer 19 is 0.16705206036567688.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 581.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.220319747924805.\n",
            "The relative quantization error of layer 20 is 0.25487470626831055.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1634.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.629465103149414.\n",
            "The relative quantization error of layer 21 is 0.21705254912376404.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2338.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.687164306640625.\n",
            "The relative quantization error of layer 22 is 0.17205096781253815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 613.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.306229591369629.\n",
            "The relative quantization error of layer 23 is 0.2564045488834381.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1009.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.4952449798584.\n",
            "The relative quantization error of layer 24 is 0.20660896599292755.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2513.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 6.09122371673584.\n",
            "The relative quantization error of layer 25 is 0.15099158883094788.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1072.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.527340412139893.\n",
            "The relative quantization error of layer 26 is 0.16728372871875763.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 325.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.649995803833008.\n",
            "The relative quantization error of layer 27 is 0.20797401666641235.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2170.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 6.066375732421875.\n",
            "The relative quantization error of layer 28 is 0.17266173660755157.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2964.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9268618822097778.\n",
            "The relative quantization error of layer 29 is 0.08369789272546768.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1131.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.437309741973877.\n",
            "The relative quantization error of layer 30 is 0.18639154732227325.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2219.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.723237037658691.\n",
            "The relative quantization error of layer 31 is 0.16725754737854004.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2931.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9496426582336426.\n",
            "The relative quantization error of layer 32 is 0.07616996765136719.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1082.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.585386276245117.\n",
            "The relative quantization error of layer 33 is 0.19608823955059052.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2182.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.5186567306518555.\n",
            "The relative quantization error of layer 34 is 0.16830728948116302.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3179.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.886430561542511.\n",
            "The relative quantization error of layer 35 is 0.06960106641054153.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1075.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.7033703327178955.\n",
            "The relative quantization error of layer 36 is 0.22627770900726318.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2287.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.665965557098389.\n",
            "The relative quantization error of layer 37 is 0.186651811003685.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3141.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9354243278503418.\n",
            "The relative quantization error of layer 38 is 0.07371798902750015.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1060.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4347941875457764.\n",
            "The relative quantization error of layer 39 is 0.26344549655914307.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2218.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.081598281860352.\n",
            "The relative quantization error of layer 40 is 0.19535097479820251.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3205.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.91428142786026.\n",
            "The relative quantization error of layer 41 is 0.0760408416390419.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1139.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4411733150482178.\n",
            "The relative quantization error of layer 42 is 0.25610288977622986.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1611.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 7.960639953613281.\n",
            "The relative quantization error of layer 43 is 0.19278037548065186.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2721.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 1.0123097896575928.\n",
            "The relative quantization error of layer 44 is 0.05241803079843521.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1627.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.807657480239868.\n",
            "The relative quantization error of layer 45 is 0.21909523010253906.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 643.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.501081943511963.\n",
            "The relative quantization error of layer 46 is 0.2553962767124176.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2633.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.434414863586426.\n",
            "The relative quantization error of layer 47 is 0.18079306185245514.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3315.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.27515098452568054.\n",
            "The relative quantization error of layer 48 is 0.049798812717199326.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1681.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.2987293004989624.\n",
            "The relative quantization error of layer 49 is 0.2940298020839691.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2641.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.507728576660156.\n",
            "The relative quantization error of layer 50 is 0.19710762798786163.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3216.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.2804052233695984.\n",
            "The relative quantization error of layer 51 is 0.0595744326710701.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1587.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.6839590072631836.\n",
            "The relative quantization error of layer 52 is 0.2967933118343353.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3223.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.679965019226074.\n",
            "The relative quantization error of layer 53 is 0.1105920746922493.\n",
            "\n",
            "Bits 10, Effective Quantized Bit Size: 10.678960897743371\n",
            "Bits 10, Quantized Test Accuracy: 0.914\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 321.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 65.40019226074219.\n",
            "The relative quantization error of layer 0 is 0.2758146822452545.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 200.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.796586990356445.\n",
            "The relative quantization error of layer 1 is 0.2793440818786621.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2650.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 13.966946601867676.\n",
            "The relative quantization error of layer 2 is 0.22150851786136627.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 28.113544464111328.\n",
            "The relative quantization error of layer 3 is 0.2999458909034729.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 43.90213394165039.\n",
            "The relative quantization error of layer 4 is 0.26509007811546326.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 421.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.377904891967773.\n",
            "The relative quantization error of layer 5 is 0.261153906583786.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1984.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.334124565124512.\n",
            "The relative quantization error of layer 6 is 0.25187960267066956.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.9384765625.\n",
            "The relative quantization error of layer 7 is 0.27835237979888916.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 414.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.455305099487305.\n",
            "The relative quantization error of layer 8 is 0.2412775307893753.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2744.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.504101753234863.\n",
            "The relative quantization error of layer 9 is 0.20060478150844574.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.664210319519043.\n",
            "The relative quantization error of layer 10 is 0.26294732093811035.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 220.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.331787109375.\n",
            "The relative quantization error of layer 11 is 0.22653162479400635.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2026.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.797378540039062.\n",
            "The relative quantization error of layer 12 is 0.1985306292772293.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 477.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.356789588928223.\n",
            "The relative quantization error of layer 13 is 0.2102152556180954.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 52.245487213134766.\n",
            "The relative quantization error of layer 14 is 0.21876227855682373.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1389.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.468070983886719.\n",
            "The relative quantization error of layer 15 is 0.2150515466928482.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2729.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.608414888381958.\n",
            "The relative quantization error of layer 16 is 0.1642247587442398.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 616.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.959195137023926.\n",
            "The relative quantization error of layer 17 is 0.22852164506912231.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1605.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.875823974609375.\n",
            "The relative quantization error of layer 18 is 0.21741952002048492.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2859.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.872476100921631.\n",
            "The relative quantization error of layer 19 is 0.16929017007350922.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 617.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.252895355224609.\n",
            "The relative quantization error of layer 20 is 0.2559804618358612.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1537.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.784300804138184.\n",
            "The relative quantization error of layer 21 is 0.22061625123023987.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2805.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.734541654586792.\n",
            "The relative quantization error of layer 22 is 0.1753600835800171.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 610.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.286747455596924.\n",
            "The relative quantization error of layer 23 is 0.2559906840324402.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1039.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.59522247314453.\n",
            "The relative quantization error of layer 24 is 0.20841649174690247.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2690.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.84322452545166.\n",
            "The relative quantization error of layer 25 is 0.14750546216964722.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1144.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.586204528808594.\n",
            "The relative quantization error of layer 26 is 0.1688024401664734.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 325.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.75748062133789.\n",
            "The relative quantization error of layer 27 is 0.20836201310157776.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2193.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.871792316436768.\n",
            "The relative quantization error of layer 28 is 0.16725948452949524.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3363.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9405384659767151.\n",
            "The relative quantization error of layer 29 is 0.08486124128103256.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1136.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.3982770442962646.\n",
            "The relative quantization error of layer 30 is 0.18355980515480042.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2302.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.927316188812256.\n",
            "The relative quantization error of layer 31 is 0.1771688312292099.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3253.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9835244417190552.\n",
            "The relative quantization error of layer 32 is 0.07937844097614288.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1178.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.5568928718566895.\n",
            "The relative quantization error of layer 33 is 0.19408747553825378.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2195.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.45727014541626.\n",
            "The relative quantization error of layer 34 is 0.16645771265029907.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2964.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9289849400520325.\n",
            "The relative quantization error of layer 35 is 0.07342204451560974.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1098.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.682379722595215.\n",
            "The relative quantization error of layer 36 is 0.22238655388355255.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2170.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.660628318786621.\n",
            "The relative quantization error of layer 37 is 0.18506623804569244.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3105.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9597732424736023.\n",
            "The relative quantization error of layer 38 is 0.07231036573648453.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1071.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.489063262939453.\n",
            "The relative quantization error of layer 39 is 0.2662203311920166.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2261.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.109858989715576.\n",
            "The relative quantization error of layer 40 is 0.19441236555576324.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3003.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9210193753242493.\n",
            "The relative quantization error of layer 41 is 0.07245946675539017.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1142.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4768214225769043.\n",
            "The relative quantization error of layer 42 is 0.25890013575553894.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1650.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.301016807556152.\n",
            "The relative quantization error of layer 43 is 0.20113509893417358.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2964.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9364233613014221.\n",
            "The relative quantization error of layer 44 is 0.051276080310344696.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1662.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.9448962211608887.\n",
            "The relative quantization error of layer 45 is 0.222906231880188.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 630.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.6093621253967285.\n",
            "The relative quantization error of layer 46 is 0.25841158628463745.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2568.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.583783149719238.\n",
            "The relative quantization error of layer 47 is 0.19087567925453186.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3124.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2806944251060486.\n",
            "The relative quantization error of layer 48 is 0.05090896040201187.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1439.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.314858078956604.\n",
            "The relative quantization error of layer 49 is 0.2930433750152588.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2534.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.438488006591797.\n",
            "The relative quantization error of layer 50 is 0.1967068463563919.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3129.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.2763707637786865.\n",
            "The relative quantization error of layer 51 is 0.06005309894680977.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1671.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.730786681175232.\n",
            "The relative quantization error of layer 52 is 0.3053918480873108.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2943.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 14.051019668579102.\n",
            "The relative quantization error of layer 53 is 0.09901251643896103.\n",
            "\n",
            "Bits 12, Effective Quantized Bit Size: 12.217169776490145\n",
            "Bits 12, Quantized Test Accuracy: 0.9124\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 300.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 66.77061462402344.\n",
            "The relative quantization error of layer 0 is 0.27911266684532166.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 154.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.98423957824707.\n",
            "The relative quantization error of layer 1 is 0.28222525119781494.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2369.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.726472854614258.\n",
            "The relative quantization error of layer 2 is 0.23269961774349213.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 172.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.755056381225586.\n",
            "The relative quantization error of layer 3 is 0.29620110988616943.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.38374710083008.\n",
            "The relative quantization error of layer 4 is 0.26917704939842224.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 409.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.06900405883789.\n",
            "The relative quantization error of layer 5 is 0.26095476746559143.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2420.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.008901596069336.\n",
            "The relative quantization error of layer 6 is 0.24287977814674377.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 183.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.610050201416016.\n",
            "The relative quantization error of layer 7 is 0.2732417583465576.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 411.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.102737426757812.\n",
            "The relative quantization error of layer 8 is 0.23880848288536072.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2168.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.451847553253174.\n",
            "The relative quantization error of layer 9 is 0.20118866860866547.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 181.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.74429988861084.\n",
            "The relative quantization error of layer 10 is 0.26252755522727966.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 198.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.44575500488281.\n",
            "The relative quantization error of layer 11 is 0.22643762826919556.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1362.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.781885147094727.\n",
            "The relative quantization error of layer 12 is 0.199377179145813.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 355.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.395288467407227.\n",
            "The relative quantization error of layer 13 is 0.20986288785934448.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 58.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 50.89189910888672.\n",
            "The relative quantization error of layer 14 is 0.212569460272789.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1423.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.457220077514648.\n",
            "The relative quantization error of layer 15 is 0.21416319906711578.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2864.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.3332602977752686.\n",
            "The relative quantization error of layer 16 is 0.15037719905376434.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 634.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.948545932769775.\n",
            "The relative quantization error of layer 17 is 0.227260023355484.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1376.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.954641342163086.\n",
            "The relative quantization error of layer 18 is 0.21875952184200287.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2665.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8976736068725586.\n",
            "The relative quantization error of layer 19 is 0.16939115524291992.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 636.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.305532455444336.\n",
            "The relative quantization error of layer 20 is 0.25717535614967346.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1448.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 13.045855522155762.\n",
            "The relative quantization error of layer 21 is 0.22488193213939667.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2943.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.628835678100586.\n",
            "The relative quantization error of layer 22 is 0.1691770702600479.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 613.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.218141555786133.\n",
            "The relative quantization error of layer 23 is 0.2521107494831085.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 919.03it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.31011199951172.\n",
            "The relative quantization error of layer 24 is 0.20508885383605957.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2159.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 6.010305881500244.\n",
            "The relative quantization error of layer 25 is 0.14984144270420074.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1022.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.5100483894348145.\n",
            "The relative quantization error of layer 26 is 0.16889235377311707.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 306.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.939659118652344.\n",
            "The relative quantization error of layer 27 is 0.2099941074848175.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1801.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.865001678466797.\n",
            "The relative quantization error of layer 28 is 0.16716782748699188.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2806.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9312437772750854.\n",
            "The relative quantization error of layer 29 is 0.08473172038793564.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1161.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.4299910068511963.\n",
            "The relative quantization error of layer 30 is 0.18627361953258514.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2182.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.723433494567871.\n",
            "The relative quantization error of layer 31 is 0.16995763778686523.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3074.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9636738300323486.\n",
            "The relative quantization error of layer 32 is 0.07815038412809372.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1087.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.4973318576812744.\n",
            "The relative quantization error of layer 33 is 0.19132311642169952.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2152.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.579824447631836.\n",
            "The relative quantization error of layer 34 is 0.1712048500776291.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2729.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.8782848715782166.\n",
            "The relative quantization error of layer 35 is 0.0702793300151825.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1118.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.7308216094970703.\n",
            "The relative quantization error of layer 36 is 0.2275633066892624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2271.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.6655802726745605.\n",
            "The relative quantization error of layer 37 is 0.18885937333106995.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3130.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9347338676452637.\n",
            "The relative quantization error of layer 38 is 0.07038641721010208.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1164.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4461374282836914.\n",
            "The relative quantization error of layer 39 is 0.2574213743209839.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2036.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.098442554473877.\n",
            "The relative quantization error of layer 40 is 0.19516225159168243.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3034.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9292933344841003.\n",
            "The relative quantization error of layer 41 is 0.07110618054866791.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1227.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.471196413040161.\n",
            "The relative quantization error of layer 42 is 0.2562352120876312.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1649.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.254206657409668.\n",
            "The relative quantization error of layer 43 is 0.197673037648201.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2820.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9625094532966614.\n",
            "The relative quantization error of layer 44 is 0.05167181417346001.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1606.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.8509275913238525.\n",
            "The relative quantization error of layer 45 is 0.22835251688957214.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 586.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.4400129318237305.\n",
            "The relative quantization error of layer 46 is 0.2598184049129486.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:01<00:00, 1797.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 8.107464790344238.\n",
            "The relative quantization error of layer 47 is 0.1991916298866272.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2952.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2699119746685028.\n",
            "The relative quantization error of layer 48 is 0.048352498561143875.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1188.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3144773244857788.\n",
            "The relative quantization error of layer 49 is 0.295899361371994.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2928.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.856047630310059.\n",
            "The relative quantization error of layer 50 is 0.18908458948135376.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3168.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.28911682963371277.\n",
            "The relative quantization error of layer 51 is 0.06236155331134796.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1435.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.6687569618225098.\n",
            "The relative quantization error of layer 52 is 0.29629793763160706.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2864.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.574912071228027.\n",
            "The relative quantization error of layer 53 is 0.11147034168243408.\n",
            "\n",
            "Bits 14, Effective Quantized Bit Size: 13.975917698864691\n",
            "Bits 14, Quantized Test Accuracy: 0.9147\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 245.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 68.07254028320312.\n",
            "The relative quantization error of layer 0 is 0.27894407510757446.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 174.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.484153747558594.\n",
            "The relative quantization error of layer 1 is 0.2772439420223236.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2219.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.34116268157959.\n",
            "The relative quantization error of layer 2 is 0.22776012122631073.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 158.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.3858585357666.\n",
            "The relative quantization error of layer 3 is 0.29108476638793945.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 175.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.318607330322266.\n",
            "The relative quantization error of layer 4 is 0.2688223421573639.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 381.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.147106170654297.\n",
            "The relative quantization error of layer 5 is 0.26046422123908997.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2624.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.343317031860352.\n",
            "The relative quantization error of layer 6 is 0.25350651144981384.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 169.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.524860382080078.\n",
            "The relative quantization error of layer 7 is 0.2722902297973633.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 365.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.259647369384766.\n",
            "The relative quantization error of layer 8 is 0.23983334004878998.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2334.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.490443229675293.\n",
            "The relative quantization error of layer 9 is 0.20078536868095398.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 186.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.438080787658691.\n",
            "The relative quantization error of layer 10 is 0.25704681873321533.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 216.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.20700454711914.\n",
            "The relative quantization error of layer 11 is 0.2250474989414215.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2125.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.460317611694336.\n",
            "The relative quantization error of layer 12 is 0.19461868703365326.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 510.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.509775161743164.\n",
            "The relative quantization error of layer 13 is 0.21245510876178741.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.3310432434082.\n",
            "The relative quantization error of layer 14 is 0.21612827479839325.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1661.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.427926063537598.\n",
            "The relative quantization error of layer 15 is 0.21604220569133759.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3268.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.390751361846924.\n",
            "The relative quantization error of layer 16 is 0.1523837149143219.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 641.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.862573623657227.\n",
            "The relative quantization error of layer 17 is 0.22406259179115295.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1759.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.925914764404297.\n",
            "The relative quantization error of layer 18 is 0.21709328889846802.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3212.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8622190952301025.\n",
            "The relative quantization error of layer 19 is 0.16819682717323303.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 686.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.19971227645874.\n",
            "The relative quantization error of layer 20 is 0.2523166239261627.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1692.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.820433616638184.\n",
            "The relative quantization error of layer 21 is 0.2210533320903778.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3074.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.677424907684326.\n",
            "The relative quantization error of layer 22 is 0.17132170498371124.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 645.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.31607723236084.\n",
            "The relative quantization error of layer 23 is 0.25360414385795593.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1084.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.859092712402344.\n",
            "The relative quantization error of layer 24 is 0.21059438586235046.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2945.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.93804407119751.\n",
            "The relative quantization error of layer 25 is 0.14898188412189484.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1154.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.650816440582275.\n",
            "The relative quantization error of layer 26 is 0.1720600724220276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 340.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.869417190551758.\n",
            "The relative quantization error of layer 27 is 0.20930516719818115.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2284.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.754580974578857.\n",
            "The relative quantization error of layer 28 is 0.16405744850635529.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3317.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.8734707832336426.\n",
            "The relative quantization error of layer 29 is 0.081370510160923.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1186.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.3993537425994873.\n",
            "The relative quantization error of layer 30 is 0.18364353477954865.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2347.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.800890922546387.\n",
            "The relative quantization error of layer 31 is 0.17180486023426056.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3382.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9238208532333374.\n",
            "The relative quantization error of layer 32 is 0.07813439518213272.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1190.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.552919387817383.\n",
            "The relative quantization error of layer 33 is 0.19504263997077942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2365.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.3213419914245605.\n",
            "The relative quantization error of layer 34 is 0.16197547316551208.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3433.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9461667537689209.\n",
            "The relative quantization error of layer 35 is 0.07475534826517105.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1179.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.6375198364257812.\n",
            "The relative quantization error of layer 36 is 0.21806176006793976.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2380.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.665171146392822.\n",
            "The relative quantization error of layer 37 is 0.18620644509792328.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3189.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9312778115272522.\n",
            "The relative quantization error of layer 38 is 0.07145436108112335.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 861.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.414842128753662.\n",
            "The relative quantization error of layer 39 is 0.2563689053058624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1773.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.026147842407227.\n",
            "The relative quantization error of layer 40 is 0.19130538403987885.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2929.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9023817181587219.\n",
            "The relative quantization error of layer 41 is 0.07119540125131607.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1096.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4350244998931885.\n",
            "The relative quantization error of layer 42 is 0.25624269247055054.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1287.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.096986770629883.\n",
            "The relative quantization error of layer 43 is 0.19390957057476044.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2703.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9450019001960754.\n",
            "The relative quantization error of layer 44 is 0.05302724242210388.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1549.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.7696306705474854.\n",
            "The relative quantization error of layer 45 is 0.2112804502248764.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 614.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.470032215118408.\n",
            "The relative quantization error of layer 46 is 0.25299298763275146.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2071.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.528444290161133.\n",
            "The relative quantization error of layer 47 is 0.19027847051620483.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2573.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2878647744655609.\n",
            "The relative quantization error of layer 48 is 0.052447330206632614.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1516.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3316423892974854.\n",
            "The relative quantization error of layer 49 is 0.2941994369029999.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2656.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.050153732299805.\n",
            "The relative quantization error of layer 50 is 0.1840846687555313.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2972.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.29498782753944397.\n",
            "The relative quantization error of layer 51 is 0.061077557504177094.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1548.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7330825328826904.\n",
            "The relative quantization error of layer 52 is 0.29926934838294983.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3115.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 13.844778060913086.\n",
            "The relative quantization error of layer 53 is 0.10079392045736313.\n",
            "\n",
            "Bits 16, Effective Quantized Bit Size: 15.867986018527738\n",
            "Bits 16, Quantized Test Accuracy: 0.9142\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 234.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 65.65751647949219.\n",
            "The relative quantization error of layer 0 is 0.2754625380039215.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 148.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.140785217285156.\n",
            "The relative quantization error of layer 1 is 0.2825686037540436.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2254.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 13.986091613769531.\n",
            "The relative quantization error of layer 2 is 0.2239670753479004.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.97068214416504.\n",
            "The relative quantization error of layer 3 is 0.2988221347332001.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.007537841796875.\n",
            "The relative quantization error of layer 4 is 0.2666734755039215.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 374.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.0682373046875.\n",
            "The relative quantization error of layer 5 is 0.2599110007286072.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2388.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.275634765625.\n",
            "The relative quantization error of layer 6 is 0.2539018392562866.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.649059295654297.\n",
            "The relative quantization error of layer 7 is 0.2734251916408539.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 431.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.1500301361084.\n",
            "The relative quantization error of layer 8 is 0.23907014727592468.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 3034.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.381594181060791.\n",
            "The relative quantization error of layer 9 is 0.1966056078672409.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 190.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.429309844970703.\n",
            "The relative quantization error of layer 10 is 0.2581915557384491.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 224.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.0289421081543.\n",
            "The relative quantization error of layer 11 is 0.22361744940280914.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2212.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.898362159729004.\n",
            "The relative quantization error of layer 12 is 0.19916124641895294.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 652.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.393691062927246.\n",
            "The relative quantization error of layer 13 is 0.21078556776046753.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 60.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.777217864990234.\n",
            "The relative quantization error of layer 14 is 0.21724990010261536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1737.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.280596733093262.\n",
            "The relative quantization error of layer 15 is 0.21100202202796936.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3384.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.3215744495391846.\n",
            "The relative quantization error of layer 16 is 0.15099966526031494.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 671.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.917016506195068.\n",
            "The relative quantization error of layer 17 is 0.22559578716754913.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1725.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.765260696411133.\n",
            "The relative quantization error of layer 18 is 0.2158968448638916.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3190.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8310165405273438.\n",
            "The relative quantization error of layer 19 is 0.16641023755073547.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 665.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.194932460784912.\n",
            "The relative quantization error of layer 20 is 0.25217360258102417.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1717.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.918007850646973.\n",
            "The relative quantization error of layer 21 is 0.22231166064739227.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3120.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.6856791973114014.\n",
            "The relative quantization error of layer 22 is 0.1721540242433548.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 660.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.221061706542969.\n",
            "The relative quantization error of layer 23 is 0.2532261610031128.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1097.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.217403411865234.\n",
            "The relative quantization error of layer 24 is 0.20335270464420319.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2943.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.906774520874023.\n",
            "The relative quantization error of layer 25 is 0.1459963470697403.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1160.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.573601722717285.\n",
            "The relative quantization error of layer 26 is 0.17074857652187347.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 338.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.139673233032227.\n",
            "The relative quantization error of layer 27 is 0.21172389388084412.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2316.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.881163120269775.\n",
            "The relative quantization error of layer 28 is 0.16828860342502594.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3372.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9032078981399536.\n",
            "The relative quantization error of layer 29 is 0.08106732368469238.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1153.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.37103533744812.\n",
            "The relative quantization error of layer 30 is 0.1815652698278427.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2363.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.717304229736328.\n",
            "The relative quantization error of layer 31 is 0.17012576758861542.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3126.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9494989514350891.\n",
            "The relative quantization error of layer 32 is 0.07780031114816666.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1172.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.5438289642333984.\n",
            "The relative quantization error of layer 33 is 0.1947033554315567.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2326.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.357813835144043.\n",
            "The relative quantization error of layer 34 is 0.16522321105003357.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3493.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.8869593739509583.\n",
            "The relative quantization error of layer 35 is 0.07104022055864334.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1189.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.700679063796997.\n",
            "The relative quantization error of layer 36 is 0.21948470175266266.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2303.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.554923057556152.\n",
            "The relative quantization error of layer 37 is 0.1823786497116089.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3455.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9475399255752563.\n",
            "The relative quantization error of layer 38 is 0.07075762003660202.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1177.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.402273416519165.\n",
            "The relative quantization error of layer 39 is 0.25779885053634644.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2367.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.116293907165527.\n",
            "The relative quantization error of layer 40 is 0.19444890320301056.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3459.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9334408044815063.\n",
            "The relative quantization error of layer 41 is 0.07379382848739624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1178.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4499216079711914.\n",
            "The relative quantization error of layer 42 is 0.2574135661125183.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1726.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.058727264404297.\n",
            "The relative quantization error of layer 43 is 0.19089864194393158.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3236.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 1.005155324935913.\n",
            "The relative quantization error of layer 44 is 0.054576724767684937.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1520.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.927042007446289.\n",
            "The relative quantization error of layer 45 is 0.2241395115852356.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 661.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.489178657531738.\n",
            "The relative quantization error of layer 46 is 0.2591841518878937.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2968.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.777307033538818.\n",
            "The relative quantization error of layer 47 is 0.19565819203853607.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3568.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.29181912541389465.\n",
            "The relative quantization error of layer 48 is 0.0517645999789238.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1758.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3246326446533203.\n",
            "The relative quantization error of layer 49 is 0.2934936285018921.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3060.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.34218978881836.\n",
            "The relative quantization error of layer 50 is 0.19576290249824524.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3577.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.31338053941726685.\n",
            "The relative quantization error of layer 51 is 0.06481579691171646.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1756.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7104040384292603.\n",
            "The relative quantization error of layer 52 is 0.29889512062072754.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3392.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 14.45854663848877.\n",
            "The relative quantization error of layer 53 is 0.10392245650291443.\n",
            "\n",
            "Bits 18, Effective Quantized Bit Size: 17.543419916684954\n",
            "Bits 18, Quantized Test Accuracy: 0.9134\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 367.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 64.69779205322266.\n",
            "The relative quantization error of layer 0 is 0.2709698975086212.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 182.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.689071655273438.\n",
            "The relative quantization error of layer 1 is 0.2792806029319763.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2734.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.727852821350098.\n",
            "The relative quantization error of layer 2 is 0.23535598814487457.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 28.059146881103516.\n",
            "The relative quantization error of layer 3 is 0.29912787675857544.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 192.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 45.06865692138672.\n",
            "The relative quantization error of layer 4 is 0.2714522182941437.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 423.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.323932647705078.\n",
            "The relative quantization error of layer 5 is 0.2603786885738373.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2832.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.58385944366455.\n",
            "The relative quantization error of layer 6 is 0.2564644515514374.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 191.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.834917068481445.\n",
            "The relative quantization error of layer 7 is 0.2755926847457886.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 428.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.632108688354492.\n",
            "The relative quantization error of layer 8 is 0.24375560879707336.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2964.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.455171585083008.\n",
            "The relative quantization error of layer 9 is 0.1992930918931961.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 194.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.602595329284668.\n",
            "The relative quantization error of layer 10 is 0.26339924335479736.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 226.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.469051361083984.\n",
            "The relative quantization error of layer 11 is 0.22660431265830994.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2282.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 13.073025703430176.\n",
            "The relative quantization error of layer 12 is 0.20360493659973145.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 658.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.518282890319824.\n",
            "The relative quantization error of layer 13 is 0.21173052489757538.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 60.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 52.57589340209961.\n",
            "The relative quantization error of layer 14 is 0.22128821909427643.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1623.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.21489143371582.\n",
            "The relative quantization error of layer 15 is 0.21014267206192017.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3132.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.40387225151062.\n",
            "The relative quantization error of layer 16 is 0.15379659831523895.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 675.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.834323883056641.\n",
            "The relative quantization error of layer 17 is 0.22417527437210083.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1757.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.09123420715332.\n",
            "The relative quantization error of layer 18 is 0.22030213475227356.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3156.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.9423434734344482.\n",
            "The relative quantization error of layer 19 is 0.17161427438259125.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 660.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.311043739318848.\n",
            "The relative quantization error of layer 20 is 0.25829893350601196.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1755.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.948535919189453.\n",
            "The relative quantization error of layer 21 is 0.22285597026348114.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3215.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.6912307739257812.\n",
            "The relative quantization error of layer 22 is 0.171346515417099.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 576.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.269643306732178.\n",
            "The relative quantization error of layer 23 is 0.2589750289916992.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1114.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.634429931640625.\n",
            "The relative quantization error of layer 24 is 0.20735707879066467.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2849.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.981052875518799.\n",
            "The relative quantization error of layer 25 is 0.1507522314786911.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1132.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.556570053100586.\n",
            "The relative quantization error of layer 26 is 0.169817253947258.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 342.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.157058715820312.\n",
            "The relative quantization error of layer 27 is 0.21287478506565094.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2351.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 6.070718288421631.\n",
            "The relative quantization error of layer 28 is 0.17336389422416687.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3372.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9030831456184387.\n",
            "The relative quantization error of layer 29 is 0.08254783600568771.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1196.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.3998935222625732.\n",
            "The relative quantization error of layer 30 is 0.1815686970949173.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2377.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.894844055175781.\n",
            "The relative quantization error of layer 31 is 0.17411884665489197.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3237.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9592757821083069.\n",
            "The relative quantization error of layer 32 is 0.07819429785013199.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1175.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.588280439376831.\n",
            "The relative quantization error of layer 33 is 0.1959390491247177.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2197.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.416419982910156.\n",
            "The relative quantization error of layer 34 is 0.16397415101528168.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2837.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9158772826194763.\n",
            "The relative quantization error of layer 35 is 0.0720018744468689.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1159.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.640669822692871.\n",
            "The relative quantization error of layer 36 is 0.22260089218616486.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2200.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.841343402862549.\n",
            "The relative quantization error of layer 37 is 0.19291192293167114.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3051.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9505324959754944.\n",
            "The relative quantization error of layer 38 is 0.07246430218219757.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1085.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4729621410369873.\n",
            "The relative quantization error of layer 39 is 0.2681536078453064.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1333.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.242758750915527.\n",
            "The relative quantization error of layer 40 is 0.199248805642128.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3223.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9415509700775146.\n",
            "The relative quantization error of layer 41 is 0.07429125159978867.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1134.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4670584201812744.\n",
            "The relative quantization error of layer 42 is 0.2614162862300873.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1633.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.049817085266113.\n",
            "The relative quantization error of layer 43 is 0.19353295862674713.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 2130.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9994252920150757.\n",
            "The relative quantization error of layer 44 is 0.053692933171987534.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1204.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.786022424697876.\n",
            "The relative quantization error of layer 45 is 0.2179064154624939.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 596.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.527774333953857.\n",
            "The relative quantization error of layer 46 is 0.259565532207489.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2078.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.481297016143799.\n",
            "The relative quantization error of layer 47 is 0.19550786912441254.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 2226.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.26031938195228577.\n",
            "The relative quantization error of layer 48 is 0.04696028679609299.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1520.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3153257369995117.\n",
            "The relative quantization error of layer 49 is 0.2891545295715332.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2995.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.583680152893066.\n",
            "The relative quantization error of layer 50 is 0.178556427359581.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 1954.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.27868008613586426.\n",
            "The relative quantization error of layer 51 is 0.061993736773729324.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1480.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7541265487670898.\n",
            "The relative quantization error of layer 52 is 0.30692076683044434.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3072.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.681166648864746.\n",
            "The relative quantization error of layer 53 is 0.11185207217931747.\n",
            "\n",
            "Bits 20, Effective Quantized Bit Size: 18.634776765219545\n",
            "Bits 20, Quantized Test Accuracy: 0.9127\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 316.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 66.83578491210938.\n",
            "The relative quantization error of layer 0 is 0.2731267511844635.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 200.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.309226989746094.\n",
            "The relative quantization error of layer 1 is 0.2832348942756653.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2601.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.553887367248535.\n",
            "The relative quantization error of layer 2 is 0.23369349539279938.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 185.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.89375114440918.\n",
            "The relative quantization error of layer 3 is 0.29724612832069397.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 185.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 43.984825134277344.\n",
            "The relative quantization error of layer 4 is 0.2669852077960968.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 424.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 28.991548538208008.\n",
            "The relative quantization error of layer 5 is 0.25898221135139465.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2865.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.204968452453613.\n",
            "The relative quantization error of layer 6 is 0.2482796013355255.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.907100677490234.\n",
            "The relative quantization error of layer 7 is 0.27685680985450745.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 427.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.20878791809082.\n",
            "The relative quantization error of layer 8 is 0.23838968575000763.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2861.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.412121772766113.\n",
            "The relative quantization error of layer 9 is 0.19711196422576904.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.380388259887695.\n",
            "The relative quantization error of layer 10 is 0.2572998106479645.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 221.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.188316345214844.\n",
            "The relative quantization error of layer 11 is 0.22354605793952942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2116.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 13.030019760131836.\n",
            "The relative quantization error of layer 12 is 0.20245008170604706.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 421.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.25588607788086.\n",
            "The relative quantization error of layer 13 is 0.20675034821033478.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 57.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.903377532958984.\n",
            "The relative quantization error of layer 14 is 0.21786698698997498.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1603.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.28836441040039.\n",
            "The relative quantization error of layer 15 is 0.2135717123746872.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2587.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.3738210201263428.\n",
            "The relative quantization error of layer 16 is 0.15365546941757202.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 504.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.86501407623291.\n",
            "The relative quantization error of layer 17 is 0.22463712096214294.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1563.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.880297660827637.\n",
            "The relative quantization error of layer 18 is 0.2184893935918808.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2706.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.7956056594848633.\n",
            "The relative quantization error of layer 19 is 0.1636248677968979.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 595.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.234147548675537.\n",
            "The relative quantization error of layer 20 is 0.2548147439956665.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1177.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.752083778381348.\n",
            "The relative quantization error of layer 21 is 0.22192847728729248.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2911.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.6685702800750732.\n",
            "The relative quantization error of layer 22 is 0.16885541379451752.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 595.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.266767978668213.\n",
            "The relative quantization error of layer 23 is 0.2531856596469879.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 980.07it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.335426330566406.\n",
            "The relative quantization error of layer 24 is 0.20591580867767334.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2623.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.937596797943115.\n",
            "The relative quantization error of layer 25 is 0.14875014126300812.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 875.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.654049396514893.\n",
            "The relative quantization error of layer 26 is 0.17114560306072235.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 321.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.845476150512695.\n",
            "The relative quantization error of layer 27 is 0.20966018736362457.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2064.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.822940826416016.\n",
            "The relative quantization error of layer 28 is 0.16477787494659424.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2812.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9198072552680969.\n",
            "The relative quantization error of layer 29 is 0.08348314464092255.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1019.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.4161853790283203.\n",
            "The relative quantization error of layer 30 is 0.18477296829223633.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2032.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.798328876495361.\n",
            "The relative quantization error of layer 31 is 0.1720266342163086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3072.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9975588917732239.\n",
            "The relative quantization error of layer 32 is 0.07925736159086227.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1047.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.54941725730896.\n",
            "The relative quantization error of layer 33 is 0.19135363399982452.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2015.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.437734127044678.\n",
            "The relative quantization error of layer 34 is 0.16519562900066376.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3149.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9014989137649536.\n",
            "The relative quantization error of layer 35 is 0.07185110449790955.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1093.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.6849453449249268.\n",
            "The relative quantization error of layer 36 is 0.22216296195983887.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2206.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.734018325805664.\n",
            "The relative quantization error of layer 37 is 0.1891144961118698.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3269.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9451019763946533.\n",
            "The relative quantization error of layer 38 is 0.07492469996213913.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1195.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.5016560554504395.\n",
            "The relative quantization error of layer 39 is 0.2674778401851654.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2399.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.111832141876221.\n",
            "The relative quantization error of layer 40 is 0.19297011196613312.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3373.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9288845062255859.\n",
            "The relative quantization error of layer 41 is 0.07344343513250351.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1151.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4621200561523438.\n",
            "The relative quantization error of layer 42 is 0.2566041648387909.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1705.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.21330451965332.\n",
            "The relative quantization error of layer 43 is 0.19773824512958527.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3039.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9735154509544373.\n",
            "The relative quantization error of layer 44 is 0.05401448905467987.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1685.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.941005229949951.\n",
            "The relative quantization error of layer 45 is 0.2245180308818817.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 641.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.595105171203613.\n",
            "The relative quantization error of layer 46 is 0.25706979632377625.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2531.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.893560886383057.\n",
            "The relative quantization error of layer 47 is 0.2006249725818634.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3007.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2674499750137329.\n",
            "The relative quantization error of layer 48 is 0.04898295924067497.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1736.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.298458456993103.\n",
            "The relative quantization error of layer 49 is 0.2875649034976959.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2996.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.893058776855469.\n",
            "The relative quantization error of layer 50 is 0.1921035796403885.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3529.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.28360632061958313.\n",
            "The relative quantization error of layer 51 is 0.059508971869945526.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1679.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7498270273208618.\n",
            "The relative quantization error of layer 52 is 0.30847111344337463.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3361.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 14.691946029663086.\n",
            "The relative quantization error of layer 53 is 0.10565538704395294.\n",
            "\n",
            "Bits 22, Effective Quantized Bit Size: 19.618338833278163\n",
            "Bits 22, Quantized Test Accuracy: 0.9141\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 261.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 69.44046020507812.\n",
            "The relative quantization error of layer 0 is 0.2777700424194336.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.031206130981445.\n",
            "The relative quantization error of layer 1 is 0.282002329826355.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2314.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.590605735778809.\n",
            "The relative quantization error of layer 2 is 0.23441193997859955.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 176.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 28.544082641601562.\n",
            "The relative quantization error of layer 3 is 0.3034030795097351.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 176.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.71052169799805.\n",
            "The relative quantization error of layer 4 is 0.27063944935798645.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 384.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.71154022216797.\n",
            "The relative quantization error of layer 5 is 0.2645803689956665.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2712.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.725312232971191.\n",
            "The relative quantization error of layer 6 is 0.2610897123813629.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 17.021833419799805.\n",
            "The relative quantization error of layer 7 is 0.2796478867530823.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 430.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.538320541381836.\n",
            "The relative quantization error of layer 8 is 0.24213196337223053.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2860.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.476452827453613.\n",
            "The relative quantization error of layer 9 is 0.20137526094913483.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.652176856994629.\n",
            "The relative quantization error of layer 10 is 0.26022759079933167.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 216.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.478267669677734.\n",
            "The relative quantization error of layer 11 is 0.22717122733592987.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2020.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.832377433776855.\n",
            "The relative quantization error of layer 12 is 0.1981697529554367.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 645.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.382965087890625.\n",
            "The relative quantization error of layer 13 is 0.20876319706439972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.450199127197266.\n",
            "The relative quantization error of layer 14 is 0.21625672280788422.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1589.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.772454261779785.\n",
            "The relative quantization error of layer 15 is 0.22243985533714294.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2892.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.4795775413513184.\n",
            "The relative quantization error of layer 16 is 0.15757706761360168.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 621.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.915143966674805.\n",
            "The relative quantization error of layer 17 is 0.2248794585466385.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1538.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.89968204498291.\n",
            "The relative quantization error of layer 18 is 0.21959099173545837.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2800.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.977813482284546.\n",
            "The relative quantization error of layer 19 is 0.17169421911239624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 661.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.308931350708008.\n",
            "The relative quantization error of layer 20 is 0.2583375871181488.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1652.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.918868064880371.\n",
            "The relative quantization error of layer 21 is 0.22265970706939697.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2888.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.7558321952819824.\n",
            "The relative quantization error of layer 22 is 0.17413754761219025.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 473.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.2074127197265625.\n",
            "The relative quantization error of layer 23 is 0.2471485286951065.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 891.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.91389274597168.\n",
            "The relative quantization error of layer 24 is 0.2101828008890152.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2778.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.948678493499756.\n",
            "The relative quantization error of layer 25 is 0.1489322930574417.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1143.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.667495250701904.\n",
            "The relative quantization error of layer 26 is 0.1735236793756485.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 327.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.960582733154297.\n",
            "The relative quantization error of layer 27 is 0.21055054664611816.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2236.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.964034557342529.\n",
            "The relative quantization error of layer 28 is 0.16866807639598846.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3217.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9054933786392212.\n",
            "The relative quantization error of layer 29 is 0.08399393409490585.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1155.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.469111442565918.\n",
            "The relative quantization error of layer 30 is 0.19021236896514893.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2275.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.922479629516602.\n",
            "The relative quantization error of layer 31 is 0.17624163627624512.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3347.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9906208515167236.\n",
            "The relative quantization error of layer 32 is 0.08068618178367615.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1141.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.525298595428467.\n",
            "The relative quantization error of layer 33 is 0.19250839948654175.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2260.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.464778900146484.\n",
            "The relative quantization error of layer 34 is 0.1667281687259674.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3099.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.9183169007301331.\n",
            "The relative quantization error of layer 35 is 0.07327117770910263.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1141.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.7262747287750244.\n",
            "The relative quantization error of layer 36 is 0.22417804598808289.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2299.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.782578468322754.\n",
            "The relative quantization error of layer 37 is 0.18820877373218536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3354.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9767950177192688.\n",
            "The relative quantization error of layer 38 is 0.07728543132543564.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1126.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.5426127910614014.\n",
            "The relative quantization error of layer 39 is 0.26892709732055664.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1475.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.195483684539795.\n",
            "The relative quantization error of layer 40 is 0.19535256922245026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2782.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9026920795440674.\n",
            "The relative quantization error of layer 41 is 0.07071509212255478.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 888.71it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4764328002929688.\n",
            "The relative quantization error of layer 42 is 0.25462958216667175.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1557.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.354670524597168.\n",
            "The relative quantization error of layer 43 is 0.1984790563583374.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3180.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9817653298377991.\n",
            "The relative quantization error of layer 44 is 0.05464779958128929.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1735.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.849575996398926.\n",
            "The relative quantization error of layer 45 is 0.2200777679681778.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 659.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.476746082305908.\n",
            "The relative quantization error of layer 46 is 0.25692641735076904.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2849.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.310512542724609.\n",
            "The relative quantization error of layer 47 is 0.18880914151668549.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3402.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2803455889225006.\n",
            "The relative quantization error of layer 48 is 0.05188702791929245.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1712.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.307727575302124.\n",
            "The relative quantization error of layer 49 is 0.29185494780540466.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2864.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.391095161437988.\n",
            "The relative quantization error of layer 50 is 0.2011757791042328.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3190.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.26781871914863586.\n",
            "The relative quantization error of layer 51 is 0.056415725499391556.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1621.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.752470850944519.\n",
            "The relative quantization error of layer 52 is 0.3059009909629822.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3447.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.941208839416504.\n",
            "The relative quantization error of layer 53 is 0.11776823550462723.\n",
            "\n",
            "Bits 24, Effective Quantized Bit Size: 19.857960186969496\n",
            "Bits 24, Quantized Test Accuracy: 0.9136\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 341.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 66.28570556640625.\n",
            "The relative quantization error of layer 0 is 0.278997004032135.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 213.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 31.10640525817871.\n",
            "The relative quantization error of layer 1 is 0.2810545861721039.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2681.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.529329299926758.\n",
            "The relative quantization error of layer 2 is 0.23125992715358734.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.31166648864746.\n",
            "The relative quantization error of layer 3 is 0.2901250422000885.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.66952896118164.\n",
            "The relative quantization error of layer 4 is 0.2702762186527252.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 427.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 28.99527931213379.\n",
            "The relative quantization error of layer 5 is 0.2583703100681305.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2221.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.52470874786377.\n",
            "The relative quantization error of layer 6 is 0.2534942924976349.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 190.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.7345027923584.\n",
            "The relative quantization error of layer 7 is 0.27363020181655884.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 374.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.181270599365234.\n",
            "The relative quantization error of layer 8 is 0.23601657152175903.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2352.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.613011360168457.\n",
            "The relative quantization error of layer 9 is 0.2015545517206192.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 180.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.459607124328613.\n",
            "The relative quantization error of layer 10 is 0.259067565202713.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 208.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 36.795692443847656.\n",
            "The relative quantization error of layer 11 is 0.22282877564430237.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2154.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.887516975402832.\n",
            "The relative quantization error of layer 12 is 0.20000578463077545.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 616.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.246661186218262.\n",
            "The relative quantization error of layer 13 is 0.20676851272583008.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 59.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 52.3065299987793.\n",
            "The relative quantization error of layer 14 is 0.220079243183136.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1571.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.521178245544434.\n",
            "The relative quantization error of layer 15 is 0.21690788865089417.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2990.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.4592878818511963.\n",
            "The relative quantization error of layer 16 is 0.1589118391275406.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 537.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.880530834197998.\n",
            "The relative quantization error of layer 17 is 0.2253706008195877.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1584.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.027960777282715.\n",
            "The relative quantization error of layer 18 is 0.21751317381858826.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2910.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.858349561691284.\n",
            "The relative quantization error of layer 19 is 0.16620075702667236.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 638.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.277024269104004.\n",
            "The relative quantization error of layer 20 is 0.25383123755455017.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1576.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.842900276184082.\n",
            "The relative quantization error of layer 21 is 0.22217023372650146.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3005.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.6767561435699463.\n",
            "The relative quantization error of layer 22 is 0.17148439586162567.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 646.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.239258766174316.\n",
            "The relative quantization error of layer 23 is 0.25225117802619934.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1060.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.404844284057617.\n",
            "The relative quantization error of layer 24 is 0.20474323630332947.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2741.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.853475570678711.\n",
            "The relative quantization error of layer 25 is 0.14720264077186584.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1168.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.5055389404296875.\n",
            "The relative quantization error of layer 26 is 0.16911226511001587.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 336.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.70071029663086.\n",
            "The relative quantization error of layer 27 is 0.2088124305009842.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2253.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.7983598709106445.\n",
            "The relative quantization error of layer 28 is 0.16656264662742615.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3143.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.8889641761779785.\n",
            "The relative quantization error of layer 29 is 0.08065169304609299.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1096.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.3361942768096924.\n",
            "The relative quantization error of layer 30 is 0.1779339611530304.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2244.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.838775634765625.\n",
            "The relative quantization error of layer 31 is 0.17231760919094086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3268.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.9475915431976318.\n",
            "The relative quantization error of layer 32 is 0.07683595269918442.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1140.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.441779375076294.\n",
            "The relative quantization error of layer 33 is 0.18732008337974548.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2202.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.4169602394104.\n",
            "The relative quantization error of layer 34 is 0.16457299888134003.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3119.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.8727083206176758.\n",
            "The relative quantization error of layer 35 is 0.06797882169485092.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1124.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.66424298286438.\n",
            "The relative quantization error of layer 36 is 0.2192240059375763.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2282.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.652348518371582.\n",
            "The relative quantization error of layer 37 is 0.18647649884223938.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3290.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9786794781684875.\n",
            "The relative quantization error of layer 38 is 0.07460261136293411.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1136.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.458466053009033.\n",
            "The relative quantization error of layer 39 is 0.2613222897052765.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1943.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 5.998556613922119.\n",
            "The relative quantization error of layer 40 is 0.19271089136600494.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2450.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9263327121734619.\n",
            "The relative quantization error of layer 41 is 0.07389868795871735.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1067.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.458307981491089.\n",
            "The relative quantization error of layer 42 is 0.2598845660686493.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1676.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.007808685302734.\n",
            "The relative quantization error of layer 43 is 0.1936889886856079.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3195.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9550800919532776.\n",
            "The relative quantization error of layer 44 is 0.04903959855437279.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1716.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.8490893840789795.\n",
            "The relative quantization error of layer 45 is 0.22202706336975098.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 658.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.579859733581543.\n",
            "The relative quantization error of layer 46 is 0.26189085841178894.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3079.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.852313995361328.\n",
            "The relative quantization error of layer 47 is 0.18651720881462097.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3649.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2821698784828186.\n",
            "The relative quantization error of layer 48 is 0.052826736122369766.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1702.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.3689721822738647.\n",
            "The relative quantization error of layer 49 is 0.2955760955810547.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3008.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.693342208862305.\n",
            "The relative quantization error of layer 50 is 0.18691259622573853.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3519.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.2739190459251404.\n",
            "The relative quantization error of layer 51 is 0.057765401899814606.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1679.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7407251596450806.\n",
            "The relative quantization error of layer 52 is 0.3079008460044861.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3437.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 13.195555686950684.\n",
            "The relative quantization error of layer 53 is 0.09420053660869598.\n",
            "\n",
            "Bits 26, Effective Quantized Bit Size: 20.15888002648885\n",
            "Bits 26, Quantized Test Accuracy: 0.9141\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 310.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 68.94013214111328.\n",
            "The relative quantization error of layer 0 is 0.2783334255218506.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 170.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.835735321044922.\n",
            "The relative quantization error of layer 1 is 0.28014469146728516.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2246.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.673439979553223.\n",
            "The relative quantization error of layer 2 is 0.23487311601638794.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 184.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 27.72486686706543.\n",
            "The relative quantization error of layer 3 is 0.29495736956596375.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 192.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.03126525878906.\n",
            "The relative quantization error of layer 4 is 0.2657588720321655.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 423.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.64542579650879.\n",
            "The relative quantization error of layer 5 is 0.26386603713035583.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2961.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.432438850402832.\n",
            "The relative quantization error of layer 6 is 0.2549346387386322.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 192.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.944108963012695.\n",
            "The relative quantization error of layer 7 is 0.2747010588645935.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 429.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.34238624572754.\n",
            "The relative quantization error of layer 8 is 0.2412445843219757.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2939.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.4625396728515625.\n",
            "The relative quantization error of layer 9 is 0.19930194318294525.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 187.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.584903717041016.\n",
            "The relative quantization error of layer 10 is 0.2609528601169586.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 224.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 37.354530334472656.\n",
            "The relative quantization error of layer 11 is 0.22648885846138.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2304.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.859529495239258.\n",
            "The relative quantization error of layer 12 is 0.20092707872390747.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 658.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.258648872375488.\n",
            "The relative quantization error of layer 13 is 0.20684784650802612.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 60.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.57866668701172.\n",
            "The relative quantization error of layer 14 is 0.21686552464962006.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1677.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.550466537475586.\n",
            "The relative quantization error of layer 15 is 0.22061887383460999.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3253.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.367387533187866.\n",
            "The relative quantization error of layer 16 is 0.15086036920547485.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 662.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.893728256225586.\n",
            "The relative quantization error of layer 17 is 0.22498869895935059.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1722.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.020474433898926.\n",
            "The relative quantization error of layer 18 is 0.2186485081911087.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3173.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.870321273803711.\n",
            "The relative quantization error of layer 19 is 0.16906476020812988.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 599.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.201316833496094.\n",
            "The relative quantization error of layer 20 is 0.2524048089981079.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1736.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 12.681051254272461.\n",
            "The relative quantization error of layer 21 is 0.21936753392219543.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3052.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.716033935546875.\n",
            "The relative quantization error of layer 22 is 0.17428451776504517.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 664.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.319602966308594.\n",
            "The relative quantization error of layer 23 is 0.25518614053726196.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1083.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.643266677856445.\n",
            "The relative quantization error of layer 24 is 0.20835167169570923.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2744.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 6.025705337524414.\n",
            "The relative quantization error of layer 25 is 0.14923211932182312.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 968.01it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.602414608001709.\n",
            "The relative quantization error of layer 26 is 0.17047974467277527.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 321.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 22.85554313659668.\n",
            "The relative quantization error of layer 27 is 0.21002359688282013.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2298.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.828932762145996.\n",
            "The relative quantization error of layer 28 is 0.16598817706108093.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3251.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.8942299485206604.\n",
            "The relative quantization error of layer 29 is 0.08254922181367874.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 999.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.412294387817383.\n",
            "The relative quantization error of layer 30 is 0.1856546401977539.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2099.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.881315231323242.\n",
            "The relative quantization error of layer 31 is 0.17253124713897705.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2974.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.999127209186554.\n",
            "The relative quantization error of layer 32 is 0.0799022912979126.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1053.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.4963061809539795.\n",
            "The relative quantization error of layer 33 is 0.19142462313175201.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2143.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.310250282287598.\n",
            "The relative quantization error of layer 34 is 0.16353844106197357.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2988.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.8812639713287354.\n",
            "The relative quantization error of layer 35 is 0.07005858421325684.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1087.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.668517589569092.\n",
            "The relative quantization error of layer 36 is 0.2231854796409607.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2133.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.598509788513184.\n",
            "The relative quantization error of layer 37 is 0.18447959423065186.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3222.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9871107339859009.\n",
            "The relative quantization error of layer 38 is 0.07794925570487976.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1126.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.482736110687256.\n",
            "The relative quantization error of layer 39 is 0.262700617313385.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2274.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 6.152976036071777.\n",
            "The relative quantization error of layer 40 is 0.19675534963607788.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3135.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.8883731365203857.\n",
            "The relative quantization error of layer 41 is 0.06919025629758835.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1110.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.4630320072174072.\n",
            "The relative quantization error of layer 42 is 0.25138893723487854.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1624.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.353169441223145.\n",
            "The relative quantization error of layer 43 is 0.19992156326770782.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2993.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 0.9445582628250122.\n",
            "The relative quantization error of layer 44 is 0.051197513937950134.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1659.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.83798885345459.\n",
            "The relative quantization error of layer 45 is 0.22086894512176514.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 641.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.506000518798828.\n",
            "The relative quantization error of layer 46 is 0.257755845785141.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2739.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 7.333980560302734.\n",
            "The relative quantization error of layer 47 is 0.1932886242866516.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3326.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.26569366455078125.\n",
            "The relative quantization error of layer 48 is 0.04905197396874428.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1638.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.2980910539627075.\n",
            "The relative quantization error of layer 49 is 0.292178750038147.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2945.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 11.341289520263672.\n",
            "The relative quantization error of layer 50 is 0.19489829242229462.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3315.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.24960146844387054.\n",
            "The relative quantization error of layer 51 is 0.05222790315747261.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1553.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7332050800323486.\n",
            "The relative quantization error of layer 52 is 0.29675039649009705.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2519.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 15.59621524810791.\n",
            "The relative quantization error of layer 53 is 0.11413415521383286.\n",
            "\n",
            "Bits 28, Effective Quantized Bit Size: 20.15888002648885\n",
            "Bits 28, Quantized Test Accuracy: 0.9141\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
            "Total number of layers to quantize 54\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 313.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 66.01620483398438.\n",
            "The relative quantization error of layer 0 is 0.2744791805744171.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 180.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 30.671056747436523.\n",
            "The relative quantization error of layer 1 is 0.2792748212814331.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1939.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 14.786314010620117.\n",
            "The relative quantization error of layer 2 is 0.23674160242080688.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 185.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 28.246673583984375.\n",
            "The relative quantization error of layer 3 is 0.30184149742126465.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 182.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 44.015193939208984.\n",
            "The relative quantization error of layer 4 is 0.26668858528137207.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 418.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 29.573772430419922.\n",
            "The relative quantization error of layer 5 is 0.2634851634502411.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2728.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 11.351916313171387.\n",
            "The relative quantization error of layer 6 is 0.2497984766960144.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 165.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 16.860706329345703.\n",
            "The relative quantization error of layer 7 is 0.27609190344810486.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 406.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 24.57322883605957.\n",
            "The relative quantization error of layer 8 is 0.24424883723258972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 53\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2240.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.694603443145752.\n",
            "The relative quantization error of layer 9 is 0.20733264088630676.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 177.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 11.479778289794922.\n",
            "The relative quantization error of layer 10 is 0.2558194696903229.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 224.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 36.91923522949219.\n",
            "The relative quantization error of layer 11 is 0.2233200967311859.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 1152])\n",
            "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2297.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.891426086425781.\n",
            "The relative quantization error of layer 12 is 0.20242135226726532.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 662.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 10.376002311706543.\n",
            "The relative quantization error of layer 13 is 0.20992104709148407.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 256])\n",
            "shape of quantized_layer_input: torch.Size([32896, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 60.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 51.908023834228516.\n",
            "The relative quantization error of layer 14 is 0.21728256344795227.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1638.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.513830184936523.\n",
            "The relative quantization error of layer 15 is 0.21652410924434662.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2683.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.5637800693511963.\n",
            "The relative quantization error of layer 16 is 0.15942969918251038.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 438.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 5.832118988037109.\n",
            "The relative quantization error of layer 17 is 0.22313401103019714.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1590.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.999146461486816.\n",
            "The relative quantization error of layer 18 is 0.22110891342163086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3123.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.965614080429077.\n",
            "The relative quantization error of layer 19 is 0.1698039323091507.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 658.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 5.294162750244141.\n",
            "The relative quantization error of layer 20 is 0.25608116388320923.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 21\n",
            "Quantization progress: 21 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1669.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 21 is 13.149007797241211.\n",
            "The relative quantization error of layer 21 is 0.22506937384605408.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 22\n",
            "Quantization progress: 22 out of 53\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2646.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 22 is 2.6737101078033447.\n",
            "The relative quantization error of layer 22 is 0.17223794758319855.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 23\n",
            "Quantization progress: 23 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 597.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 23 is 4.377931118011475.\n",
            "The relative quantization error of layer 23 is 0.26134422421455383.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 24\n",
            "Quantization progress: 24 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1063.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 24 is 20.71727180480957.\n",
            "The relative quantization error of layer 24 is 0.20915810763835907.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 25\n",
            "Quantization progress: 25 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 2304])\n",
            "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2741.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 25 is 5.981024265289307.\n",
            "The relative quantization error of layer 25 is 0.1483055204153061.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 26\n",
            "Quantization progress: 26 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1090.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 26 is 6.567160129547119.\n",
            "The relative quantization error of layer 26 is 0.16961388289928436.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 27\n",
            "Quantization progress: 27 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 512])\n",
            "shape of quantized_layer_input: torch.Size([8320, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 340.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 27 is 23.091480255126953.\n",
            "The relative quantization error of layer 27 is 0.21235916018486023.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 28\n",
            "Quantization progress: 28 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2368.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 28 is 5.831350326538086.\n",
            "The relative quantization error of layer 28 is 0.16587133705615997.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 29\n",
            "Quantization progress: 29 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3352.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 29 is 0.9144889712333679.\n",
            "The relative quantization error of layer 29 is 0.08346731215715408.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 30\n",
            "Quantization progress: 30 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1118.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 30 is 2.4429588317871094.\n",
            "The relative quantization error of layer 30 is 0.18866191804409027.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 31\n",
            "Quantization progress: 31 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1994.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 31 is 5.863757610321045.\n",
            "The relative quantization error of layer 31 is 0.17126904428005219.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 32\n",
            "Quantization progress: 32 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2999.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 32 is 0.962003767490387.\n",
            "The relative quantization error of layer 32 is 0.07863561809062958.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 33\n",
            "Quantization progress: 33 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1127.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 33 is 2.5520880222320557.\n",
            "The relative quantization error of layer 33 is 0.19352427124977112.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 34\n",
            "Quantization progress: 34 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2096.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 34 is 6.471096038818359.\n",
            "The relative quantization error of layer 34 is 0.1661047637462616.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 35\n",
            "Quantization progress: 35 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2595.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 35 is 0.8684490919113159.\n",
            "The relative quantization error of layer 35 is 0.0689118430018425.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 36\n",
            "Quantization progress: 36 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1135.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 36 is 2.693718910217285.\n",
            "The relative quantization error of layer 36 is 0.22315575182437897.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 37\n",
            "Quantization progress: 37 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2249.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 37 is 6.710750579833984.\n",
            "The relative quantization error of layer 37 is 0.18540208041667938.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 38\n",
            "Quantization progress: 38 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3438.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 38 is 0.9661288857460022.\n",
            "The relative quantization error of layer 38 is 0.07403946667909622.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 39\n",
            "Quantization progress: 39 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1153.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 39 is 2.4555916786193848.\n",
            "The relative quantization error of layer 39 is 0.2664467692375183.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 40\n",
            "Quantization progress: 40 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2378.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 40 is 5.886287689208984.\n",
            "The relative quantization error of layer 40 is 0.19036324322223663.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 41\n",
            "Quantization progress: 41 out of 53\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3456.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 41 is 0.9344785213470459.\n",
            "The relative quantization error of layer 41 is 0.07545974105596542.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 42\n",
            "Quantization progress: 42 out of 53\n",
            "\n",
            "shape of W: torch.Size([1024, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1155.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 42 is 2.450042963027954.\n",
            "The relative quantization error of layer 42 is 0.26154011487960815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 43\n",
            "Quantization progress: 43 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1700.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 43 is 8.07320499420166.\n",
            "The relative quantization error of layer 43 is 0.19429609179496765.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 44\n",
            "Quantization progress: 44 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 4608])\n",
            "shape of quantized_layer_input: torch.Size([384, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3123.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 44 is 1.0076210498809814.\n",
            "The relative quantization error of layer 44 is 0.05445387586951256.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 45\n",
            "Quantization progress: 45 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1640.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 45 is 2.838604211807251.\n",
            "The relative quantization error of layer 45 is 0.21942369639873505.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 46\n",
            "Quantization progress: 46 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 1024, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 1024])\n",
            "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 658.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 46 is 5.532769203186035.\n",
            "The relative quantization error of layer 46 is 0.25556519627571106.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 47\n",
            "Quantization progress: 47 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2285.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 47 is 8.002267837524414.\n",
            "The relative quantization error of layer 47 is 0.20006714761257172.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 48\n",
            "Quantization progress: 48 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3372.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 48 is 0.2653612792491913.\n",
            "The relative quantization error of layer 48 is 0.047254450619220734.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 49\n",
            "Quantization progress: 49 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1614.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 49 is 1.2724480628967285.\n",
            "The relative quantization error of layer 49 is 0.28676891326904297.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 50\n",
            "Quantization progress: 50 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 2048, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 2048])\n",
            "shape of quantized_layer_input: torch.Size([640, 2048])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2853.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 50 is 10.845529556274414.\n",
            "The relative quantization error of layer 50 is 0.18390560150146484.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 51\n",
            "Quantization progress: 51 out of 53\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3331.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 51 is 0.2801527678966522.\n",
            "The relative quantization error of layer 51 is 0.058402493596076965.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 52\n",
            "Quantization progress: 52 out of 53\n",
            "\n",
            "shape of W: torch.Size([2048, 512, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([640, 512])\n",
            "shape of quantized_layer_input: torch.Size([640, 512])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1425.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 52 is 1.7818130254745483.\n",
            "The relative quantization error of layer 52 is 0.3161536157131195.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 53\n",
            "Quantization progress: 53 out of 53\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3484.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 53 is 14.422073364257812.\n",
            "The relative quantization error of layer 53 is 0.10493845492601395.\n",
            "\n",
            "Bits 30, Effective Quantized Bit Size: 20.15888002648885\n",
            "Bits 30, Quantized Test Accuracy: 0.9124\n",
            "Results saved to checkpoints_teacher/results_teacher_quantization.csv\n"
          ]
        }
      ],
      "source": [
        "bits_list = range(2, 31, 2)  # 2, 4, ..., 30\n",
        "\n",
        "def calculate_bit_size(model):\n",
        "    \"\"\"\n",
        "    Calculate the effective bit size of a quantized model.\n",
        "    \n",
        "    Parameters:\n",
        "        model: nn.Module\n",
        "            The quantized neural network model.\n",
        "    \n",
        "    Returns:\n",
        "        float: The average bit size across all layers.\n",
        "    \"\"\"\n",
        "    total_bits = 0\n",
        "    total_params = 0\n",
        "    \n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Calculate unique values and their count\n",
        "            unique_values = torch.unique(param.data).cpu().numpy()\n",
        "            num_unique_values = len(unique_values)\n",
        "            \n",
        "            # Calculate bit size for this layer\n",
        "            layer_bits = np.ceil(np.log2(num_unique_values)) if num_unique_values > 1 else 1\n",
        "            total_bits += layer_bits * param.numel()\n",
        "            total_params += param.numel()\n",
        "    \n",
        "    # Return average bit size across all parameters\n",
        "    return total_bits / total_params if total_params > 0 else 0\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        teacher_net.model,\n",
        "        'resnet50',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=1.16,\n",
        "        cnn_alphabet_scalar=1.16,\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, 0.9225, quantized_test_accuracy, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV files\n",
        "quant_teacher = pd.read_csv(\"checkpoints_teacher/results_teacher_quantization.csv\")\n",
        "\n",
        "# Add a row with original accuracy to both dataframes\n",
        "new_row_quant = pd.DataFrame({\"Bits\": [32], \"Quantized Test Accuracy\": [0.9225]})\n",
        "quant_teacher = pd.concat([quant_teacher, new_row_quant], ignore_index=True)\n",
        "\n",
        "# Plot both lines sharing the same axes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(quant_teacher[\"Bits\"], quant_teacher[\"Quantized Test Accuracy\"], marker='o', label=\"Quantized Accuracy\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Test Accuracy vs Bits Size\")\n",
        "plt.xlabel(\"Bits Size\")\n",
        "plt.ylabel(\"Quantized Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Method\", loc=\"best\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('images/teacher_quant_acc.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV files\n",
        "quant_teacher = pd.read_csv(\"checkpoints_teacher/results_teacher_quantization.csv\")\n",
        "\n",
        "# Add a row with original accuracy to both dataframes\n",
        "new_row_quant = pd.DataFrame({\"Bits\": [32], \"Training Time (s)\": [0]})\n",
        "quant_teacher = pd.concat([quant_teacher, new_row_quant], ignore_index=True)\n",
        "\n",
        "# Plot both lines sharing the same axes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(quant_teacher[\"Bits\"], quant_teacher[\"Training Time (s)\"], marker='o', label=\"Training Time (s)\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Training Time (s) vs Bits Size\")\n",
        "plt.xlabel(\"Bits Size\")\n",
        "plt.ylabel(\"Training Time (s)y\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Method\", loc=\"best\")\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('images/teacher_quant_time.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayk6sDh7UXz"
      },
      "source": [
        "## Student Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Without KD "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n",
            "0 11173962 23520842\n",
            "epoch: 0 validation accuracy: 0.110\n",
            "[1,   100/  372] train loss: 1.450 train accuracy: 0.453\n",
            "[1,   200/  372] train loss: 0.954 train accuracy: 0.703\n",
            "[1,   300/  372] train loss: 0.751 train accuracy: 0.758\n",
            "epoch: 1 validation accuracy: 0.742\n",
            "[2,   100/  372] train loss: 0.602 train accuracy: 0.773\n",
            "[2,   200/  372] train loss: 0.441 train accuracy: 0.852\n",
            "[2,   300/  372] train loss: 0.438 train accuracy: 0.852\n",
            "epoch: 2 validation accuracy: 0.826\n",
            "[3,   100/  372] train loss: 0.491 train accuracy: 0.828\n",
            "[3,   200/  372] train loss: 0.349 train accuracy: 0.883\n",
            "[3,   300/  372] train loss: 0.368 train accuracy: 0.875\n",
            "epoch: 3 validation accuracy: 0.862\n",
            "[4,   100/  372] train loss: 0.361 train accuracy: 0.898\n",
            "[4,   200/  372] train loss: 0.385 train accuracy: 0.867\n",
            "[4,   300/  372] train loss: 0.267 train accuracy: 0.891\n",
            "epoch: 4 validation accuracy: 0.864\n",
            "[5,   100/  372] train loss: 0.312 train accuracy: 0.898\n",
            "[5,   200/  372] train loss: 0.227 train accuracy: 0.922\n",
            "[5,   300/  372] train loss: 0.216 train accuracy: 0.945\n",
            "epoch: 5 validation accuracy: 0.873\n",
            "[6,   100/  372] train loss: 0.229 train accuracy: 0.930\n",
            "[6,   200/  372] train loss: 0.149 train accuracy: 0.945\n",
            "[6,   300/  372] train loss: 0.229 train accuracy: 0.930\n",
            "epoch: 6 validation accuracy: 0.881\n",
            "[7,   100/  372] train loss: 0.230 train accuracy: 0.922\n",
            "[7,   200/  372] train loss: 0.220 train accuracy: 0.922\n",
            "[7,   300/  372] train loss: 0.158 train accuracy: 0.945\n",
            "epoch: 7 validation accuracy: 0.890\n",
            "[8,   100/  372] train loss: 0.182 train accuracy: 0.930\n",
            "[8,   200/  372] train loss: 0.153 train accuracy: 0.930\n",
            "[8,   300/  372] train loss: 0.127 train accuracy: 0.961\n",
            "epoch: 8 validation accuracy: 0.893\n",
            "[9,   100/  372] train loss: 0.216 train accuracy: 0.945\n",
            "[9,   200/  372] train loss: 0.136 train accuracy: 0.945\n",
            "[9,   300/  372] train loss: 0.167 train accuracy: 0.945\n",
            "epoch: 9 validation accuracy: 0.889\n",
            "[10,   100/  372] train loss: 0.174 train accuracy: 0.922\n",
            "[10,   200/  372] train loss: 0.099 train accuracy: 0.961\n",
            "[10,   300/  372] train loss: 0.076 train accuracy: 0.977\n",
            "epoch: 10 validation accuracy: 0.893\n",
            "[11,   100/  372] train loss: 0.061 train accuracy: 0.977\n",
            "[11,   200/  372] train loss: 0.112 train accuracy: 0.977\n",
            "[11,   300/  372] train loss: 0.145 train accuracy: 0.969\n",
            "epoch: 11 validation accuracy: 0.893\n",
            "[12,   100/  372] train loss: 0.061 train accuracy: 0.984\n",
            "[12,   200/  372] train loss: 0.056 train accuracy: 0.984\n",
            "[12,   300/  372] train loss: 0.152 train accuracy: 0.945\n",
            "epoch: 12 validation accuracy: 0.894\n",
            "[13,   100/  372] train loss: 0.073 train accuracy: 0.984\n",
            "[13,   200/  372] train loss: 0.069 train accuracy: 0.977\n",
            "[13,   300/  372] train loss: 0.125 train accuracy: 0.938\n",
            "epoch: 13 validation accuracy: 0.897\n",
            "[14,   100/  372] train loss: 0.039 train accuracy: 1.000\n",
            "[14,   200/  372] train loss: 0.095 train accuracy: 0.977\n",
            "[14,   300/  372] train loss: 0.021 train accuracy: 1.000\n",
            "epoch: 14 validation accuracy: 0.888\n",
            "[15,   100/  372] train loss: 0.062 train accuracy: 0.984\n",
            "[15,   200/  372] train loss: 0.034 train accuracy: 1.000\n",
            "[15,   300/  372] train loss: 0.123 train accuracy: 0.969\n",
            "epoch: 15 validation accuracy: 0.890\n",
            "[16,   100/  372] train loss: 0.029 train accuracy: 0.992\n",
            "[16,   200/  372] train loss: 0.027 train accuracy: 1.000\n",
            "[16,   300/  372] train loss: 0.046 train accuracy: 0.977\n",
            "epoch: 16 validation accuracy: 0.889\n",
            "[17,   100/  372] train loss: 0.042 train accuracy: 0.992\n",
            "[17,   200/  372] train loss: 0.027 train accuracy: 1.000\n",
            "[17,   300/  372] train loss: 0.035 train accuracy: 0.992\n",
            "epoch: 17 validation accuracy: 0.890\n",
            "[18,   100/  372] train loss: 0.043 train accuracy: 0.992\n",
            "[18,   200/  372] train loss: 0.032 train accuracy: 1.000\n",
            "[18,   300/  372] train loss: 0.037 train accuracy: 1.000\n",
            "epoch: 18 validation accuracy: 0.894\n",
            "[19,   100/  372] train loss: 0.066 train accuracy: 0.977\n",
            "[19,   200/  372] train loss: 0.055 train accuracy: 0.992\n",
            "[19,   300/  372] train loss: 0.049 train accuracy: 0.984\n",
            "epoch: 19 validation accuracy: 0.901\n",
            "[20,   100/  372] train loss: 0.055 train accuracy: 0.984\n",
            "[20,   200/  372] train loss: 0.036 train accuracy: 1.000\n",
            "[20,   300/  372] train loss: 0.013 train accuracy: 1.000\n",
            "epoch: 20 validation accuracy: 0.898\n",
            "Checkpoint saved Epoch 20: checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth\n",
            "Test accuracy:  0.8891\n",
            "Results saved to checkpoints_student/checkpoints_student_NoKD/results_student.csv\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "print_every = 100\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [0.0] # only use label for training\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill_nokd = {}\n",
        "pruning_factor = 0\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student_nokd + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=False, fuse=False, qat=False, dif_arch=True)\n",
        "    student_net.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(student_net)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "    results_distill_nokd[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(\n",
        "            teacher_net, student_net, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=False,\n",
        "            checkpoint_save_path = checkpoints_path_student_nokd\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student_nokd + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill_nokd[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': quantized_model.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_student/checkpoints_student_nokd/results_student_quantization.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 207.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 46.06303405761719."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The relative quantization error of layer 0 is 0.13444562256336212.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 751.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 70.73119354248047.\n",
            "The relative quantization error of layer 1 is 0.13634201884269714.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2181.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 63.91177749633789.\n",
            "The relative quantization error of layer 2 is 0.27810558676719666.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1959.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 130.11041259765625.\n",
            "The relative quantization error of layer 3 is 0.2529365122318268.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1714.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 68.27381134033203.\n",
            "The relative quantization error of layer 4 is 0.3909069299697876.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1182.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 262.6944580078125.\n",
            "The relative quantization error of layer 5 is 0.3929980397224426.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2493.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 53.73585510253906.\n",
            "The relative quantization error of layer 6 is 0.34700435400009155.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 258.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 350.3122253417969.\n",
            "The relative quantization error of layer 7 is 0.45527133345603943.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2488.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 90.69682312011719.\n",
            "The relative quantization error of layer 8 is 0.38430410623550415.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2461.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 42.40264892578125.\n",
            "The relative quantization error of layer 9 is 0.470932275056839.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1955.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 141.40061950683594.\n",
            "The relative quantization error of layer 10 is 0.39148521423339844.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2789.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 31.18891143798828.\n",
            "The relative quantization error of layer 11 is 0.26742658019065857.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 615.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 136.4730987548828.\n",
            "The relative quantization error of layer 12 is 0.6073117852210999.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2636.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 36.753883361816406.\n",
            "The relative quantization error of layer 13 is 0.19757497310638428.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2853.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 14.36873722076416.\n",
            "The relative quantization error of layer 14 is 0.24802115559577942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2643.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 52.117347717285156.\n",
            "The relative quantization error of layer 15 is 0.2108452320098877.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2844.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 8.529401779174805.\n",
            "The relative quantization error of layer 16 is 0.1359567791223526.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1190.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 116.2540054321289.\n",
            "The relative quantization error of layer 17 is 0.6928878426551819.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2585.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 16.423301696777344.\n",
            "The relative quantization error of layer 18 is 0.09377649426460266.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2385.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 7.337141036987305.\n",
            "The relative quantization error of layer 19 is 0.2477860301733017.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2876.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 129.11752319335938."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The relative quantization error of layer 20 is 0.7728695869445801.\n",
            "\n",
            "Bits 2, Effective Quantized Bit Size: 3.0045257000158045\n",
            "Bits 2, Quantized Test Accuracy: 0.2641\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 278.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 10.907515525817871.\n",
            "The relative quantization error of layer 0 is 0.032099418342113495.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 815.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 20.867666244506836.\n",
            "The relative quantization error of layer 1 is 0.04030719771981239.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2079.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 19.107864379882812.\n",
            "The relative quantization error of layer 2 is 0.08286567032337189.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1870.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 42.81741714477539.\n",
            "The relative quantization error of layer 3 is 0.08383191376924515.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1882.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 24.088756561279297.\n",
            "The relative quantization error of layer 4 is 0.137722909450531.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1569.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 83.82260131835938.\n",
            "The relative quantization error of layer 5 is 0.12627534568309784.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2198.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 17.125152587890625.\n",
            "The relative quantization error of layer 6 is 0.10940610617399216.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 244.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 143.886962890625.\n",
            "The relative quantization error of layer 7 is 0.18770121037960052.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2685.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 31.016698837280273.\n",
            "The relative quantization error of layer 8 is 0.13268712162971497.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2308.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 15.550689697265625.\n",
            "The relative quantization error of layer 9 is 0.17380493879318237.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1969.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 53.449974060058594.\n",
            "The relative quantization error of layer 10 is 0.14766256511211395.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2698.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 11.435561180114746.\n",
            "The relative quantization error of layer 11 is 0.09757309406995773.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 554.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 54.45892333984375.\n",
            "The relative quantization error of layer 12 is 0.24352864921092987.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2858.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 14.547122955322266.\n",
            "The relative quantization error of layer 13 is 0.07996991276741028.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2765.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 6.613264083862305.\n",
            "The relative quantization error of layer 14 is 0.11355321109294891.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2651.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 25.845062255859375.\n",
            "The relative quantization error of layer 15 is 0.1061660572886467.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2776.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.74824857711792.\n",
            "The relative quantization error of layer 16 is 0.06166486442089081.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1242.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 55.680667877197266.\n",
            "The relative quantization error of layer 17 is 0.33338651061058044.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2982.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 10.57098388671875.\n",
            "The relative quantization error of layer 18 is 0.059766363352537155.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2491.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.741366386413574.\n",
            "The relative quantization error of layer 19 is 0.20296555757522583.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2723.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 81.53309631347656.\n",
            "The relative quantization error of layer 20 is 0.4892757534980774.\n",
            "\n",
            "Bits 4, Effective Quantized Bit Size: 5.002805629730976\n",
            "Bits 4, Quantized Test Accuracy: 0.7248\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 241.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9264535903930664.\n",
            "The relative quantization error of layer 0 is 0.008324528113007545.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1017.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 8.835186958312988.\n",
            "The relative quantization error of layer 1 is 0.017066774889826775.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1972.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.309185028076172.\n",
            "The relative quantization error of layer 2 is 0.03187653049826622.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2086.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.359424591064453.\n",
            "The relative quantization error of layer 3 is 0.04728538542985916.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1900.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.64567756652832.\n",
            "The relative quantization error of layer 4 is 0.08299051225185394.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1220.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 40.512603759765625.\n",
            "The relative quantization error of layer 5 is 0.06137887388467789.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2630.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 7.485381603240967.\n",
            "The relative quantization error of layer 6 is 0.04790734127163887.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 247.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 109.72518157958984.\n",
            "The relative quantization error of layer 7 is 0.14261062443256378.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2317.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 17.351282119750977.\n",
            "The relative quantization error of layer 8 is 0.07315518707036972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2228.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 9.022244453430176.\n",
            "The relative quantization error of layer 9 is 0.10049954056739807.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1894.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 32.39591598510742.\n",
            "The relative quantization error of layer 10 is 0.09059646725654602.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2830.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.860140323638916.\n",
            "The relative quantization error of layer 11 is 0.05881142243742943.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 600.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 34.200592041015625.\n",
            "The relative quantization error of layer 12 is 0.15274490416049957.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2654.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 8.252365112304688.\n",
            "The relative quantization error of layer 13 is 0.045179326087236404.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2493.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 4.299185276031494.\n",
            "The relative quantization error of layer 14 is 0.07303006947040558.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2782.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 16.519628524780273.\n",
            "The relative quantization error of layer 15 is 0.06721989810466766.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2628.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.4573869705200195.\n",
            "The relative quantization error of layer 16 is 0.03857508674263954.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1236.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 36.41985321044922.\n",
            "The relative quantization error of layer 17 is 0.21784788370132446.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2961.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 8.186391830444336.\n",
            "The relative quantization error of layer 18 is 0.04702043533325195.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2446.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.027994155883789.\n",
            "The relative quantization error of layer 19 is 0.17175798118114471.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2572.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 62.08434295654297.\n",
            "The relative quantization error of layer 20 is 0.363545298576355.\n",
            "\n",
            "Bits 6, Effective Quantized Bit Size: 6.994332717437199\n",
            "Bits 6, Quantized Test Accuracy: 0.8156\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 267.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.7251628637313843.\n",
            "The relative quantization error of layer 0 is 0.0020957766100764275.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2285.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.720099925994873.\n",
            "The relative quantization error of layer 1 is 0.014888903126120567.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2276.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.857051372528076.\n",
            "The relative quantization error of layer 2 is 0.02552594244480133.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1714.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.120756149291992.\n",
            "The relative quantization error of layer 3 is 0.04678751900792122.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1609.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.356759071350098.\n",
            "The relative quantization error of layer 4 is 0.08191906660795212.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1122.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.18549728393555.\n",
            "The relative quantization error of layer 5 is 0.052897438406944275.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2461.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.442615032196045.\n",
            "The relative quantization error of layer 6 is 0.0410853736102581.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 266.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.23285675048828.\n",
            "The relative quantization error of layer 7 is 0.13914407789707184.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2367.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.772095680236816.\n",
            "The relative quantization error of layer 8 is 0.06655303388834.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2194.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 9.404073715209961.\n",
            "The relative quantization error of layer 9 is 0.10658195614814758.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1691.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 35.09798812866211.\n",
            "The relative quantization error of layer 10 is 0.0973074734210968.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2591.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 7.457761764526367.\n",
            "The relative quantization error of layer 11 is 0.0634961724281311.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 496.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 36.466495513916016.\n",
            "The relative quantization error of layer 12 is 0.16254976391792297.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2498.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 9.206914901733398.\n",
            "The relative quantization error of layer 13 is 0.04914138838648796.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2739.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 4.043501853942871.\n",
            "The relative quantization error of layer 14 is 0.07015509903430939.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2450.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 16.79196548461914.\n",
            "The relative quantization error of layer 15 is 0.06853615492582321.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2423.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.4264566898345947.\n",
            "The relative quantization error of layer 16 is 0.038000110536813736.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1398.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 36.21830749511719.\n",
            "The relative quantization error of layer 17 is 0.2147519439458847.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2723.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 8.02423095703125.\n",
            "The relative quantization error of layer 18 is 0.04567204788327217.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2500.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.313257694244385.\n",
            "The relative quantization error of layer 19 is 0.17611922323703766.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2585.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 60.4703483581543.\n",
            "The relative quantization error of layer 20 is 0.34778615832328796.\n",
            "\n",
            "Bits 8, Effective Quantized Bit Size: 8.845252919242073\n",
            "Bits 8, Quantized Test Accuracy: 0.8236\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 284.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.16613030433654785.\n",
            "The relative quantization error of layer 0 is 0.0004879382613580674.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1852.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.225368976593018.\n",
            "The relative quantization error of layer 1 is 0.013956745155155659.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2117.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.8083014488220215.\n",
            "The relative quantization error of layer 2 is 0.025370080024003983.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1993.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 22.97593116760254.\n",
            "The relative quantization error of layer 3 is 0.04465687274932861.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1714.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.257433891296387.\n",
            "The relative quantization error of layer 4 is 0.08031469583511353.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1285.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 34.517173767089844.\n",
            "The relative quantization error of layer 5 is 0.051912762224674225.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2276.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.355752468109131.\n",
            "The relative quantization error of layer 6 is 0.04096218943595886.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 261.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.43145751953125.\n",
            "The relative quantization error of layer 7 is 0.13918694853782654.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2477.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 16.064302444458008.\n",
            "The relative quantization error of layer 8 is 0.06770884245634079.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2219.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.716989040374756.\n",
            "The relative quantization error of layer 9 is 0.08588173985481262.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1745.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.60831069946289.\n",
            "The relative quantization error of layer 10 is 0.08222421258687973.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2571.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.1221923828125.\n",
            "The relative quantization error of layer 11 is 0.051974955946207047.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 684.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 30.48602867126465.\n",
            "The relative quantization error of layer 12 is 0.1355680376291275.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2880.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.548954963684082.\n",
            "The relative quantization error of layer 13 is 0.04075966030359268.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2779.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.4822921752929688.\n",
            "The relative quantization error of layer 14 is 0.06024067848920822.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2194.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.868790626525879.\n",
            "The relative quantization error of layer 15 is 0.060209184885025024.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2390.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1739468574523926.\n",
            "The relative quantization error of layer 16 is 0.03530916944146156.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1179.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 32.494422912597656.\n",
            "The relative quantization error of layer 17 is 0.20146024227142334.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2833.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.253141403198242.\n",
            "The relative quantization error of layer 18 is 0.04098116606473923.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2701.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.139949321746826.\n",
            "The relative quantization error of layer 19 is 0.17623458802700043.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1954.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 56.21334457397461.\n",
            "The relative quantization error of layer 20 is 0.3282751441001892.\n",
            "\n",
            "Bits 10, Effective Quantized Bit Size: 10.63193234414078\n",
            "Bits 10, Quantized Test Accuracy: 0.8306\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 281.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.04827012121677399.\n",
            "The relative quantization error of layer 0 is 0.0001318274880759418.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 789.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.501816272735596.\n",
            "The relative quantization error of layer 1 is 0.014454827643930912.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1959.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.910979270935059.\n",
            "The relative quantization error of layer 2 is 0.02574019879102707.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1613.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.0949649810791.\n",
            "The relative quantization error of layer 3 is 0.04492722451686859.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1429.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 13.896195411682129.\n",
            "The relative quantization error of layer 4 is 0.0789334699511528.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1285.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.1518440246582.\n",
            "The relative quantization error of layer 5 is 0.05258820950984955.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2294.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.708526611328125.\n",
            "The relative quantization error of layer 6 is 0.043287377804517746.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 254.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.48839569091797.\n",
            "The relative quantization error of layer 7 is 0.13955704867839813.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2691.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.63642406463623.\n",
            "The relative quantization error of layer 8 is 0.0668933093547821.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2241.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.099923610687256.\n",
            "The relative quantization error of layer 9 is 0.08053142577409744.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1979.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 30.51600456237793.\n",
            "The relative quantization error of layer 10 is 0.08440626412630081.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2612.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.2261061668396.\n",
            "The relative quantization error of layer 11 is 0.053032804280519485.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 653.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 32.58631134033203.\n",
            "The relative quantization error of layer 12 is 0.14528806507587433.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2733.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.688253879547119.\n",
            "The relative quantization error of layer 13 is 0.04172414541244507.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2550.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.4503021240234375.\n",
            "The relative quantization error of layer 14 is 0.059932123869657516.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2702.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 15.229037284851074.\n",
            "The relative quantization error of layer 15 is 0.0624409094452858.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2548.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.3556363582611084.\n",
            "The relative quantization error of layer 16 is 0.03701634705066681.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1391.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 34.62229919433594.\n",
            "The relative quantization error of layer 17 is 0.21030059456825256.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2489.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.651524066925049.\n",
            "The relative quantization error of layer 18 is 0.04294152185320854.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2754.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.816863059997559.\n",
            "The relative quantization error of layer 19 is 0.1688414216041565.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2039.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 57.38375473022461.\n",
            "The relative quantization error of layer 20 is 0.34517499804496765.\n",
            "\n",
            "Bits 12, Effective Quantized Bit Size: 12.626025397258376\n",
            "Bits 12, Quantized Test Accuracy: 0.8204\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 290.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.011804155074059963.\n",
            "The relative quantization error of layer 0 is 3.228008790756576e-05.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2232.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.391330718994141.\n",
            "The relative quantization error of layer 1 is 0.014232710935175419.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2223.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.782114028930664.\n",
            "The relative quantization error of layer 2 is 0.02535523660480976.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1387.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.15887451171875.\n",
            "The relative quantization error of layer 3 is 0.04509754851460457.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1858.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.654540061950684.\n",
            "The relative quantization error of layer 4 is 0.08316217362880707.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1230.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.62026596069336.\n",
            "The relative quantization error of layer 5 is 0.05341584235429764.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1916.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.607958793640137.\n",
            "The relative quantization error of layer 6 is 0.042287953197956085.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 265.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.34608459472656.\n",
            "The relative quantization error of layer 7 is 0.13993500173091888.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2435.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.963472366333008.\n",
            "The relative quantization error of layer 8 is 0.06802570074796677.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2267.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.238883018493652.\n",
            "The relative quantization error of layer 9 is 0.08143467456102371.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1769.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.59270477294922.\n",
            "The relative quantization error of layer 10 is 0.08221542835235596.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2301.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.080173969268799.\n",
            "The relative quantization error of layer 11 is 0.051771048456430435.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 498.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 30.282411575317383.\n",
            "The relative quantization error of layer 12 is 0.13509047031402588.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2574.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.393630504608154.\n",
            "The relative quantization error of layer 13 is 0.04031803086400032.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2526.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.4819142818450928.\n",
            "The relative quantization error of layer 14 is 0.06021025404334068.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2701.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.80072021484375.\n",
            "The relative quantization error of layer 15 is 0.06058865040540695.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2530.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1979098320007324.\n",
            "The relative quantization error of layer 16 is 0.03475302830338478.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1219.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 32.54218673706055.\n",
            "The relative quantization error of layer 17 is 0.1967732310295105.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2885.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.123910427093506.\n",
            "The relative quantization error of layer 18 is 0.04112643003463745.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2588.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.145427227020264.\n",
            "The relative quantization error of layer 19 is 0.1751132756471634.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2169.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 56.674644470214844.\n",
            "The relative quantization error of layer 20 is 0.3323054313659668.\n",
            "\n",
            "Bits 14, Effective Quantized Bit Size: 14.181367003037955\n",
            "Bits 14, Quantized Test Accuracy: 0.8267\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 300.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.002848756965249777.\n",
            "The relative quantization error of layer 0 is 8.275263098767027e-06.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 909.95it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.474122524261475.\n",
            "The relative quantization error of layer 1 is 0.014416230842471123.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1846.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.884037971496582.\n",
            "The relative quantization error of layer 2 is 0.025601085275411606.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1636.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.00116539001465.\n",
            "The relative quantization error of layer 3 is 0.04497021436691284.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2232.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.125391960144043.\n",
            "The relative quantization error of layer 4 is 0.08106588572263718.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1864.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 34.67897415161133.\n",
            "The relative quantization error of layer 5 is 0.05213937908411026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2624.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.424779891967773.\n",
            "The relative quantization error of layer 6 is 0.04154525697231293.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 263.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 106.71249389648438.\n",
            "The relative quantization error of layer 7 is 0.13820858299732208.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2577.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.850330352783203.\n",
            "The relative quantization error of layer 8 is 0.06771346926689148.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1802.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.404690265655518.\n",
            "The relative quantization error of layer 9 is 0.08339850604534149.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1849.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 28.8309383392334.\n",
            "The relative quantization error of layer 10 is 0.08030914515256882.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2713.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.694540023803711.\n",
            "The relative quantization error of layer 11 is 0.04832078143954277.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 566.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.981294631958008.\n",
            "The relative quantization error of layer 12 is 0.13335327804088593.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2490.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.180540084838867.\n",
            "The relative quantization error of layer 13 is 0.03864266350865364.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2299.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.4453725814819336.\n",
            "The relative quantization error of layer 14 is 0.05866321921348572.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2723.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.598088264465332.\n",
            "The relative quantization error of layer 15 is 0.05945385619997978.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2571.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1087350845336914.\n",
            "The relative quantization error of layer 16 is 0.033992279320955276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1015.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 31.704282760620117.\n",
            "The relative quantization error of layer 17 is 0.19033192098140717.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2598.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.101626873016357.\n",
            "The relative quantization error of layer 18 is 0.04075288027524948.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2525.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.905699253082275.\n",
            "The relative quantization error of layer 19 is 0.16956643760204315.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2560.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 58.42378616333008.\n",
            "The relative quantization error of layer 20 is 0.34449368715286255.\n",
            "\n",
            "Bits 16, Effective Quantized Bit Size: 15.825875906862759\n",
            "Bits 16, Quantized Test Accuracy: 0.825\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 262.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.0006881784065626562.\n",
            "The relative quantization error of layer 0 is 2.076524651783984e-06.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2149.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.2052812576293945.\n",
            "The relative quantization error of layer 1 is 0.013886708766222.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2223.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.770081996917725.\n",
            "The relative quantization error of layer 2 is 0.02532724104821682.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1613.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.479307174682617.\n",
            "The relative quantization error of layer 3 is 0.04571361467242241.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1309.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.280120849609375.\n",
            "The relative quantization error of layer 4 is 0.08113584667444229.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1387.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 34.83104705810547.\n",
            "The relative quantization error of layer 5 is 0.052669707685709.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2445.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.335319519042969.\n",
            "The relative quantization error of layer 6 is 0.04014777019619942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 259.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.9742202758789.\n",
            "The relative quantization error of layer 7 is 0.13968022167682648.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2660.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.796844482421875.\n",
            "The relative quantization error of layer 8 is 0.06787808984518051.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2254.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.71078634262085.\n",
            "The relative quantization error of layer 9 is 0.08574232459068298.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1935.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.538923263549805.\n",
            "The relative quantization error of layer 10 is 0.0813651978969574.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2688.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.130458831787109.\n",
            "The relative quantization error of layer 11 is 0.051438815891742706.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 640.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 31.275672912597656.\n",
            "The relative quantization error of layer 12 is 0.13963767886161804.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2410.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.50826358795166.\n",
            "The relative quantization error of layer 13 is 0.0400107316672802.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2880.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.6619412899017334.\n",
            "The relative quantization error of layer 14 is 0.06168162077665329.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2230.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 15.14067554473877.\n",
            "The relative quantization error of layer 15 is 0.061706770211458206.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2728.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.2732632160186768.\n",
            "The relative quantization error of layer 16 is 0.03524351119995117.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1236.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 33.46623229980469.\n",
            "The relative quantization error of layer 17 is 0.1991564929485321.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2675.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.20965051651001.\n",
            "The relative quantization error of layer 18 is 0.04129885137081146.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2981.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.000382423400879.\n",
            "The relative quantization error of layer 19 is 0.1741633415222168.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2497.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 56.408958435058594.\n",
            "The relative quantization error of layer 20 is 0.3358711004257202.\n",
            "\n",
            "Bits 18, Effective Quantized Bit Size: 17.554970027641048\n",
            "Bits 18, Quantized Test Accuracy: 0.8189\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 275.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.00018191125127486885.\n",
            "The relative quantization error of layer 0 is 5.372333475861524e-07.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1719.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.372864723205566.\n",
            "The relative quantization error of layer 1 is 0.014238744042813778.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2350.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.991860866546631.\n",
            "The relative quantization error of layer 2 is 0.02608454041182995.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1613.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 22.769784927368164.\n",
            "The relative quantization error of layer 3 is 0.04442078247666359.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1465.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.786624908447266.\n",
            "The relative quantization error of layer 4 is 0.08393969386816025.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1358.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 36.11402130126953.\n",
            "The relative quantization error of layer 5 is 0.05387785658240318.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2336.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.508045673370361.\n",
            "The relative quantization error of layer 6 is 0.04198634997010231.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 267.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 108.83590698242188.\n",
            "The relative quantization error of layer 7 is 0.14101910591125488.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2565.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.773421287536621.\n",
            "The relative quantization error of layer 8 is 0.06681505590677261.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2360.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.597981929779053.\n",
            "The relative quantization error of layer 9 is 0.08435646444559097.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1745.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.64502716064453.\n",
            "The relative quantization error of layer 10 is 0.08297660946846008.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2053.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.2555155754089355.\n",
            "The relative quantization error of layer 11 is 0.05348405987024307.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 895.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 30.848222732543945.\n",
            "The relative quantization error of layer 12 is 0.1371377408504486.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2927.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.6359734535217285.\n",
            "The relative quantization error of layer 13 is 0.04109959304332733.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2380.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.273134708404541.\n",
            "The relative quantization error of layer 14 is 0.0565190315246582.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2355.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 15.204527854919434.\n",
            "The relative quantization error of layer 15 is 0.062158435583114624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 1900.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.3634583950042725.\n",
            "The relative quantization error of layer 16 is 0.03653642162680626.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1534.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 33.284175872802734.\n",
            "The relative quantization error of layer 17 is 0.19948814809322357.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3148.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.832222938537598.\n",
            "The relative quantization error of layer 18 is 0.04477502033114433.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2731.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.191840171813965.\n",
            "The relative quantization error of layer 19 is 0.17548947036266327.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3148.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 54.35201644897461.\n",
            "The relative quantization error of layer 20 is 0.3228743076324463.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 20, Effective Quantized Bit Size: 19.095648973927062\n",
            "Bits 20, Quantized Test Accuracy: 0.8221\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 382.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 5.0069877033820376e-05.\n",
            "The relative quantization error of layer 0 is 1.4889306498844235e-07.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1135.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.237751007080078.\n",
            "The relative quantization error of layer 1 is 0.01396206859499216.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2306.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.865598201751709.\n",
            "The relative quantization error of layer 2 is 0.025472497567534447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2391.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.443090438842773.\n",
            "The relative quantization error of layer 3 is 0.04556000605225563.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2366.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.789254188537598.\n",
            "The relative quantization error of layer 4 is 0.0852188840508461.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1576.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 33.768409729003906.\n",
            "The relative quantization error of layer 5 is 0.05052933096885681.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2812.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.287575721740723.\n",
            "The relative quantization error of layer 6 is 0.04062667116522789.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 297.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 106.92469787597656.\n",
            "The relative quantization error of layer 7 is 0.13835327327251434.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3141.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.586827278137207.\n",
            "The relative quantization error of layer 8 is 0.0660892203450203.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2879.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 9.061131477355957.\n",
            "The relative quantization error of layer 9 is 0.10091344267129898.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2056.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 33.28255081176758.\n",
            "The relative quantization error of layer 10 is 0.09327811747789383.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3075.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 7.091591835021973.\n",
            "The relative quantization error of layer 11 is 0.05985671281814575.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 711.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 33.960540771484375.\n",
            "The relative quantization error of layer 12 is 0.15205109119415283.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3301.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 8.307516098022461.\n",
            "The relative quantization error of layer 13 is 0.046042606234550476.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3009.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.850506067276001.\n",
            "The relative quantization error of layer 14 is 0.06559599936008453.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2880.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 15.882102012634277.\n",
            "The relative quantization error of layer 15 is 0.06461026519536972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2777.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.2075297832489014.\n",
            "The relative quantization error of layer 16 is 0.03518372029066086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1445.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 34.78226852416992.\n",
            "The relative quantization error of layer 17 is 0.20919343829154968.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3471.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 8.071683883666992.\n",
            "The relative quantization error of layer 18 is 0.045501384884119034.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3183.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.218087673187256.\n",
            "The relative quantization error of layer 19 is 0.17627286911010742.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3079.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 58.19667434692383.\n",
            "The relative quantization error of layer 20 is 0.3446282148361206.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 22, Effective Quantized Bit Size: 20.197547834868242\n",
            "Bits 22, Quantized Test Accuracy: 0.8201\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 335.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.414725167909637e-05.\n",
            "The relative quantization error of layer 0 is 7.15744761237147e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1348.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.3805365562438965.\n",
            "The relative quantization error of layer 1 is 0.014249470084905624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2534.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.669137477874756.\n",
            "The relative quantization error of layer 2 is 0.02474210411310196.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2201.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.718162536621094.\n",
            "The relative quantization error of layer 3 is 0.04603893309831619.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2281.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.559904098510742.\n",
            "The relative quantization error of layer 4 is 0.08290564268827438.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1508.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.08572769165039.\n",
            "The relative quantization error of layer 5 is 0.05248181149363518.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2720.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.662108421325684.\n",
            "The relative quantization error of layer 6 is 0.04281596094369888.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 295.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.99903869628906.\n",
            "The relative quantization error of layer 7 is 0.13994641602039337.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2891.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.828848838806152.\n",
            "The relative quantization error of layer 8 is 0.06725092232227325.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2800.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.541008472442627.\n",
            "The relative quantization error of layer 9 is 0.08395966142416.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1906.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.364673614501953.\n",
            "The relative quantization error of layer 10 is 0.08112309128046036.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3094.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.238152980804443.\n",
            "The relative quantization error of layer 11 is 0.05249612405896187.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 725.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 30.630725860595703.\n",
            "The relative quantization error of layer 12 is 0.13686059415340424.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3161.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.623269081115723.\n",
            "The relative quantization error of layer 13 is 0.04118015617132187.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3059.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.5460317134857178.\n",
            "The relative quantization error of layer 14 is 0.06030753627419472.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2959.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.605561256408691.\n",
            "The relative quantization error of layer 15 is 0.059876449406147.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2829.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1458652019500732.\n",
            "The relative quantization error of layer 16 is 0.03401356562972069.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1232.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 32.59581756591797.\n",
            "The relative quantization error of layer 17 is 0.1956717073917389.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3071.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.088708877563477.\n",
            "The relative quantization error of layer 18 is 0.04023861140012741.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2665.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.850642204284668.\n",
            "The relative quantization error of layer 19 is 0.1654990315437317.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3097.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 51.645362854003906.\n",
            "The relative quantization error of layer 20 is 0.3018400967121124.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 24, Effective Quantized Bit Size: 20.38229734448712\n",
            "Bits 24, Quantized Test Accuracy: 0.8388\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 303.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.2668578822049312e-05.\n",
            "The relative quantization error of layer 0 is 6.638577332296336e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2679.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.30624532699585.\n",
            "The relative quantization error of layer 1 is 0.01411267090588808.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2548.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.800195217132568.\n",
            "The relative quantization error of layer 2 is 0.025347474962472916.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2241.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.145294189453125.\n",
            "The relative quantization error of layer 3 is 0.04526440054178238.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2354.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 14.274190902709961.\n",
            "The relative quantization error of layer 4 is 0.08104582130908966.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1803.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.54157257080078.\n",
            "The relative quantization error of layer 5 is 0.053670063614845276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2966.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.456416130065918.\n",
            "The relative quantization error of layer 6 is 0.041886087507009506.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 297.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.19373321533203.\n",
            "The relative quantization error of layer 7 is 0.13872838020324707.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2963.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.528190612792969.\n",
            "The relative quantization error of layer 8 is 0.06546734273433685.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2664.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 8.265650749206543.\n",
            "The relative quantization error of layer 9 is 0.09313070774078369.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2127.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 31.26369285583496.\n",
            "The relative quantization error of layer 10 is 0.08658749610185623.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2962.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.518939018249512.\n",
            "The relative quantization error of layer 11 is 0.05461070314049721.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 738.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 32.22367858886719.\n",
            "The relative quantization error of layer 12 is 0.14333784580230713.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3025.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.904006004333496.\n",
            "The relative quantization error of layer 13 is 0.04326840117573738.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2835.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.9707698822021484.\n",
            "The relative quantization error of layer 14 is 0.06766404211521149.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2689.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 16.220645904541016.\n",
            "The relative quantization error of layer 15 is 0.0667913556098938.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3101.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.497133493423462.\n",
            "The relative quantization error of layer 16 is 0.039072565734386444.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1745.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 35.078819274902344.\n",
            "The relative quantization error of layer 17 is 0.21180355548858643.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3345.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.684393882751465.\n",
            "The relative quantization error of layer 18 is 0.04446300491690636.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3100.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.242825508117676.\n",
            "The relative quantization error of layer 19 is 0.18037284910678864.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3160.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 59.303829193115234.\n",
            "The relative quantization error of layer 20 is 0.36064717173576355.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 26, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 26, Quantized Test Accuracy: 0.808\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 305.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.1047490008641034e-05.\n",
            "The relative quantization error of layer 0 is 6.124947304897432e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1170.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.329297065734863.\n",
            "The relative quantization error of layer 1 is 0.014170510694384575.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2508.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.874244213104248.\n",
            "The relative quantization error of layer 2 is 0.025635432451963425.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2248.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.284137725830078.\n",
            "The relative quantization error of layer 3 is 0.04538194090127945.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2304.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 13.807764053344727.\n",
            "The relative quantization error of layer 4 is 0.0787927433848381.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1804.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.973594665527344.\n",
            "The relative quantization error of layer 5 is 0.05395066365599632.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2901.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.643779754638672.\n",
            "The relative quantization error of layer 6 is 0.04236162081360817.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 321.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.35588073730469.\n",
            "The relative quantization error of layer 7 is 0.1391434669494629.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3104.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 16.115556716918945.\n",
            "The relative quantization error of layer 8 is 0.06882262974977493.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3014.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.432402610778809.\n",
            "The relative quantization error of layer 9 is 0.08309219777584076.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2256.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 30.860265731811523.\n",
            "The relative quantization error of layer 10 is 0.08562099188566208.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3079.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.2398600578308105.\n",
            "The relative quantization error of layer 11 is 0.05364402011036873.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 769.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 31.481996536254883."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The relative quantization error of layer 12 is 0.14041957259178162.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2969.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.693965911865234.\n",
            "The relative quantization error of layer 13 is 0.041853610426187515.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2859.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.5698530673980713.\n",
            "The relative quantization error of layer 14 is 0.061238013207912445.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2936.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.535195350646973.\n",
            "The relative quantization error of layer 15 is 0.05916533246636391.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3020.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.263378143310547.\n",
            "The relative quantization error of layer 16 is 0.03507198765873909.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1427.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 31.843700408935547.\n",
            "The relative quantization error of layer 17 is 0.1938186138868332.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3184.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.926069259643555.\n",
            "The relative quantization error of layer 18 is 0.03945549950003624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2802.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.857135772705078.\n",
            "The relative quantization error of layer 19 is 0.16540534794330597.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3072.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 53.96320724487305.\n",
            "The relative quantization error of layer 20 is 0.317848265171051.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 28, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 28, Quantized Test Accuracy: 0.8392\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 325.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 1.9829620214295574e-05.\n",
            "The relative quantization error of layer 0 is 5.603591546332609e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2614.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.230504512786865.\n",
            "The relative quantization error of layer 1 is 0.013987780548632145.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2695.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 5.988799571990967.\n",
            "The relative quantization error of layer 2 is 0.026150142773985863.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2303.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.369970321655273.\n",
            "The relative quantization error of layer 3 is 0.045439597219228745.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2174.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 13.848917961120605.\n",
            "The relative quantization error of layer 4 is 0.07852470129728317.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1665.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 35.04779815673828.\n",
            "The relative quantization error of layer 5 is 0.052133843302726746.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3074.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.62437105178833.\n",
            "The relative quantization error of layer 6 is 0.042861390858888626.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 355.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 107.94094848632812.\n",
            "The relative quantization error of layer 7 is 0.13981831073760986.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2946.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.869132041931152.\n",
            "The relative quantization error of layer 8 is 0.06762892007827759.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2883.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 8.744839668273926.\n",
            "The relative quantization error of layer 9 is 0.09785690903663635.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2337.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 31.926164627075195.\n",
            "The relative quantization error of layer 10 is 0.08922664821147919.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3034.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.518498420715332.\n",
            "The relative quantization error of layer 11 is 0.0555972158908844.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 769.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 33.2050666809082.\n",
            "The relative quantization error of layer 12 is 0.14839383959770203.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3164.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 8.102639198303223.\n",
            "The relative quantization error of layer 13 is 0.04465937986969948.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2963.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.767024040222168.\n",
            "The relative quantization error of layer 14 is 0.06416555494070053.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2676.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 15.442811012268066.\n",
            "The relative quantization error of layer 15 is 0.061894193291664124.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2806.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1606228351593018.\n",
            "The relative quantization error of layer 16 is 0.033889323472976685.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1418.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 32.813167572021484.\n",
            "The relative quantization error of layer 17 is 0.19930244982242584.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3253.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.584970951080322.\n",
            "The relative quantization error of layer 18 is 0.04402536153793335.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3019.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.145308971405029.\n",
            "The relative quantization error of layer 19 is 0.17303791642189026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3358.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 53.70393371582031.\n",
            "The relative quantization error of layer 20 is 0.3206023871898651.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 30, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 30, Quantized Test Accuracy: 0.8249\n",
            "Results saved to checkpoints_student/checkpoints_student_nokd/results_student_quantization.csv\n"
          ]
        }
      ],
      "source": [
        "bits_list = range(2, 31, 2)  # 2, 4, ..., 30\n",
        "\n",
        "def calculate_bit_size(model):\n",
        "    \"\"\"\n",
        "    Calculate the effective bit size of a quantized model.\n",
        "    \n",
        "    Parameters:\n",
        "        model: nn.Module\n",
        "            The quantized neural network model.\n",
        "    \n",
        "    Returns:\n",
        "        float: The average bit size across all layers.\n",
        "    \"\"\"\n",
        "    total_bits = 0\n",
        "    total_params = 0\n",
        "    \n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Calculate unique values and their count\n",
        "            unique_values = torch.unique(param.data).cpu().numpy()\n",
        "            num_unique_values = len(unique_values)\n",
        "            \n",
        "            # Calculate bit size for this layer\n",
        "            layer_bits = np.ceil(np.log2(num_unique_values)) if num_unique_values > 1 else 1\n",
        "            total_bits += layer_bits * param.numel()\n",
        "            total_params += param.numel()\n",
        "    \n",
        "    # Return average bit size across all parameters\n",
        "    return total_bits / total_params if total_params > 0 else 0\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        student_net.model,\n",
        "        'resnet18',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=1.16,\n",
        "        cnn_alphabet_scalar=1.16,\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, 0.8891, quantized_test_accuracy, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 11173962 23520842\n",
            "epoch: 0 validation accuracy: 0.110\n",
            "[1,   100/  372] train loss: 5.777 train accuracy: 0.680\n",
            "[1,   200/  372] train loss: 3.589 train accuracy: 0.797\n",
            "[1,   300/  372] train loss: 2.916 train accuracy: 0.836\n",
            "epoch: 1 validation accuracy: 0.858\n",
            "[2,   100/  372] train loss: 1.893 train accuracy: 0.906\n",
            "[2,   200/  372] train loss: 1.805 train accuracy: 0.953\n",
            "[2,   300/  372] train loss: 1.338 train accuracy: 0.930\n",
            "epoch: 2 validation accuracy: 0.888\n",
            "[3,   100/  372] train loss: 1.538 train accuracy: 0.922\n",
            "[3,   200/  372] train loss: 1.118 train accuracy: 0.930\n",
            "[3,   300/  372] train loss: 1.191 train accuracy: 0.953\n",
            "epoch: 3 validation accuracy: 0.901\n",
            "[4,   100/  372] train loss: 1.134 train accuracy: 0.938\n",
            "[4,   200/  372] train loss: 1.383 train accuracy: 0.938\n",
            "[4,   300/  372] train loss: 0.837 train accuracy: 0.953\n",
            "epoch: 4 validation accuracy: 0.907\n",
            "[5,   100/  372] train loss: 0.899 train accuracy: 0.953\n",
            "[5,   200/  372] train loss: 0.848 train accuracy: 0.977\n",
            "[5,   300/  372] train loss: 0.939 train accuracy: 0.977\n",
            "epoch: 5 validation accuracy: 0.913\n",
            "[6,   100/  372] train loss: 0.723 train accuracy: 0.961\n",
            "[6,   200/  372] train loss: 0.649 train accuracy: 0.969\n",
            "[6,   300/  372] train loss: 0.942 train accuracy: 0.906\n",
            "epoch: 6 validation accuracy: 0.913\n",
            "[7,   100/  372] train loss: 0.838 train accuracy: 0.938\n",
            "[7,   200/  372] train loss: 0.711 train accuracy: 0.977\n",
            "[7,   300/  372] train loss: 0.526 train accuracy: 0.977\n",
            "epoch: 7 validation accuracy: 0.910\n",
            "[8,   100/  372] train loss: 0.614 train accuracy: 0.977\n",
            "[8,   200/  372] train loss: 0.495 train accuracy: 0.961\n",
            "[8,   300/  372] train loss: 0.501 train accuracy: 0.984\n",
            "epoch: 8 validation accuracy: 0.914\n",
            "[9,   100/  372] train loss: 0.716 train accuracy: 0.969\n",
            "[9,   200/  372] train loss: 0.581 train accuracy: 0.992\n",
            "[9,   300/  372] train loss: 0.667 train accuracy: 0.969\n",
            "epoch: 9 validation accuracy: 0.915\n",
            "[10,   100/  372] train loss: 0.491 train accuracy: 0.977\n",
            "[10,   200/  372] train loss: 0.463 train accuracy: 0.992\n",
            "[10,   300/  372] train loss: 0.399 train accuracy: 1.000\n",
            "epoch: 10 validation accuracy: 0.918\n",
            "[11,   100/  372] train loss: 0.376 train accuracy: 0.977\n",
            "[11,   200/  372] train loss: 0.467 train accuracy: 0.977\n",
            "[11,   300/  372] train loss: 0.424 train accuracy: 0.977\n",
            "epoch: 11 validation accuracy: 0.916\n",
            "[12,   100/  372] train loss: 0.385 train accuracy: 0.992\n",
            "[12,   200/  372] train loss: 0.358 train accuracy: 1.000\n",
            "[12,   300/  372] train loss: 0.636 train accuracy: 0.977\n",
            "epoch: 12 validation accuracy: 0.916\n",
            "[13,   100/  372] train loss: 0.394 train accuracy: 0.969\n",
            "[13,   200/  372] train loss: 0.454 train accuracy: 0.969\n",
            "[13,   300/  372] train loss: 0.384 train accuracy: 0.984\n",
            "epoch: 13 validation accuracy: 0.916\n",
            "[14,   100/  372] train loss: 0.389 train accuracy: 0.977\n",
            "[14,   200/  372] train loss: 0.268 train accuracy: 0.984\n",
            "[14,   300/  372] train loss: 0.333 train accuracy: 0.992\n",
            "epoch: 14 validation accuracy: 0.915\n",
            "[15,   100/  372] train loss: 0.305 train accuracy: 0.984\n",
            "[15,   200/  372] train loss: 0.368 train accuracy: 0.992\n",
            "[15,   300/  372] train loss: 0.410 train accuracy: 0.984\n",
            "epoch: 15 validation accuracy: 0.918\n",
            "[16,   100/  372] train loss: 0.358 train accuracy: 0.977\n",
            "[16,   200/  372] train loss: 0.308 train accuracy: 0.977\n",
            "[16,   300/  372] train loss: 0.328 train accuracy: 0.992\n",
            "epoch: 16 validation accuracy: 0.918\n",
            "[17,   100/  372] train loss: 0.326 train accuracy: 0.984\n",
            "[17,   200/  372] train loss: 0.304 train accuracy: 0.977\n",
            "[17,   300/  372] train loss: 0.347 train accuracy: 0.992\n",
            "epoch: 17 validation accuracy: 0.919\n",
            "[18,   100/  372] train loss: 0.355 train accuracy: 0.992\n",
            "[18,   200/  372] train loss: 0.341 train accuracy: 0.984\n",
            "[18,   300/  372] train loss: 0.448 train accuracy: 0.969\n",
            "epoch: 18 validation accuracy: 0.919\n",
            "[19,   100/  372] train loss: 0.359 train accuracy: 0.969\n",
            "[19,   200/  372] train loss: 0.300 train accuracy: 0.984\n",
            "[19,   300/  372] train loss: 0.390 train accuracy: 0.977\n",
            "epoch: 19 validation accuracy: 0.922\n",
            "[20,   100/  372] train loss: 0.409 train accuracy: 1.000\n",
            "[20,   200/  372] train loss: 0.376 train accuracy: 1.000\n",
            "[20,   300/  372] train loss: 0.324 train accuracy: 1.000\n",
            "epoch: 20 validation accuracy: 0.919\n",
            "Checkpoint saved Epoch 20: checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth\n",
            "Test accuracy:  0.9152\n",
            "Results saved to checkpoints_student/checkpoints_student_VAN/results_student.csv\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "print_every = 100\n",
        "\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill_van = {}\n",
        "pruning_factor = 0\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student_van + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=False, fuse=False, qat=False, dif_arch=True)\n",
        "    student_net.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(student_net)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "\n",
        "    results_distill_van[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(\n",
        "            teacher_net, student_net, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=False,\n",
        "            checkpoint_save_path = checkpoints_path_student_van\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student_van + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill_van[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': student_net.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 246.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 51.50834655761719.\n",
            "The relative quantization error of layer 0 is 0.14557930827140808.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1932.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 70.86209869384766.\n",
            "The relative quantization error of layer 1 is 0.1388840675354004.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2191.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 62.65403366088867.\n",
            "The relative quantization error of layer 2 is 0.24729953706264496.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1929.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 126.94184112548828.\n",
            "The relative quantization error of layer 3 is 0.23974211513996124.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2071.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 63.66826629638672.\n",
            "The relative quantization error of layer 4 is 0.3499382436275482.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1535.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 246.72926330566406.\n",
            "The relative quantization error of layer 5 is 0.3565079867839813.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2678.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 52.12347412109375.\n",
            "The relative quantization error of layer 6 is 0.33030954003334045.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 262.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 337.6912536621094.\n",
            "The relative quantization error of layer 7 is 0.4331929087638855.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2719.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 87.82482147216797.\n",
            "The relative quantization error of layer 8 is 0.3708684742450714.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2340.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 41.983829498291016.\n",
            "The relative quantization error of layer 9 is 0.4417859613895416.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1295.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 136.49388122558594.\n",
            "The relative quantization error of layer 10 is 0.3607312738895416.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2699.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 30.521957397460938.\n",
            "The relative quantization error of layer 11 is 0.25258761644363403.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 623.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 133.0901641845703.\n",
            "The relative quantization error of layer 12 is 0.5706446170806885.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2387.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 34.14548110961914.\n",
            "The relative quantization error of layer 13 is 0.19253374636173248.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2801.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 14.429980278015137.\n",
            "The relative quantization error of layer 14 is 0.24442359805107117.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2736.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 50.64638137817383.\n",
            "The relative quantization error of layer 15 is 0.20519700646400452.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2811.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 8.570271492004395.\n",
            "The relative quantization error of layer 16 is 0.13611146807670593.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 929.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 112.3578872680664.\n",
            "The relative quantization error of layer 17 is 0.676101803779602.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2764.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 16.261615753173828.\n",
            "The relative quantization error of layer 18 is 0.09000939130783081.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2885.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 6.583651065826416.\n",
            "The relative quantization error of layer 19 is 0.18714921176433563.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2745.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 100.76458740234375.\n",
            "The relative quantization error of layer 20 is 0.7347511053085327.\n",
            "\n",
            "Bits 2, Effective Quantized Bit Size: 3.0045257000158045\n",
            "Bits 2, Quantized Test Accuracy: 0.3802\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 296.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 12.171177864074707.\n",
            "The relative quantization error of layer 0 is 0.03470459207892418.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1030.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 21.751140594482422.\n",
            "The relative quantization error of layer 1 is 0.04265321418642998.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1919.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 19.08643913269043.\n",
            "The relative quantization error of layer 2 is 0.07479719072580338.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1432.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 41.95392608642578.\n",
            "The relative quantization error of layer 3 is 0.07986230403184891.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1139.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 21.001644134521484.\n",
            "The relative quantization error of layer 4 is 0.11497432738542557.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1738.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 76.71067810058594.\n",
            "The relative quantization error of layer 5 is 0.11158798635005951.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2841.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 15.942973136901855.\n",
            "The relative quantization error of layer 6 is 0.09962442517280579.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 278.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 138.2447967529297.\n",
            "The relative quantization error of layer 7 is 0.17795470356941223.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2556.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 29.157495498657227.\n",
            "The relative quantization error of layer 8 is 0.12378151714801788.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2169.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 14.844072341918945.\n",
            "The relative quantization error of layer 9 is 0.1568700075149536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1925.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 49.60158920288086.\n",
            "The relative quantization error of layer 10 is 0.13050805032253265.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2733.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 10.881108283996582.\n",
            "The relative quantization error of layer 11 is 0.08924686163663864.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 598.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 51.80830001831055.\n",
            "The relative quantization error of layer 12 is 0.22326253354549408.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2594.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 12.900338172912598.\n",
            "The relative quantization error of layer 13 is 0.07457821816205978.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2698.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 6.091648101806641.\n",
            "The relative quantization error of layer 14 is 0.10252244770526886.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2626.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 23.006059646606445.\n",
            "The relative quantization error of layer 15 is 0.09487605094909668.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2648.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.421687602996826.\n",
            "The relative quantization error of layer 16 is 0.056326065212488174.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1632.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 50.138153076171875.\n",
            "The relative quantization error of layer 17 is 0.2992452383041382.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2962.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 10.02501392364502.\n",
            "The relative quantization error of layer 18 is 0.055252041667699814.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3008.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.876715660095215.\n",
            "The relative quantization error of layer 19 is 0.1395609974861145.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2104.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 46.384212493896484.\n",
            "The relative quantization error of layer 20 is 0.3413636088371277.\n",
            "\n",
            "Bits 4, Effective Quantized Bit Size: 5.002805629730976\n",
            "Bits 4, Quantized Test Accuracy: 0.8546\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 277.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 4.426090240478516.\n",
            "The relative quantization error of layer 0 is 0.012208864092826843.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2224.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.870403289794922.\n",
            "The relative quantization error of layer 1 is 0.0232979878783226.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2243.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 8.577534675598145.\n",
            "The relative quantization error of layer 2 is 0.033892251551151276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1586.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 25.77039337158203.\n",
            "The relative quantization error of layer 3 is 0.04860929772257805.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1913.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 12.346526145935059.\n",
            "The relative quantization error of layer 4 is 0.06735939532518387.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1456.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 36.73167037963867.\n",
            "The relative quantization error of layer 5 is 0.05386516451835632.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2500.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 6.710758209228516.\n",
            "The relative quantization error of layer 6 is 0.041831329464912415.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 279.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 105.74032592773438.\n",
            "The relative quantization error of layer 7 is 0.13593803346157074.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2384.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 16.730361938476562.\n",
            "The relative quantization error of layer 8 is 0.07031562179327011.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1785.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 8.218256950378418.\n",
            "The relative quantization error of layer 9 is 0.0856827050447464.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1963.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 30.721586227416992.\n",
            "The relative quantization error of layer 10 is 0.08246509730815887.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2837.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.147480487823486.\n",
            "The relative quantization error of layer 11 is 0.05077754706144333.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 878.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 33.16331481933594.\n",
            "The relative quantization error of layer 12 is 0.1426815241575241.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2947.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.106513023376465.\n",
            "The relative quantization error of layer 13 is 0.04073328524827957.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2771.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.618587017059326.\n",
            "The relative quantization error of layer 14 is 0.06056699529290199.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2714.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.295516014099121.\n",
            "The relative quantization error of layer 15 is 0.05794680491089821.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2860.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1240477561950684.\n",
            "The relative quantization error of layer 16 is 0.0336301326751709.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1047.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 31.4227237701416.\n",
            "The relative quantization error of layer 17 is 0.1872747242450714.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2720.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.144030570983887.\n",
            "The relative quantization error of layer 18 is 0.03894123435020447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2718.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.874680280685425.\n",
            "The relative quantization error of layer 19 is 0.10897190868854523.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2799.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 32.15949249267578.\n",
            "The relative quantization error of layer 20 is 0.23239614069461823.\n",
            "\n",
            "Bits 6, Effective Quantized Bit Size: 6.996898682848572\n",
            "Bits 6, Quantized Test Accuracy: 0.8883\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 321.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 3.1270437240600586.\n",
            "The relative quantization error of layer 0 is 0.008752516470849514.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1029.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.424178123474121.\n",
            "The relative quantization error of layer 1 is 0.022379735484719276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2422.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.586287021636963.\n",
            "The relative quantization error of layer 2 is 0.030008116737008095.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2292.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 25.144298553466797.\n",
            "The relative quantization error of layer 3 is 0.04726080596446991.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2021.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.420692443847656.\n",
            "The relative quantization error of layer 4 is 0.06251583248376846.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1638.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.023792266845703.\n",
            "The relative quantization error of layer 5 is 0.044985122978687286.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2860.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.281225681304932.\n",
            "The relative quantization error of layer 6 is 0.03279077634215355.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 281.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.39610290527344.\n",
            "The relative quantization error of layer 7 is 0.13258278369903564.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2853.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 14.843278884887695.\n",
            "The relative quantization error of layer 8 is 0.06230568885803223.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2684.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.112173557281494.\n",
            "The relative quantization error of layer 9 is 0.07517120987176895.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2121.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 28.83920669555664.\n",
            "The relative quantization error of layer 10 is 0.07639967650175095.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2947.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.63809061050415.\n",
            "The relative quantization error of layer 11 is 0.046301860362291336.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 770.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 30.34449577331543.\n",
            "The relative quantization error of layer 12 is 0.1306685209274292.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2861.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.516124248504639.\n",
            "The relative quantization error of layer 13 is 0.03614548593759537.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2962.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.1535801887512207.\n",
            "The relative quantization error of layer 14 is 0.054457202553749084.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2837.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 14.028456687927246.\n",
            "The relative quantization error of layer 15 is 0.05716859549283981.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2814.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.050478935241699.\n",
            "The relative quantization error of layer 16 is 0.03290138766169548.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1320.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 30.54088020324707.\n",
            "The relative quantization error of layer 17 is 0.17954301834106445.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2717.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.936770915985107.\n",
            "The relative quantization error of layer 18 is 0.03856032341718674.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3273.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.9066712856292725.\n",
            "The relative quantization error of layer 19 is 0.111038938164711.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2959.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 33.45311737060547.\n",
            "The relative quantization error of layer 20 is 0.24155716598033905.\n",
            "\n",
            "Bits 8, Effective Quantized Bit Size: 8.94889959353719\n",
            "Bits 8, Quantized Test Accuracy: 0.891\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 280.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9038989543914795.\n",
            "The relative quantization error of layer 0 is 0.008268644101917744.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2506.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.138666152954102.\n",
            "The relative quantization error of layer 1 is 0.021880408748984337.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2511.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.664865016937256.\n",
            "The relative quantization error of layer 2 is 0.030232707038521767.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2254.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.7823543548584.\n",
            "The relative quantization error of layer 3 is 0.044879619032144547.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1959.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.388952255249023.\n",
            "The relative quantization error of layer 4 is 0.06153858080506325.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1406.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.104398727416992.\n",
            "The relative quantization error of layer 5 is 0.0451284758746624.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2619.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.325951099395752.\n",
            "The relative quantization error of layer 6 is 0.03359365090727806.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 274.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.07483673095703.\n",
            "The relative quantization error of layer 7 is 0.13221415877342224.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2681.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.26479721069336.\n",
            "The relative quantization error of layer 8 is 0.06380880624055862.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2439.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.943042278289795.\n",
            "The relative quantization error of layer 9 is 0.07242691516876221.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1622.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 27.981931686401367.\n",
            "The relative quantization error of layer 10 is 0.07422546297311783.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2888.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.5348615646362305.\n",
            "The relative quantization error of layer 11 is 0.045094236731529236.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 588.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.525463104248047.\n",
            "The relative quantization error of layer 12 is 0.126621276140213.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2470.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.319664478302002.\n",
            "The relative quantization error of layer 13 is 0.03607557341456413.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2821.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.959059953689575.\n",
            "The relative quantization error of layer 14 is 0.05071870982646942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2818.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 13.805383682250977.\n",
            "The relative quantization error of layer 15 is 0.056099750101566315.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2859.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.0078272819519043.\n",
            "The relative quantization error of layer 16 is 0.03271927312016487.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1362.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 29.82168197631836.\n",
            "The relative quantization error of layer 17 is 0.18406742811203003.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2765.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.825990676879883.\n",
            "The relative quantization error of layer 18 is 0.03675837814807892.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2765.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.710608720779419.\n",
            "The relative quantization error of layer 19 is 0.1051974967122078.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3086.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 31.20798683166504.\n",
            "The relative quantization error of layer 20 is 0.22817574441432953.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 10, Effective Quantized Bit Size: 10.63193234414078\n",
            "Bits 10, Quantized Test Accuracy: 0.8904\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 301.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 3.004448890686035.\n",
            "The relative quantization error of layer 0 is 0.007955143228173256.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1345.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.025102615356445.\n",
            "The relative quantization error of layer 1 is 0.021586664021015167.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2477.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.759510040283203.\n",
            "The relative quantization error of layer 2 is 0.030453231185674667.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2185.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.34676170349121.\n",
            "The relative quantization error of layer 3 is 0.0441974401473999.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2211.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.731690406799316.\n",
            "The relative quantization error of layer 4 is 0.06392941623926163.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1597.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 32.488224029541016.\n",
            "The relative quantization error of layer 5 is 0.04702455550432205.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2719.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.384589195251465.\n",
            "The relative quantization error of layer 6 is 0.034017376601696014.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 297.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.16610717773438.\n",
            "The relative quantization error of layer 7 is 0.1321602314710617.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2704.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.031761169433594.\n",
            "The relative quantization error of layer 8 is 0.06411162763834.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2505.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.799180030822754.\n",
            "The relative quantization error of layer 9 is 0.07270363718271255.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2086.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.389568328857422.\n",
            "The relative quantization error of layer 10 is 0.07761792838573456.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3003.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.719224452972412.\n",
            "The relative quantization error of layer 11 is 0.04663502052426338.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 737.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 31.269081115722656.\n",
            "The relative quantization error of layer 12 is 0.13427020609378815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3206.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.573251247406006.\n",
            "The relative quantization error of layer 13 is 0.037266455590724945.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2788.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.0925543308258057.\n",
            "The relative quantization error of layer 14 is 0.052743036299943924.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2655.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 13.026747703552246.\n",
            "The relative quantization error of layer 15 is 0.05347880348563194.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2890.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.936079740524292.\n",
            "The relative quantization error of layer 16 is 0.03093876875936985.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1535.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 28.248558044433594.\n",
            "The relative quantization error of layer 17 is 0.1709136962890625.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3166.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.925055980682373.\n",
            "The relative quantization error of layer 18 is 0.03804551064968109.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2834.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.7436747550964355.\n",
            "The relative quantization error of layer 19 is 0.10742528736591339.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3139.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 29.858299255371094.\n",
            "The relative quantization error of layer 20 is 0.21640583872795105.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 12, Effective Quantized Bit Size: 12.626025397258376\n",
            "Bits 12, Quantized Test Accuracy: 0.8934\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 409.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 3.0158746242523193.\n",
            "The relative quantization error of layer 0 is 0.007999425753951073.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2488.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.593881607055664.\n",
            "The relative quantization error of layer 1 is 0.022691521793603897.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2557.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.489469528198242.\n",
            "The relative quantization error of layer 2 is 0.02970964089035988.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2177.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.556652069091797.\n",
            "The relative quantization error of layer 3 is 0.0446312315762043.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1960.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 12.097318649291992.\n",
            "The relative quantization error of layer 4 is 0.06616998463869095.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1497.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.40948486328125.\n",
            "The relative quantization error of layer 5 is 0.04543672874569893.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2678.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.319197654724121.\n",
            "The relative quantization error of layer 6 is 0.03336102142930031.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 270.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.00697326660156.\n",
            "The relative quantization error of layer 7 is 0.1325114369392395.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3084.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.146476745605469.\n",
            "The relative quantization error of layer 8 is 0.06405386328697205.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2661.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.940392017364502.\n",
            "The relative quantization error of layer 9 is 0.07333392649888992.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2114.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 27.568445205688477.\n",
            "The relative quantization error of layer 10 is 0.07288812845945358.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2988.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.390329360961914.\n",
            "The relative quantization error of layer 11 is 0.044403985142707825.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 734.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 28.95638656616211.\n",
            "The relative quantization error of layer 12 is 0.12479700148105621.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3386.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.160343647003174.\n",
            "The relative quantization error of layer 13 is 0.035101260989904404.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3033.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.979743003845215.\n",
            "The relative quantization error of layer 14 is 0.050664834678173065.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2663.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.614057540893555.\n",
            "The relative quantization error of layer 15 is 0.05184045433998108.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2684.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.7904961109161377.\n",
            "The relative quantization error of layer 16 is 0.029096301645040512.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1550.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 26.844961166381836.\n",
            "The relative quantization error of layer 17 is 0.16090084612369537.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3071.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.228673934936523.\n",
            "The relative quantization error of layer 18 is 0.03525905683636665.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2662.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.722792387008667.\n",
            "The relative quantization error of layer 19 is 0.10633251070976257.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3268.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 30.616661071777344.\n",
            "The relative quantization error of layer 20 is 0.22117754817008972.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 14, Effective Quantized Bit Size: 14.187965199810058\n",
            "Bits 14, Quantized Test Accuracy: 0.894\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 326.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.977328300476074.\n",
            "The relative quantization error of layer 0 is 0.008377866819500923.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1321.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.120885848999023.\n",
            "The relative quantization error of layer 1 is 0.02177751250565052.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2460.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.797516822814941.\n",
            "The relative quantization error of layer 2 is 0.0307499747723341.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1974.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 23.986574172973633.\n",
            "The relative quantization error of layer 3 is 0.04549620300531387.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2125.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.34270191192627.\n",
            "The relative quantization error of layer 4 is 0.06268367171287537.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1638.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.045490264892578.\n",
            "The relative quantization error of layer 5 is 0.04500668868422508.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2672.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.32633638381958.\n",
            "The relative quantization error of layer 6 is 0.03364028036594391.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 282.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 102.5428237915039.\n",
            "The relative quantization error of layer 7 is 0.1313268095254898.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2981.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.265867233276367.\n",
            "The relative quantization error of layer 8 is 0.0644722655415535.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2513.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.202618598937988.\n",
            "The relative quantization error of layer 9 is 0.07621500641107559.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2004.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 29.99654197692871.\n",
            "The relative quantization error of layer 10 is 0.07983101159334183.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3033.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.865023136138916.\n",
            "The relative quantization error of layer 11 is 0.048288073390722275.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 742.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 33.47256851196289.\n",
            "The relative quantization error of layer 12 is 0.14388470351696014.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2765.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 7.082459926605225.\n",
            "The relative quantization error of layer 13 is 0.03988366946578026.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2703.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.2827420234680176.\n",
            "The relative quantization error of layer 14 is 0.05530096963047981.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2986.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 13.668827056884766.\n",
            "The relative quantization error of layer 15 is 0.055344898253679276.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2933.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.044740915298462.\n",
            "The relative quantization error of layer 16 is 0.03347668796777725.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1417.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 30.5371036529541.\n",
            "The relative quantization error of layer 17 is 0.18349669873714447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2787.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.743584156036377.\n",
            "The relative quantization error of layer 18 is 0.037175197154283524.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2730.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8515052795410156.\n",
            "The relative quantization error of layer 19 is 0.11211901903152466.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3092.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 32.679664611816406.\n",
            "The relative quantization error of layer 20 is 0.23794104158878326.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 16, Effective Quantized Bit Size: 15.825875906862759\n",
            "Bits 16, Quantized Test Accuracy: 0.8888\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 326.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.8929848670959473.\n",
            "The relative quantization error of layer 0 is 0.008462498895823956.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2519.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.336386680603027.\n",
            "The relative quantization error of layer 1 is 0.022182749584317207.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2442.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.9270148277282715.\n",
            "The relative quantization error of layer 2 is 0.03126020357012749.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1405.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.27971839904785.\n",
            "The relative quantization error of layer 3 is 0.04589423909783363.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2320.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.813497543334961.\n",
            "The relative quantization error of layer 4 is 0.06469012796878815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1531.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.159324645996094.\n",
            "The relative quantization error of layer 5 is 0.045485448092222214.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2720.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.204638481140137.\n",
            "The relative quantization error of layer 6 is 0.03224052116274834.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 290.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.20207977294922.\n",
            "The relative quantization error of layer 7 is 0.13224758207798004.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2832.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 14.894118309020996.\n",
            "The relative quantization error of layer 8 is 0.06349236518144608.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2610.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.636012077331543.\n",
            "The relative quantization error of layer 9 is 0.06922196596860886.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1976.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 27.589914321899414.\n",
            "The relative quantization error of layer 10 is 0.07267402857542038.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2811.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.264476776123047.\n",
            "The relative quantization error of layer 11 is 0.04264147952198982.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 609.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.91469383239746.\n",
            "The relative quantization error of layer 12 is 0.12840884923934937.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2438.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.3439154624938965.\n",
            "The relative quantization error of layer 13 is 0.03555487096309662.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2818.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.9796814918518066.\n",
            "The relative quantization error of layer 14 is 0.049652598798274994.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2685.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.070813179016113.\n",
            "The relative quantization error of layer 15 is 0.04914645478129387.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2999.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.856755018234253.\n",
            "The relative quantization error of layer 16 is 0.02901458367705345.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1745.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 26.97138023376465.\n",
            "The relative quantization error of layer 17 is 0.159828782081604.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3045.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.293733596801758.\n",
            "The relative quantization error of layer 18 is 0.034540168941020966.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2610.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.765138864517212.\n",
            "The relative quantization error of layer 19 is 0.10855582356452942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3204.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 30.69622039794922.\n",
            "The relative quantization error of layer 20 is 0.22829285264015198.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 18, Effective Quantized Bit Size: 17.554970027641048\n",
            "Bits 18, Quantized Test Accuracy: 0.8936\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 284.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.923593044281006.\n",
            "The relative quantization error of layer 0 is 0.008365603163838387.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2183.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 10.994545936584473.\n",
            "The relative quantization error of layer 1 is 0.021570321172475815.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1427.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.568013668060303.\n",
            "The relative quantization error of layer 2 is 0.02977660298347473.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1231.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.603139877319336.\n",
            "The relative quantization error of layer 3 is 0.046624138951301575.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1165.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 12.220954895019531.\n",
            "The relative quantization error of layer 4 is 0.06679761409759521.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1570.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 33.12971115112305.\n",
            "The relative quantization error of layer 5 is 0.04763594642281532.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2460.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.408443927764893.\n",
            "The relative quantization error of layer 6 is 0.03410894051194191.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 266.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 104.29991912841797.\n",
            "The relative quantization error of layer 7 is 0.13327421247959137.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1591.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.210519790649414.\n",
            "The relative quantization error of layer 8 is 0.06410625576972961.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1983.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.718453884124756.\n",
            "The relative quantization error of layer 9 is 0.07021208107471466.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1709.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 27.34658432006836.\n",
            "The relative quantization error of layer 10 is 0.07271353155374527.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2137.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.3029303550720215.\n",
            "The relative quantization error of layer 11 is 0.043878715485334396.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 695.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.768329620361328.\n",
            "The relative quantization error of layer 12 is 0.12747244536876678.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2733.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.390563011169434.\n",
            "The relative quantization error of layer 13 is 0.03615433722734451.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2676.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.937863826751709.\n",
            "The relative quantization error of layer 14 is 0.05004693940281868.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2240.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.76074504852295.\n",
            "The relative quantization error of layer 15 is 0.05163083225488663.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2952.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.9018235206604004.\n",
            "The relative quantization error of layer 16 is 0.03016887791454792.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1579.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 27.579458236694336.\n",
            "The relative quantization error of layer 17 is 0.16389566659927368.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3003.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.806891918182373.\n",
            "The relative quantization error of layer 18 is 0.03775416687130928.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2702.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8279521465301514.\n",
            "The relative quantization error of layer 19 is 0.1084461659193039.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2882.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 28.949981689453125.\n",
            "The relative quantization error of layer 20 is 0.21031160652637482.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 20, Effective Quantized Bit Size: 19.095648973927062\n",
            "Bits 20, Quantized Test Accuracy: 0.8928\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 340.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9270544052124023.\n",
            "The relative quantization error of layer 0 is 0.008432799018919468.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1201.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 10.690994262695312.\n",
            "The relative quantization error of layer 1 is 0.02096106857061386.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2761.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.661298751831055.\n",
            "The relative quantization error of layer 2 is 0.030216949060559273.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2509.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.293075561523438.\n",
            "The relative quantization error of layer 3 is 0.0459832102060318.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1983.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 12.19894790649414.\n",
            "The relative quantization error of layer 4 is 0.06766020506620407.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1659.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.971397399902344.\n",
            "The relative quantization error of layer 5 is 0.04622884839773178.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2858.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.435564041137695.\n",
            "The relative quantization error of layer 6 is 0.034284431487321854.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 288.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 102.92401885986328.\n",
            "The relative quantization error of layer 7 is 0.13152949512004852.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3097.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.138986587524414.\n",
            "The relative quantization error of layer 8 is 0.06377335637807846.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2753.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.720657825469971.\n",
            "The relative quantization error of layer 9 is 0.07030565291643143.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2339.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 30.16020393371582.\n",
            "The relative quantization error of layer 10 is 0.08082035183906555.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3201.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.001717567443848.\n",
            "The relative quantization error of layer 11 is 0.04901724308729172.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 707.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 32.63803482055664.\n",
            "The relative quantization error of layer 12 is 0.14077208936214447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2894.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.746683597564697.\n",
            "The relative quantization error of layer 13 is 0.03907138481736183.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3130.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.268627882003784.\n",
            "The relative quantization error of layer 14 is 0.05549425259232521.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2819.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 13.9525785446167.\n",
            "The relative quantization error of layer 15 is 0.056781720370054245.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2354.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.953220009803772.\n",
            "The relative quantization error of layer 16 is 0.031110135838389397.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 836.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 30.43597984313965.\n",
            "The relative quantization error of layer 17 is 0.18284308910369873.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2783.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.1354827880859375.\n",
            "The relative quantization error of layer 18 is 0.038622718304395676.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 1733.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.817784547805786.\n",
            "The relative quantization error of layer 19 is 0.10781476646661758.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3236.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 32.785587310791016.\n",
            "The relative quantization error of layer 20 is 0.24269528687000275.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 22, Effective Quantized Bit Size: 20.197547834868242\n",
            "Bits 22, Quantized Test Accuracy: 0.8888\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 468.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.925710916519165.\n",
            "The relative quantization error of layer 0 is 0.008400969207286835.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1322.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.051159858703613.\n",
            "The relative quantization error of layer 1 is 0.021678758785128593.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2496.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.29067325592041.\n",
            "The relative quantization error of layer 2 is 0.02874155342578888.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2124.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.783954620361328.\n",
            "The relative quantization error of layer 3 is 0.046713922172784805.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2219.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.750299453735352.\n",
            "The relative quantization error of layer 4 is 0.06396962702274323.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1758.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.47983169555664.\n",
            "The relative quantization error of layer 5 is 0.045454856008291245.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2794.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.555065155029297.\n",
            "The relative quantization error of layer 6 is 0.03480706363916397.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 277.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.9100112915039.\n",
            "The relative quantization error of layer 7 is 0.1327093541622162.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2874.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.115729331970215.\n",
            "The relative quantization error of layer 8 is 0.06380219012498856.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2601.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.1810526847839355.\n",
            "The relative quantization error of layer 9 is 0.07518628984689713.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2166.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 28.194311141967773.\n",
            "The relative quantization error of layer 10 is 0.07457426190376282.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2844.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.542384147644043.\n",
            "The relative quantization error of layer 11 is 0.04533064365386963.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 733.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.96132469177246.\n",
            "The relative quantization error of layer 12 is 0.128690704703331.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3200.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.697242736816406.\n",
            "The relative quantization error of layer 13 is 0.03811665624380112.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2936.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.0041630268096924.\n",
            "The relative quantization error of layer 14 is 0.05023416876792908.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2603.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.859991073608398.\n",
            "The relative quantization error of layer 15 is 0.05278884246945381.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2835.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.8454484939575195.\n",
            "The relative quantization error of layer 16 is 0.029618514701724052.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1610.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 27.702945709228516.\n",
            "The relative quantization error of layer 17 is 0.1656949371099472.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3086.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.483841896057129.\n",
            "The relative quantization error of layer 18 is 0.034809552133083344.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3042.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.722804069519043.\n",
            "The relative quantization error of layer 19 is 0.10541888326406479.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3267.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 27.742822647094727.\n",
            "The relative quantization error of layer 20 is 0.2013823539018631.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 24, Effective Quantized Bit Size: 20.38229734448712\n",
            "Bits 24, Quantized Test Accuracy: 0.8924\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 240.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9711952209472656.\n",
            "The relative quantization error of layer 0 is 0.008435201831161976.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2507.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 11.315180778503418.\n",
            "The relative quantization error of layer 1 is 0.022251557558774948.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2191.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.532960891723633.\n",
            "The relative quantization error of layer 2 is 0.029751896858215332.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1728.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.186925888061523.\n",
            "The relative quantization error of layer 3 is 0.04593554511666298.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2443.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.541033744812012.\n",
            "The relative quantization error of layer 4 is 0.06286589801311493.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1564.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.60711669921875.\n",
            "The relative quantization error of layer 5 is 0.04610319435596466.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2864.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.143178939819336.\n",
            "The relative quantization error of layer 6 is 0.03257245942950249.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 288.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 102.95454406738281.\n",
            "The relative quantization error of layer 7 is 0.1315261274576187.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3268.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 14.837437629699707.\n",
            "The relative quantization error of layer 8 is 0.06218838319182396.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2963.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 7.389004707336426.\n",
            "The relative quantization error of layer 9 is 0.07824244350194931.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2295.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 30.879037857055664.\n",
            "The relative quantization error of layer 10 is 0.08207827061414719.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3211.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 6.09996223449707.\n",
            "The relative quantization error of layer 11 is 0.0492936410009861.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 788.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 32.62150955200195.\n",
            "The relative quantization error of layer 12 is 0.14018508791923523.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3455.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.986245632171631.\n",
            "The relative quantization error of layer 13 is 0.04001816362142563.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2877.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.505516767501831.\n",
            "The relative quantization error of layer 14 is 0.05851956084370613.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2574.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 13.869468688964844.\n",
            "The relative quantization error of layer 15 is 0.05724375694990158.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2712.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.1538004875183105.\n",
            "The relative quantization error of layer 16 is 0.03475484997034073.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1654.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 30.122821807861328.\n",
            "The relative quantization error of layer 17 is 0.18139107525348663.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3081.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.959440231323242.\n",
            "The relative quantization error of layer 18 is 0.039072342216968536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3016.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.87445330619812.\n",
            "The relative quantization error of layer 19 is 0.11099207401275635.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3088.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 32.32337188720703.\n",
            "The relative quantization error of layer 20 is 0.23785273730754852.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 26, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 26, Quantized Test Accuracy: 0.8922\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 241.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9228079319000244.\n",
            "The relative quantization error of layer 0 is 0.008241481147706509.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1365.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 10.930720329284668.\n",
            "The relative quantization error of layer 1 is 0.02147139422595501.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2477.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.525959014892578.\n",
            "The relative quantization error of layer 2 is 0.029574288055300713.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2389.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.082849502563477.\n",
            "The relative quantization error of layer 3 is 0.04553159698843956.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2127.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.237444877624512.\n",
            "The relative quantization error of layer 4 is 0.0618126206099987.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1593.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 32.23233413696289.\n",
            "The relative quantization error of layer 5 is 0.04681339114904404.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2805.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.524768829345703.\n",
            "The relative quantization error of layer 6 is 0.03438116982579231.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 279.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.0668716430664.\n",
            "The relative quantization error of layer 7 is 0.13178619742393494.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3005.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 15.099709510803223.\n",
            "The relative quantization error of layer 8 is 0.06402865797281265.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2874.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.954866886138916.\n",
            "The relative quantization error of layer 9 is 0.07339903712272644.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2242.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 28.724483489990234.\n",
            "The relative quantization error of layer 10 is 0.07642723619937897.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3087.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.451231956481934.\n",
            "The relative quantization error of layer 11 is 0.0455324612557888.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 755.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.742040634155273.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The relative quantization error of layer 12 is 0.12752112746238708.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3129.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.329458236694336.\n",
            "The relative quantization error of layer 13 is 0.03608038276433945.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2884.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.989546775817871.\n",
            "The relative quantization error of layer 14 is 0.050358716398477554.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3131.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.477206230163574.\n",
            "The relative quantization error of layer 15 is 0.050974976271390915.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2860.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.819632649421692.\n",
            "The relative quantization error of layer 16 is 0.028899919241666794.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1318.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 26.31940269470215.\n",
            "The relative quantization error of layer 17 is 0.16001370549201965.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3221.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.119537830352783.\n",
            "The relative quantization error of layer 18 is 0.033381443470716476.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3159.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.7959189414978027.\n",
            "The relative quantization error of layer 19 is 0.10784116387367249.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3148.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 28.334257125854492.\n",
            "The relative quantization error of layer 20 is 0.20575809478759766.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 28, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 28, Quantized Test Accuracy: 0.8917\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 305.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.9909298419952393.\n",
            "The relative quantization error of layer 0 is 0.008199208416044712.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1186.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 10.864128112792969.\n",
            "The relative quantization error of layer 1 is 0.021341731771826744.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2593.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 7.819016456604004.\n",
            "The relative quantization error of layer 2 is 0.030839771032333374.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2176.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 24.126468658447266.\n",
            "The relative quantization error of layer 3 is 0.04561483487486839.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2242.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 11.311098098754883.\n",
            "The relative quantization error of layer 4 is 0.06184756010770798.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1673.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 31.839677810668945.\n",
            "The relative quantization error of layer 5 is 0.04572629928588867.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3016.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.412407398223877.\n",
            "The relative quantization error of layer 6 is 0.03421517089009285.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 349.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 103.46207427978516.\n",
            "The relative quantization error of layer 7 is 0.13266800343990326.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3130.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 14.912757873535156.\n",
            "The relative quantization error of layer 8 is 0.06317584961652756.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3127.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.496058464050293.\n",
            "The relative quantization error of layer 9 is 0.06808827817440033.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2312.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 26.918176651000977.\n",
            "The relative quantization error of layer 10 is 0.07181569933891296.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3318.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.149537563323975.\n",
            "The relative quantization error of layer 11 is 0.04244539514183998.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 735.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 29.28129768371582.\n",
            "The relative quantization error of layer 12 is 0.12627676129341125.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3041.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.02067756652832.\n",
            "The relative quantization error of layer 13 is 0.03448651731014252.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2957.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 3.030878782272339.\n",
            "The relative quantization error of layer 14 is 0.050979554653167725.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3200.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 12.653983116149902.\n",
            "The relative quantization error of layer 15 is 0.050503235310316086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3029.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.8131616115570068.\n",
            "The relative quantization error of layer 16 is 0.02925306186079979.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1267.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 26.840904235839844.\n",
            "The relative quantization error of layer 17 is 0.1628260761499405.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 2085.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.220644474029541.\n",
            "The relative quantization error of layer 18 is 0.03500693663954735.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3056.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.59016489982605.\n",
            "The relative quantization error of layer 19 is 0.10172855108976364.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1913.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 29.119821548461914.\n",
            "The relative quantization error of layer 20 is 0.21167895197868347.\n",
            "\n",
            "Bits 30, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 30, Quantized Test Accuracy: 0.8963\n",
            "Results saved to checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\n"
          ]
        }
      ],
      "source": [
        "bits_list = range(2, 31, 2)  # 2, 4, ..., 30\n",
        "\n",
        "def calculate_bit_size(model):\n",
        "    \"\"\"\n",
        "    Calculate the effective bit size of a quantized model.\n",
        "    \n",
        "    Parameters:\n",
        "        model: nn.Module\n",
        "            The quantized neural network model.\n",
        "    \n",
        "    Returns:\n",
        "        float: The average bit size across all layers.\n",
        "    \"\"\"\n",
        "    total_bits = 0\n",
        "    total_params = 0\n",
        "    \n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Calculate unique values and their count\n",
        "            unique_values = torch.unique(param.data).cpu().numpy()\n",
        "            num_unique_values = len(unique_values)\n",
        "            \n",
        "            # Calculate bit size for this layer\n",
        "            layer_bits = np.ceil(np.log2(num_unique_values)) if num_unique_values > 1 else 1\n",
        "            total_bits += layer_bits * param.numel()\n",
        "            total_params += param.numel()\n",
        "    \n",
        "    # Return average bit size across all parameters\n",
        "    return total_bits / total_params if total_params > 0 else 0\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        student_net.model,\n",
        "        'resnet18',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=1.16,\n",
        "        cnn_alphabet_scalar=1.16,\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, 0.9152, quantized_test_accuracy, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0.0\n",
            "0.0 11173962 23520842\n",
            "[Epoch 1, Batch 100/372] Train Loss: 12.237, Train Accuracy: 0.086\n",
            "[Epoch 1, Batch 200/372] Train Loss: 4.760, Train Accuracy: 0.234\n",
            "[Epoch 1, Batch 300/372] Train Loss: 7.098, Train Accuracy: 0.602\n",
            "Epoch 1 Validation Accuracy: 0.640\n",
            "[Epoch 2, Batch 100/372] Train Loss: 5.812, Train Accuracy: 0.727\n",
            "[Epoch 2, Batch 200/372] Train Loss: 4.924, Train Accuracy: 0.086\n",
            "[Epoch 2, Batch 300/372] Train Loss: 3.587, Train Accuracy: 0.328\n",
            "Epoch 2 Validation Accuracy: 0.739\n",
            "[Epoch 3, Batch 100/372] Train Loss: 2.799, Train Accuracy: 0.844\n",
            "[Epoch 3, Batch 200/372] Train Loss: 2.914, Train Accuracy: 0.664\n",
            "[Epoch 3, Batch 300/372] Train Loss: 2.755, Train Accuracy: 0.797\n",
            "Epoch 3 Validation Accuracy: 0.800\n",
            "[Epoch 4, Batch 100/372] Train Loss: 3.705, Train Accuracy: 0.336\n",
            "[Epoch 4, Batch 200/372] Train Loss: 2.659, Train Accuracy: 0.719\n",
            "[Epoch 4, Batch 300/372] Train Loss: 3.255, Train Accuracy: 0.102\n",
            "Epoch 4 Validation Accuracy: 0.816\n",
            "[Epoch 5, Batch 100/372] Train Loss: 3.493, Train Accuracy: 0.078\n",
            "[Epoch 5, Batch 200/372] Train Loss: 2.840, Train Accuracy: 0.750\n",
            "[Epoch 5, Batch 300/372] Train Loss: 2.968, Train Accuracy: 0.109\n",
            "Epoch 5 Validation Accuracy: 0.832\n",
            "[Epoch 6, Batch 100/372] Train Loss: 2.474, Train Accuracy: 0.133\n",
            "[Epoch 6, Batch 200/372] Train Loss: 2.951, Train Accuracy: 0.148\n",
            "[Epoch 6, Batch 300/372] Train Loss: 2.703, Train Accuracy: 0.117\n",
            "Epoch 6 Validation Accuracy: 0.847\n",
            "[Epoch 7, Batch 100/372] Train Loss: 2.365, Train Accuracy: 0.133\n",
            "[Epoch 7, Batch 200/372] Train Loss: 2.690, Train Accuracy: 0.086\n",
            "[Epoch 7, Batch 300/372] Train Loss: 2.829, Train Accuracy: 0.609\n",
            "Epoch 7 Validation Accuracy: 0.846\n",
            "[Epoch 8, Batch 100/372] Train Loss: 2.501, Train Accuracy: 0.664\n",
            "[Epoch 8, Batch 200/372] Train Loss: 2.072, Train Accuracy: 0.133\n",
            "[Epoch 8, Batch 300/372] Train Loss: 2.237, Train Accuracy: 0.773\n",
            "Epoch 8 Validation Accuracy: 0.858\n",
            "[Epoch 9, Batch 100/372] Train Loss: 2.503, Train Accuracy: 0.195\n",
            "[Epoch 9, Batch 200/372] Train Loss: 2.395, Train Accuracy: 0.117\n",
            "[Epoch 9, Batch 300/372] Train Loss: 2.954, Train Accuracy: 0.781\n",
            "Epoch 9 Validation Accuracy: 0.862\n",
            "[Epoch 10, Batch 100/372] Train Loss: 2.271, Train Accuracy: 0.125\n",
            "[Epoch 10, Batch 200/372] Train Loss: 2.810, Train Accuracy: 0.203\n",
            "[Epoch 10, Batch 300/372] Train Loss: 2.727, Train Accuracy: 0.188\n",
            "Epoch 10 Validation Accuracy: 0.857\n",
            "[Epoch 11, Batch 100/372] Train Loss: 2.880, Train Accuracy: 0.266\n",
            "[Epoch 11, Batch 200/372] Train Loss: 2.778, Train Accuracy: 0.320\n",
            "[Epoch 11, Batch 300/372] Train Loss: 2.210, Train Accuracy: 0.109\n",
            "Epoch 11 Validation Accuracy: 0.854\n",
            "[Epoch 12, Batch 100/372] Train Loss: 2.048, Train Accuracy: 0.867\n",
            "[Epoch 12, Batch 200/372] Train Loss: 2.627, Train Accuracy: 0.375\n",
            "[Epoch 12, Batch 300/372] Train Loss: 2.132, Train Accuracy: 0.820\n",
            "Epoch 12 Validation Accuracy: 0.872\n",
            "[Epoch 13, Batch 100/372] Train Loss: 3.036, Train Accuracy: 0.516\n",
            "[Epoch 13, Batch 200/372] Train Loss: 2.286, Train Accuracy: 0.805\n",
            "[Epoch 13, Batch 300/372] Train Loss: 2.326, Train Accuracy: 0.250\n",
            "Epoch 13 Validation Accuracy: 0.819\n",
            "[Epoch 14, Batch 100/372] Train Loss: 2.032, Train Accuracy: 0.133\n",
            "[Epoch 14, Batch 200/372] Train Loss: 1.988, Train Accuracy: 0.141\n",
            "[Epoch 14, Batch 300/372] Train Loss: 2.261, Train Accuracy: 0.188\n",
            "Epoch 14 Validation Accuracy: 0.854\n",
            "[Epoch 15, Batch 100/372] Train Loss: 1.913, Train Accuracy: 0.844\n",
            "[Epoch 15, Batch 200/372] Train Loss: 2.234, Train Accuracy: 0.781\n",
            "[Epoch 15, Batch 300/372] Train Loss: 2.005, Train Accuracy: 0.820\n",
            "Epoch 15 Validation Accuracy: 0.897\n",
            "[Epoch 16, Batch 100/372] Train Loss: 2.560, Train Accuracy: 0.453\n",
            "[Epoch 16, Batch 200/372] Train Loss: 1.639, Train Accuracy: 0.094\n",
            "[Epoch 16, Batch 300/372] Train Loss: 2.221, Train Accuracy: 0.906\n",
            "Epoch 16 Validation Accuracy: 0.884\n",
            "[Epoch 17, Batch 100/372] Train Loss: 1.812, Train Accuracy: 0.938\n",
            "[Epoch 17, Batch 200/372] Train Loss: 1.685, Train Accuracy: 0.156\n",
            "[Epoch 17, Batch 300/372] Train Loss: 2.732, Train Accuracy: 0.359\n",
            "Epoch 17 Validation Accuracy: 0.878\n",
            "[Epoch 18, Batch 100/372] Train Loss: 2.440, Train Accuracy: 0.922\n",
            "[Epoch 18, Batch 200/372] Train Loss: 1.868, Train Accuracy: 0.930\n",
            "[Epoch 18, Batch 300/372] Train Loss: 2.236, Train Accuracy: 0.773\n",
            "Epoch 18 Validation Accuracy: 0.884\n",
            "[Epoch 19, Batch 100/372] Train Loss: 2.006, Train Accuracy: 0.930\n",
            "[Epoch 19, Batch 200/372] Train Loss: 1.517, Train Accuracy: 0.930\n",
            "[Epoch 19, Batch 300/372] Train Loss: 3.134, Train Accuracy: 0.312\n",
            "Epoch 19 Validation Accuracy: 0.893\n",
            "[Epoch 20, Batch 100/372] Train Loss: 1.734, Train Accuracy: 0.133\n",
            "[Epoch 20, Batch 200/372] Train Loss: 2.236, Train Accuracy: 0.211\n",
            "[Epoch 20, Batch 300/372] Train Loss: 1.574, Train Accuracy: 0.086\n",
            "Epoch 20 Validation Accuracy: 0.876\n",
            "[Epoch 21, Batch 100/372] Train Loss: 1.343, Train Accuracy: 0.930\n",
            "[Epoch 21, Batch 200/372] Train Loss: 1.786, Train Accuracy: 0.898\n",
            "[Epoch 21, Batch 300/372] Train Loss: 2.339, Train Accuracy: 0.633\n",
            "Epoch 21 Validation Accuracy: 0.888\n",
            "[Epoch 22, Batch 100/372] Train Loss: 2.811, Train Accuracy: 0.594\n",
            "[Epoch 22, Batch 200/372] Train Loss: 2.793, Train Accuracy: 0.562\n",
            "[Epoch 22, Batch 300/372] Train Loss: 2.586, Train Accuracy: 0.367\n",
            "Epoch 22 Validation Accuracy: 0.903\n",
            "[Epoch 23, Batch 100/372] Train Loss: 2.499, Train Accuracy: 0.414\n",
            "[Epoch 23, Batch 200/372] Train Loss: 1.912, Train Accuracy: 0.656\n",
            "[Epoch 23, Batch 300/372] Train Loss: 1.706, Train Accuracy: 0.164\n",
            "Epoch 23 Validation Accuracy: 0.895\n",
            "[Epoch 24, Batch 100/372] Train Loss: 1.645, Train Accuracy: 0.148\n",
            "[Epoch 24, Batch 200/372] Train Loss: 2.376, Train Accuracy: 0.562\n",
            "[Epoch 24, Batch 300/372] Train Loss: 2.171, Train Accuracy: 0.781\n",
            "Epoch 24 Validation Accuracy: 0.893\n",
            "[Epoch 25, Batch 100/372] Train Loss: 1.082, Train Accuracy: 0.164\n",
            "[Epoch 25, Batch 200/372] Train Loss: 1.820, Train Accuracy: 0.906\n",
            "[Epoch 25, Batch 300/372] Train Loss: 1.292, Train Accuracy: 0.930\n",
            "Epoch 25 Validation Accuracy: 0.899\n",
            "Checkpoint saved at epoch 25: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_25.tar\n",
            "[Epoch 26, Batch 100/372] Train Loss: 1.946, Train Accuracy: 0.188\n",
            "[Epoch 26, Batch 200/372] Train Loss: 2.002, Train Accuracy: 0.148\n",
            "[Epoch 26, Batch 300/372] Train Loss: 1.368, Train Accuracy: 0.117\n",
            "Epoch 26 Validation Accuracy: 0.893\n",
            "[Epoch 27, Batch 100/372] Train Loss: 2.281, Train Accuracy: 0.727\n",
            "[Epoch 27, Batch 200/372] Train Loss: 1.367, Train Accuracy: 0.141\n",
            "[Epoch 27, Batch 300/372] Train Loss: 1.547, Train Accuracy: 0.906\n",
            "Epoch 27 Validation Accuracy: 0.895\n",
            "[Epoch 28, Batch 100/372] Train Loss: 1.605, Train Accuracy: 0.891\n",
            "[Epoch 28, Batch 200/372] Train Loss: 2.274, Train Accuracy: 0.633\n",
            "[Epoch 28, Batch 300/372] Train Loss: 1.222, Train Accuracy: 0.148\n",
            "Epoch 28 Validation Accuracy: 0.897\n",
            "[Epoch 29, Batch 100/372] Train Loss: 2.291, Train Accuracy: 0.320\n",
            "[Epoch 29, Batch 200/372] Train Loss: 1.204, Train Accuracy: 0.953\n",
            "[Epoch 29, Batch 300/372] Train Loss: 1.694, Train Accuracy: 0.125\n",
            "Epoch 29 Validation Accuracy: 0.902\n",
            "[Epoch 30, Batch 100/372] Train Loss: 1.634, Train Accuracy: 0.906\n",
            "[Epoch 30, Batch 200/372] Train Loss: 1.216, Train Accuracy: 0.117\n",
            "[Epoch 30, Batch 300/372] Train Loss: 1.456, Train Accuracy: 0.898\n",
            "Epoch 30 Validation Accuracy: 0.902\n",
            "[Epoch 31, Batch 100/372] Train Loss: 1.542, Train Accuracy: 0.164\n",
            "[Epoch 31, Batch 200/372] Train Loss: 1.811, Train Accuracy: 0.812\n",
            "[Epoch 31, Batch 300/372] Train Loss: 1.157, Train Accuracy: 0.969\n",
            "Epoch 31 Validation Accuracy: 0.904\n",
            "[Epoch 32, Batch 100/372] Train Loss: 1.211, Train Accuracy: 0.070\n",
            "[Epoch 32, Batch 200/372] Train Loss: 1.196, Train Accuracy: 0.961\n",
            "[Epoch 32, Batch 300/372] Train Loss: 1.467, Train Accuracy: 0.914\n",
            "Epoch 32 Validation Accuracy: 0.905\n",
            "[Epoch 33, Batch 100/372] Train Loss: 2.258, Train Accuracy: 0.492\n",
            "[Epoch 33, Batch 200/372] Train Loss: 1.410, Train Accuracy: 0.898\n",
            "[Epoch 33, Batch 300/372] Train Loss: 1.233, Train Accuracy: 0.039\n",
            "Epoch 33 Validation Accuracy: 0.911\n",
            "[Epoch 34, Batch 100/372] Train Loss: 1.097, Train Accuracy: 0.156\n",
            "[Epoch 34, Batch 200/372] Train Loss: 1.694, Train Accuracy: 0.180\n",
            "[Epoch 34, Batch 300/372] Train Loss: 1.953, Train Accuracy: 0.758\n",
            "Epoch 34 Validation Accuracy: 0.908\n",
            "[Epoch 35, Batch 100/372] Train Loss: 2.360, Train Accuracy: 0.453\n",
            "[Epoch 35, Batch 200/372] Train Loss: 1.338, Train Accuracy: 0.945\n",
            "[Epoch 35, Batch 300/372] Train Loss: 1.282, Train Accuracy: 0.977\n",
            "Epoch 35 Validation Accuracy: 0.906\n",
            "[Epoch 36, Batch 100/372] Train Loss: 1.046, Train Accuracy: 0.977\n",
            "[Epoch 36, Batch 200/372] Train Loss: 1.071, Train Accuracy: 0.086\n",
            "[Epoch 36, Batch 300/372] Train Loss: 2.080, Train Accuracy: 0.203\n",
            "Epoch 36 Validation Accuracy: 0.900\n",
            "[Epoch 37, Batch 100/372] Train Loss: 1.121, Train Accuracy: 0.945\n",
            "[Epoch 37, Batch 200/372] Train Loss: 1.511, Train Accuracy: 0.117\n",
            "[Epoch 37, Batch 300/372] Train Loss: 1.013, Train Accuracy: 0.945\n",
            "Epoch 37 Validation Accuracy: 0.902\n",
            "[Epoch 38, Batch 100/372] Train Loss: 1.390, Train Accuracy: 0.938\n",
            "[Epoch 38, Batch 200/372] Train Loss: 2.567, Train Accuracy: 0.484\n",
            "[Epoch 38, Batch 300/372] Train Loss: 1.645, Train Accuracy: 0.117\n",
            "Epoch 38 Validation Accuracy: 0.905\n",
            "[Epoch 39, Batch 100/372] Train Loss: 0.964, Train Accuracy: 0.969\n",
            "[Epoch 39, Batch 200/372] Train Loss: 1.208, Train Accuracy: 0.062\n",
            "[Epoch 39, Batch 300/372] Train Loss: 1.260, Train Accuracy: 0.125\n",
            "Epoch 39 Validation Accuracy: 0.910\n",
            "[Epoch 40, Batch 100/372] Train Loss: 1.087, Train Accuracy: 0.984\n",
            "[Epoch 40, Batch 200/372] Train Loss: 1.659, Train Accuracy: 0.086\n",
            "[Epoch 40, Batch 300/372] Train Loss: 1.188, Train Accuracy: 0.086\n",
            "Epoch 40 Validation Accuracy: 0.909\n",
            "[Epoch 41, Batch 100/372] Train Loss: 0.911, Train Accuracy: 0.102\n",
            "[Epoch 41, Batch 200/372] Train Loss: 0.890, Train Accuracy: 0.969\n",
            "[Epoch 41, Batch 300/372] Train Loss: 0.985, Train Accuracy: 0.086\n",
            "Epoch 41 Validation Accuracy: 0.912\n",
            "[Epoch 42, Batch 100/372] Train Loss: 1.030, Train Accuracy: 0.930\n",
            "[Epoch 42, Batch 200/372] Train Loss: 1.337, Train Accuracy: 0.117\n",
            "[Epoch 42, Batch 300/372] Train Loss: 2.260, Train Accuracy: 0.414\n",
            "Epoch 42 Validation Accuracy: 0.910\n",
            "[Epoch 43, Batch 100/372] Train Loss: 0.921, Train Accuracy: 0.094\n",
            "[Epoch 43, Batch 200/372] Train Loss: 2.014, Train Accuracy: 0.516\n",
            "[Epoch 43, Batch 300/372] Train Loss: 1.899, Train Accuracy: 0.742\n",
            "Epoch 43 Validation Accuracy: 0.908\n",
            "[Epoch 44, Batch 100/372] Train Loss: 0.872, Train Accuracy: 0.094\n",
            "[Epoch 44, Batch 200/372] Train Loss: 0.926, Train Accuracy: 0.055\n",
            "[Epoch 44, Batch 300/372] Train Loss: 1.410, Train Accuracy: 0.914\n",
            "Epoch 44 Validation Accuracy: 0.908\n",
            "[Epoch 45, Batch 100/372] Train Loss: 0.997, Train Accuracy: 0.938\n",
            "[Epoch 45, Batch 200/372] Train Loss: 1.000, Train Accuracy: 0.930\n",
            "[Epoch 45, Batch 300/372] Train Loss: 1.305, Train Accuracy: 0.891\n",
            "Epoch 45 Validation Accuracy: 0.918\n",
            "[Epoch 46, Batch 100/372] Train Loss: 1.435, Train Accuracy: 0.156\n",
            "[Epoch 46, Batch 200/372] Train Loss: 1.172, Train Accuracy: 0.914\n",
            "[Epoch 46, Batch 300/372] Train Loss: 1.712, Train Accuracy: 0.156\n",
            "Epoch 46 Validation Accuracy: 0.916\n",
            "[Epoch 47, Batch 100/372] Train Loss: 0.888, Train Accuracy: 0.961\n",
            "[Epoch 47, Batch 200/372] Train Loss: 0.799, Train Accuracy: 0.117\n",
            "[Epoch 47, Batch 300/372] Train Loss: 0.988, Train Accuracy: 0.977\n",
            "Epoch 47 Validation Accuracy: 0.912\n",
            "[Epoch 48, Batch 100/372] Train Loss: 0.818, Train Accuracy: 0.117\n",
            "[Epoch 48, Batch 200/372] Train Loss: 0.934, Train Accuracy: 0.953\n",
            "[Epoch 48, Batch 300/372] Train Loss: 1.457, Train Accuracy: 0.906\n",
            "Epoch 48 Validation Accuracy: 0.916\n",
            "[Epoch 49, Batch 100/372] Train Loss: 1.740, Train Accuracy: 0.398\n",
            "[Epoch 49, Batch 200/372] Train Loss: 2.062, Train Accuracy: 0.227\n",
            "[Epoch 49, Batch 300/372] Train Loss: 1.994, Train Accuracy: 0.734\n",
            "Epoch 49 Validation Accuracy: 0.922\n",
            "[Epoch 50, Batch 100/372] Train Loss: 1.438, Train Accuracy: 0.109\n",
            "[Epoch 50, Batch 200/372] Train Loss: 1.605, Train Accuracy: 0.922\n",
            "[Epoch 50, Batch 300/372] Train Loss: 2.022, Train Accuracy: 0.258\n",
            "Epoch 50 Validation Accuracy: 0.921\n",
            "Checkpoint saved at epoch 50: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_50.tar\n",
            "[Epoch 51, Batch 100/372] Train Loss: 0.823, Train Accuracy: 0.984\n",
            "[Epoch 51, Batch 200/372] Train Loss: 0.760, Train Accuracy: 0.977\n",
            "[Epoch 51, Batch 300/372] Train Loss: 1.705, Train Accuracy: 0.133\n",
            "Epoch 51 Validation Accuracy: 0.909\n",
            "[Epoch 52, Batch 100/372] Train Loss: 1.482, Train Accuracy: 0.898\n",
            "[Epoch 52, Batch 200/372] Train Loss: 1.467, Train Accuracy: 0.891\n",
            "[Epoch 52, Batch 300/372] Train Loss: 1.169, Train Accuracy: 0.141\n",
            "Epoch 52 Validation Accuracy: 0.920\n",
            "[Epoch 53, Batch 100/372] Train Loss: 1.063, Train Accuracy: 0.125\n",
            "[Epoch 53, Batch 200/372] Train Loss: 1.492, Train Accuracy: 0.195\n",
            "[Epoch 53, Batch 300/372] Train Loss: 2.579, Train Accuracy: 0.500\n",
            "Epoch 53 Validation Accuracy: 0.918\n",
            "[Epoch 54, Batch 100/372] Train Loss: 2.152, Train Accuracy: 0.227\n",
            "[Epoch 54, Batch 200/372] Train Loss: 0.950, Train Accuracy: 0.109\n",
            "[Epoch 54, Batch 300/372] Train Loss: 2.531, Train Accuracy: 0.594\n",
            "Epoch 54 Validation Accuracy: 0.920\n",
            "[Epoch 55, Batch 100/372] Train Loss: 1.221, Train Accuracy: 0.094\n",
            "[Epoch 55, Batch 200/372] Train Loss: 2.118, Train Accuracy: 0.680\n",
            "[Epoch 55, Batch 300/372] Train Loss: 1.176, Train Accuracy: 0.086\n",
            "Epoch 55 Validation Accuracy: 0.919\n",
            "[Epoch 56, Batch 100/372] Train Loss: 2.091, Train Accuracy: 0.711\n",
            "[Epoch 56, Batch 200/372] Train Loss: 1.042, Train Accuracy: 0.984\n",
            "[Epoch 56, Batch 300/372] Train Loss: 1.152, Train Accuracy: 0.938\n",
            "Epoch 56 Validation Accuracy: 0.922\n",
            "[Epoch 57, Batch 100/372] Train Loss: 0.669, Train Accuracy: 0.109\n",
            "[Epoch 57, Batch 200/372] Train Loss: 0.955, Train Accuracy: 0.969\n",
            "[Epoch 57, Batch 300/372] Train Loss: 1.543, Train Accuracy: 0.164\n",
            "Epoch 57 Validation Accuracy: 0.912\n",
            "[Epoch 58, Batch 100/372] Train Loss: 1.586, Train Accuracy: 0.867\n",
            "[Epoch 58, Batch 200/372] Train Loss: 0.862, Train Accuracy: 0.969\n",
            "[Epoch 58, Batch 300/372] Train Loss: 1.672, Train Accuracy: 0.859\n",
            "Epoch 58 Validation Accuracy: 0.922\n",
            "[Epoch 59, Batch 100/372] Train Loss: 1.675, Train Accuracy: 0.805\n",
            "[Epoch 59, Batch 200/372] Train Loss: 0.731, Train Accuracy: 0.969\n",
            "[Epoch 59, Batch 300/372] Train Loss: 2.181, Train Accuracy: 0.367\n",
            "Epoch 59 Validation Accuracy: 0.924\n",
            "[Epoch 60, Batch 100/372] Train Loss: 0.856, Train Accuracy: 0.984\n",
            "[Epoch 60, Batch 200/372] Train Loss: 1.006, Train Accuracy: 0.125\n",
            "[Epoch 60, Batch 300/372] Train Loss: 2.073, Train Accuracy: 0.164\n",
            "Epoch 60 Validation Accuracy: 0.908\n",
            "[Epoch 61, Batch 100/372] Train Loss: 0.922, Train Accuracy: 0.086\n",
            "[Epoch 61, Batch 200/372] Train Loss: 1.778, Train Accuracy: 0.164\n",
            "[Epoch 61, Batch 300/372] Train Loss: 1.584, Train Accuracy: 0.234\n",
            "Epoch 61 Validation Accuracy: 0.922\n",
            "[Epoch 62, Batch 100/372] Train Loss: 1.987, Train Accuracy: 0.453\n",
            "[Epoch 62, Batch 200/372] Train Loss: 1.551, Train Accuracy: 0.859\n",
            "[Epoch 62, Batch 300/372] Train Loss: 1.967, Train Accuracy: 0.312\n",
            "Epoch 62 Validation Accuracy: 0.922\n",
            "[Epoch 63, Batch 100/372] Train Loss: 0.808, Train Accuracy: 0.969\n",
            "[Epoch 63, Batch 200/372] Train Loss: 1.364, Train Accuracy: 0.906\n",
            "[Epoch 63, Batch 300/372] Train Loss: 1.323, Train Accuracy: 0.969\n",
            "Epoch 63 Validation Accuracy: 0.918\n",
            "[Epoch 64, Batch 100/372] Train Loss: 0.993, Train Accuracy: 0.086\n",
            "[Epoch 64, Batch 200/372] Train Loss: 0.863, Train Accuracy: 0.086\n",
            "[Epoch 64, Batch 300/372] Train Loss: 1.863, Train Accuracy: 0.477\n",
            "Epoch 64 Validation Accuracy: 0.914\n",
            "[Epoch 65, Batch 100/372] Train Loss: 0.707, Train Accuracy: 0.953\n",
            "[Epoch 65, Batch 200/372] Train Loss: 1.592, Train Accuracy: 0.898\n",
            "[Epoch 65, Batch 300/372] Train Loss: 2.036, Train Accuracy: 0.453\n",
            "Epoch 65 Validation Accuracy: 0.918\n",
            "[Epoch 66, Batch 100/372] Train Loss: 0.686, Train Accuracy: 0.125\n",
            "[Epoch 66, Batch 200/372] Train Loss: 1.737, Train Accuracy: 0.242\n",
            "[Epoch 66, Batch 300/372] Train Loss: 2.150, Train Accuracy: 0.609\n",
            "Epoch 66 Validation Accuracy: 0.922\n",
            "[Epoch 67, Batch 100/372] Train Loss: 1.424, Train Accuracy: 0.141\n",
            "[Epoch 67, Batch 200/372] Train Loss: 1.046, Train Accuracy: 0.984\n",
            "[Epoch 67, Batch 300/372] Train Loss: 0.867, Train Accuracy: 0.953\n",
            "Epoch 67 Validation Accuracy: 0.922\n",
            "[Epoch 68, Batch 100/372] Train Loss: 0.763, Train Accuracy: 0.078\n",
            "[Epoch 68, Batch 200/372] Train Loss: 0.909, Train Accuracy: 0.133\n",
            "[Epoch 68, Batch 300/372] Train Loss: 1.276, Train Accuracy: 0.102\n",
            "Epoch 68 Validation Accuracy: 0.924\n",
            "[Epoch 69, Batch 100/372] Train Loss: 0.755, Train Accuracy: 0.117\n",
            "[Epoch 69, Batch 200/372] Train Loss: 1.218, Train Accuracy: 0.141\n",
            "[Epoch 69, Batch 300/372] Train Loss: 0.780, Train Accuracy: 0.109\n",
            "Epoch 69 Validation Accuracy: 0.922\n",
            "[Epoch 70, Batch 100/372] Train Loss: 0.958, Train Accuracy: 0.070\n",
            "[Epoch 70, Batch 200/372] Train Loss: 1.692, Train Accuracy: 0.195\n",
            "[Epoch 70, Batch 300/372] Train Loss: 1.970, Train Accuracy: 0.453\n",
            "Epoch 70 Validation Accuracy: 0.925\n",
            "[Epoch 71, Batch 100/372] Train Loss: 1.352, Train Accuracy: 0.242\n",
            "[Epoch 71, Batch 200/372] Train Loss: 0.914, Train Accuracy: 0.961\n",
            "[Epoch 71, Batch 300/372] Train Loss: 0.628, Train Accuracy: 0.977\n",
            "Epoch 71 Validation Accuracy: 0.924\n",
            "[Epoch 72, Batch 100/372] Train Loss: 0.634, Train Accuracy: 0.984\n",
            "[Epoch 72, Batch 200/372] Train Loss: 1.581, Train Accuracy: 0.180\n",
            "[Epoch 72, Batch 300/372] Train Loss: 0.780, Train Accuracy: 0.086\n",
            "Epoch 72 Validation Accuracy: 0.927\n",
            "[Epoch 73, Batch 100/372] Train Loss: 0.975, Train Accuracy: 0.141\n",
            "[Epoch 73, Batch 200/372] Train Loss: 1.945, Train Accuracy: 0.828\n",
            "[Epoch 73, Batch 300/372] Train Loss: 0.540, Train Accuracy: 0.094\n",
            "Epoch 73 Validation Accuracy: 0.919\n",
            "[Epoch 74, Batch 100/372] Train Loss: 1.939, Train Accuracy: 0.609\n",
            "[Epoch 74, Batch 200/372] Train Loss: 0.701, Train Accuracy: 0.109\n",
            "[Epoch 74, Batch 300/372] Train Loss: 1.788, Train Accuracy: 0.734\n",
            "Epoch 74 Validation Accuracy: 0.917\n",
            "[Epoch 75, Batch 100/372] Train Loss: 1.448, Train Accuracy: 0.914\n",
            "[Epoch 75, Batch 200/372] Train Loss: 0.678, Train Accuracy: 0.117\n",
            "[Epoch 75, Batch 300/372] Train Loss: 1.742, Train Accuracy: 0.156\n",
            "Epoch 75 Validation Accuracy: 0.917\n",
            "Checkpoint saved at epoch 75: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_75.tar\n",
            "[Epoch 76, Batch 100/372] Train Loss: 1.886, Train Accuracy: 0.180\n",
            "[Epoch 76, Batch 200/372] Train Loss: 1.205, Train Accuracy: 0.906\n",
            "[Epoch 76, Batch 300/372] Train Loss: 1.468, Train Accuracy: 0.156\n",
            "Epoch 76 Validation Accuracy: 0.928\n",
            "[Epoch 77, Batch 100/372] Train Loss: 1.922, Train Accuracy: 0.555\n",
            "[Epoch 77, Batch 200/372] Train Loss: 1.906, Train Accuracy: 0.305\n",
            "[Epoch 77, Batch 300/372] Train Loss: 0.703, Train Accuracy: 0.055\n",
            "Epoch 77 Validation Accuracy: 0.918\n",
            "[Epoch 78, Batch 100/372] Train Loss: 2.050, Train Accuracy: 0.406\n",
            "[Epoch 78, Batch 200/372] Train Loss: 0.740, Train Accuracy: 0.945\n",
            "[Epoch 78, Batch 300/372] Train Loss: 0.636, Train Accuracy: 0.984\n",
            "Epoch 78 Validation Accuracy: 0.926\n",
            "[Epoch 79, Batch 100/372] Train Loss: 0.674, Train Accuracy: 0.164\n",
            "[Epoch 79, Batch 200/372] Train Loss: 0.565, Train Accuracy: 0.070\n",
            "[Epoch 79, Batch 300/372] Train Loss: 0.706, Train Accuracy: 0.984\n",
            "Epoch 79 Validation Accuracy: 0.930\n",
            "[Epoch 80, Batch 100/372] Train Loss: 0.559, Train Accuracy: 0.172\n",
            "[Epoch 80, Batch 200/372] Train Loss: 1.258, Train Accuracy: 0.102\n",
            "[Epoch 80, Batch 300/372] Train Loss: 1.856, Train Accuracy: 0.477\n",
            "Epoch 80 Validation Accuracy: 0.893\n",
            "[Epoch 81, Batch 100/372] Train Loss: 1.078, Train Accuracy: 0.930\n",
            "[Epoch 81, Batch 200/372] Train Loss: 0.619, Train Accuracy: 0.078\n",
            "[Epoch 81, Batch 300/372] Train Loss: 2.111, Train Accuracy: 0.461\n",
            "Epoch 81 Validation Accuracy: 0.925\n",
            "[Epoch 82, Batch 100/372] Train Loss: 2.187, Train Accuracy: 0.375\n",
            "[Epoch 82, Batch 200/372] Train Loss: 0.521, Train Accuracy: 1.000\n",
            "[Epoch 82, Batch 300/372] Train Loss: 1.996, Train Accuracy: 0.672\n",
            "Epoch 82 Validation Accuracy: 0.929\n",
            "[Epoch 83, Batch 100/372] Train Loss: 2.048, Train Accuracy: 0.734\n",
            "[Epoch 83, Batch 200/372] Train Loss: 1.896, Train Accuracy: 0.672\n",
            "[Epoch 83, Batch 300/372] Train Loss: 0.761, Train Accuracy: 0.102\n",
            "Epoch 83 Validation Accuracy: 0.923\n",
            "[Epoch 84, Batch 100/372] Train Loss: 1.567, Train Accuracy: 0.258\n",
            "[Epoch 84, Batch 200/372] Train Loss: 1.248, Train Accuracy: 0.148\n",
            "[Epoch 84, Batch 300/372] Train Loss: 0.634, Train Accuracy: 0.094\n",
            "Epoch 84 Validation Accuracy: 0.926\n",
            "[Epoch 85, Batch 100/372] Train Loss: 0.558, Train Accuracy: 0.062\n",
            "[Epoch 85, Batch 200/372] Train Loss: 1.457, Train Accuracy: 0.156\n",
            "[Epoch 85, Batch 300/372] Train Loss: 1.490, Train Accuracy: 0.852\n",
            "Epoch 85 Validation Accuracy: 0.917\n",
            "[Epoch 86, Batch 100/372] Train Loss: 0.653, Train Accuracy: 0.055\n",
            "[Epoch 86, Batch 200/372] Train Loss: 0.752, Train Accuracy: 0.992\n",
            "[Epoch 86, Batch 300/372] Train Loss: 0.760, Train Accuracy: 0.984\n",
            "Epoch 86 Validation Accuracy: 0.926\n",
            "[Epoch 87, Batch 100/372] Train Loss: 0.659, Train Accuracy: 0.992\n",
            "[Epoch 87, Batch 200/372] Train Loss: 1.414, Train Accuracy: 0.141\n",
            "[Epoch 87, Batch 300/372] Train Loss: 0.529, Train Accuracy: 0.086\n",
            "Epoch 87 Validation Accuracy: 0.919\n",
            "[Epoch 88, Batch 100/372] Train Loss: 0.822, Train Accuracy: 0.945\n",
            "[Epoch 88, Batch 200/372] Train Loss: 0.643, Train Accuracy: 0.117\n",
            "[Epoch 88, Batch 300/372] Train Loss: 0.637, Train Accuracy: 0.094\n",
            "Epoch 88 Validation Accuracy: 0.927\n",
            "[Epoch 89, Batch 100/372] Train Loss: 1.407, Train Accuracy: 0.172\n",
            "[Epoch 89, Batch 200/372] Train Loss: 0.661, Train Accuracy: 0.180\n",
            "[Epoch 89, Batch 300/372] Train Loss: 0.935, Train Accuracy: 0.969\n",
            "Epoch 89 Validation Accuracy: 0.925\n",
            "[Epoch 90, Batch 100/372] Train Loss: 0.521, Train Accuracy: 0.984\n",
            "[Epoch 90, Batch 200/372] Train Loss: 2.179, Train Accuracy: 0.352\n",
            "[Epoch 90, Batch 300/372] Train Loss: 0.819, Train Accuracy: 0.102\n",
            "Epoch 90 Validation Accuracy: 0.922\n",
            "[Epoch 91, Batch 100/372] Train Loss: 2.275, Train Accuracy: 0.531\n",
            "[Epoch 91, Batch 200/372] Train Loss: 0.804, Train Accuracy: 0.984\n",
            "[Epoch 91, Batch 300/372] Train Loss: 0.741, Train Accuracy: 0.961\n",
            "Epoch 91 Validation Accuracy: 0.924\n",
            "[Epoch 92, Batch 100/372] Train Loss: 1.757, Train Accuracy: 0.836\n",
            "[Epoch 92, Batch 200/372] Train Loss: 1.977, Train Accuracy: 0.695\n",
            "[Epoch 92, Batch 300/372] Train Loss: 1.599, Train Accuracy: 0.203\n",
            "Epoch 92 Validation Accuracy: 0.930\n",
            "[Epoch 93, Batch 100/372] Train Loss: 0.607, Train Accuracy: 0.039\n",
            "[Epoch 93, Batch 200/372] Train Loss: 1.404, Train Accuracy: 0.820\n",
            "[Epoch 93, Batch 300/372] Train Loss: 0.497, Train Accuracy: 0.117\n",
            "Epoch 93 Validation Accuracy: 0.921\n",
            "[Epoch 94, Batch 100/372] Train Loss: 0.455, Train Accuracy: 0.992\n",
            "[Epoch 94, Batch 200/372] Train Loss: 1.694, Train Accuracy: 0.453\n",
            "[Epoch 94, Batch 300/372] Train Loss: 0.567, Train Accuracy: 0.094\n",
            "Epoch 94 Validation Accuracy: 0.923\n",
            "[Epoch 95, Batch 100/372] Train Loss: 0.619, Train Accuracy: 0.977\n",
            "[Epoch 95, Batch 200/372] Train Loss: 0.610, Train Accuracy: 0.078\n",
            "[Epoch 95, Batch 300/372] Train Loss: 0.593, Train Accuracy: 0.992\n",
            "Epoch 95 Validation Accuracy: 0.929\n",
            "[Epoch 96, Batch 100/372] Train Loss: 0.875, Train Accuracy: 0.117\n",
            "[Epoch 96, Batch 200/372] Train Loss: 1.293, Train Accuracy: 0.930\n",
            "[Epoch 96, Batch 300/372] Train Loss: 0.747, Train Accuracy: 0.125\n",
            "Epoch 96 Validation Accuracy: 0.928\n",
            "[Epoch 97, Batch 100/372] Train Loss: 0.814, Train Accuracy: 0.945\n",
            "[Epoch 97, Batch 200/372] Train Loss: 0.617, Train Accuracy: 0.977\n",
            "[Epoch 97, Batch 300/372] Train Loss: 1.890, Train Accuracy: 0.242\n",
            "Epoch 97 Validation Accuracy: 0.925\n",
            "[Epoch 98, Batch 100/372] Train Loss: 0.600, Train Accuracy: 0.984\n",
            "[Epoch 98, Batch 200/372] Train Loss: 1.781, Train Accuracy: 0.367\n",
            "[Epoch 98, Batch 300/372] Train Loss: 0.564, Train Accuracy: 0.992\n",
            "Epoch 98 Validation Accuracy: 0.920\n",
            "[Epoch 99, Batch 100/372] Train Loss: 2.004, Train Accuracy: 0.438\n",
            "[Epoch 99, Batch 200/372] Train Loss: 0.778, Train Accuracy: 0.148\n",
            "[Epoch 99, Batch 300/372] Train Loss: 0.784, Train Accuracy: 0.109\n",
            "Epoch 99 Validation Accuracy: 0.927\n",
            "[Epoch 100, Batch 100/372] Train Loss: 0.892, Train Accuracy: 0.953\n",
            "[Epoch 100, Batch 200/372] Train Loss: 0.690, Train Accuracy: 0.117\n",
            "[Epoch 100, Batch 300/372] Train Loss: 0.635, Train Accuracy: 0.031\n",
            "Epoch 100 Validation Accuracy: 0.924\n",
            "Checkpoint saved at epoch 100: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_100.tar\n",
            "[Epoch 101, Batch 100/372] Train Loss: 1.516, Train Accuracy: 0.156\n",
            "[Epoch 101, Batch 200/372] Train Loss: 0.983, Train Accuracy: 0.961\n",
            "[Epoch 101, Batch 300/372] Train Loss: 1.387, Train Accuracy: 0.875\n",
            "Epoch 101 Validation Accuracy: 0.927\n",
            "[Epoch 102, Batch 100/372] Train Loss: 0.976, Train Accuracy: 0.945\n",
            "[Epoch 102, Batch 200/372] Train Loss: 0.517, Train Accuracy: 0.094\n",
            "[Epoch 102, Batch 300/372] Train Loss: 0.633, Train Accuracy: 0.992\n",
            "Epoch 102 Validation Accuracy: 0.922\n",
            "[Epoch 103, Batch 100/372] Train Loss: 0.604, Train Accuracy: 0.977\n",
            "[Epoch 103, Batch 200/372] Train Loss: 0.823, Train Accuracy: 0.117\n",
            "[Epoch 103, Batch 300/372] Train Loss: 0.644, Train Accuracy: 0.992\n",
            "Epoch 103 Validation Accuracy: 0.925\n",
            "[Epoch 104, Batch 100/372] Train Loss: 0.781, Train Accuracy: 0.125\n",
            "[Epoch 104, Batch 200/372] Train Loss: 0.592, Train Accuracy: 0.102\n",
            "[Epoch 104, Batch 300/372] Train Loss: 0.452, Train Accuracy: 0.102\n",
            "Epoch 104 Validation Accuracy: 0.914\n",
            "[Epoch 105, Batch 100/372] Train Loss: 0.848, Train Accuracy: 0.961\n",
            "[Epoch 105, Batch 200/372] Train Loss: 2.109, Train Accuracy: 0.250\n",
            "[Epoch 105, Batch 300/372] Train Loss: 0.482, Train Accuracy: 0.977\n",
            "Epoch 105 Validation Accuracy: 0.928\n",
            "[Epoch 106, Batch 100/372] Train Loss: 1.653, Train Accuracy: 0.656\n",
            "[Epoch 106, Batch 200/372] Train Loss: 1.915, Train Accuracy: 0.570\n",
            "[Epoch 106, Batch 300/372] Train Loss: 0.573, Train Accuracy: 0.102\n",
            "Epoch 106 Validation Accuracy: 0.927\n",
            "[Epoch 107, Batch 100/372] Train Loss: 0.664, Train Accuracy: 0.977\n",
            "[Epoch 107, Batch 200/372] Train Loss: 1.696, Train Accuracy: 0.172\n",
            "[Epoch 107, Batch 300/372] Train Loss: 0.622, Train Accuracy: 0.156\n",
            "Epoch 107 Validation Accuracy: 0.920\n",
            "[Epoch 108, Batch 100/372] Train Loss: 1.554, Train Accuracy: 0.180\n",
            "[Epoch 108, Batch 200/372] Train Loss: 0.474, Train Accuracy: 0.102\n",
            "[Epoch 108, Batch 300/372] Train Loss: 1.763, Train Accuracy: 0.727\n",
            "Epoch 108 Validation Accuracy: 0.929\n",
            "[Epoch 109, Batch 100/372] Train Loss: 0.499, Train Accuracy: 0.984\n",
            "[Epoch 109, Batch 200/372] Train Loss: 0.446, Train Accuracy: 0.992\n",
            "[Epoch 109, Batch 300/372] Train Loss: 1.440, Train Accuracy: 0.195\n",
            "Epoch 109 Validation Accuracy: 0.927\n",
            "[Epoch 110, Batch 100/372] Train Loss: 0.671, Train Accuracy: 0.992\n",
            "[Epoch 110, Batch 200/372] Train Loss: 0.633, Train Accuracy: 0.078\n",
            "[Epoch 110, Batch 300/372] Train Loss: 1.030, Train Accuracy: 0.938\n",
            "Epoch 110 Validation Accuracy: 0.909\n",
            "[Epoch 111, Batch 100/372] Train Loss: 0.985, Train Accuracy: 0.945\n",
            "[Epoch 111, Batch 200/372] Train Loss: 1.719, Train Accuracy: 0.180\n",
            "[Epoch 111, Batch 300/372] Train Loss: 0.566, Train Accuracy: 0.109\n",
            "Epoch 111 Validation Accuracy: 0.921\n",
            "[Epoch 112, Batch 100/372] Train Loss: 1.623, Train Accuracy: 0.438\n",
            "[Epoch 112, Batch 200/372] Train Loss: 1.045, Train Accuracy: 0.094\n",
            "[Epoch 112, Batch 300/372] Train Loss: 0.746, Train Accuracy: 0.977\n",
            "Epoch 112 Validation Accuracy: 0.928\n",
            "[Epoch 113, Batch 100/372] Train Loss: 1.603, Train Accuracy: 0.250\n",
            "[Epoch 113, Batch 200/372] Train Loss: 0.500, Train Accuracy: 0.070\n",
            "[Epoch 113, Batch 300/372] Train Loss: 1.281, Train Accuracy: 0.883\n",
            "Epoch 113 Validation Accuracy: 0.930\n",
            "[Epoch 114, Batch 100/372] Train Loss: 0.491, Train Accuracy: 1.000\n",
            "[Epoch 114, Batch 200/372] Train Loss: 1.003, Train Accuracy: 0.898\n",
            "[Epoch 114, Batch 300/372] Train Loss: 1.956, Train Accuracy: 0.227\n",
            "Epoch 114 Validation Accuracy: 0.924\n",
            "[Epoch 115, Batch 100/372] Train Loss: 1.741, Train Accuracy: 0.305\n",
            "[Epoch 115, Batch 200/372] Train Loss: 1.500, Train Accuracy: 0.836\n",
            "[Epoch 115, Batch 300/372] Train Loss: 0.807, Train Accuracy: 0.977\n",
            "Epoch 115 Validation Accuracy: 0.930\n",
            "[Epoch 116, Batch 100/372] Train Loss: 1.748, Train Accuracy: 0.180\n",
            "[Epoch 116, Batch 200/372] Train Loss: 1.292, Train Accuracy: 0.906\n",
            "[Epoch 116, Batch 300/372] Train Loss: 1.279, Train Accuracy: 0.164\n",
            "Epoch 116 Validation Accuracy: 0.927\n",
            "[Epoch 117, Batch 100/372] Train Loss: 0.500, Train Accuracy: 0.070\n",
            "[Epoch 117, Batch 200/372] Train Loss: 1.337, Train Accuracy: 0.883\n",
            "[Epoch 117, Batch 300/372] Train Loss: 2.028, Train Accuracy: 0.547\n",
            "Epoch 117 Validation Accuracy: 0.921\n",
            "[Epoch 118, Batch 100/372] Train Loss: 0.469, Train Accuracy: 0.977\n",
            "[Epoch 118, Batch 200/372] Train Loss: 1.976, Train Accuracy: 0.484\n",
            "[Epoch 118, Batch 300/372] Train Loss: 1.656, Train Accuracy: 0.344\n",
            "Epoch 118 Validation Accuracy: 0.930\n",
            "[Epoch 119, Batch 100/372] Train Loss: 1.423, Train Accuracy: 0.219\n",
            "[Epoch 119, Batch 200/372] Train Loss: 0.436, Train Accuracy: 0.102\n",
            "[Epoch 119, Batch 300/372] Train Loss: 0.803, Train Accuracy: 0.969\n",
            "Epoch 119 Validation Accuracy: 0.933\n",
            "[Epoch 120, Batch 100/372] Train Loss: 1.599, Train Accuracy: 0.297\n",
            "[Epoch 120, Batch 200/372] Train Loss: 0.964, Train Accuracy: 0.961\n",
            "[Epoch 120, Batch 300/372] Train Loss: 0.502, Train Accuracy: 0.086\n",
            "Epoch 120 Validation Accuracy: 0.926\n",
            "[Epoch 121, Batch 100/372] Train Loss: 0.464, Train Accuracy: 0.055\n",
            "[Epoch 121, Batch 200/372] Train Loss: 0.530, Train Accuracy: 0.992\n",
            "[Epoch 121, Batch 300/372] Train Loss: 1.372, Train Accuracy: 0.172\n",
            "Epoch 121 Validation Accuracy: 0.933\n",
            "[Epoch 122, Batch 100/372] Train Loss: 0.545, Train Accuracy: 0.133\n",
            "[Epoch 122, Batch 200/372] Train Loss: 0.489, Train Accuracy: 0.133\n",
            "[Epoch 122, Batch 300/372] Train Loss: 0.411, Train Accuracy: 0.125\n",
            "Epoch 122 Validation Accuracy: 0.940\n",
            "[Epoch 123, Batch 100/372] Train Loss: 1.299, Train Accuracy: 0.125\n",
            "[Epoch 123, Batch 200/372] Train Loss: 1.286, Train Accuracy: 0.164\n",
            "[Epoch 123, Batch 300/372] Train Loss: 0.995, Train Accuracy: 0.977\n",
            "Epoch 123 Validation Accuracy: 0.931\n",
            "[Epoch 124, Batch 100/372] Train Loss: 0.605, Train Accuracy: 0.977\n",
            "[Epoch 124, Batch 200/372] Train Loss: 0.520, Train Accuracy: 0.102\n",
            "[Epoch 124, Batch 300/372] Train Loss: 0.495, Train Accuracy: 0.062\n",
            "Epoch 124 Validation Accuracy: 0.924\n",
            "[Epoch 125, Batch 100/372] Train Loss: 0.568, Train Accuracy: 0.062\n",
            "[Epoch 125, Batch 200/372] Train Loss: 0.484, Train Accuracy: 0.125\n",
            "[Epoch 125, Batch 300/372] Train Loss: 0.420, Train Accuracy: 0.992\n",
            "Epoch 125 Validation Accuracy: 0.929\n",
            "Checkpoint saved at epoch 125: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_125.tar\n",
            "[Epoch 126, Batch 100/372] Train Loss: 1.965, Train Accuracy: 0.750\n",
            "[Epoch 126, Batch 200/372] Train Loss: 0.595, Train Accuracy: 0.977\n",
            "[Epoch 126, Batch 300/372] Train Loss: 0.521, Train Accuracy: 0.086\n",
            "Epoch 126 Validation Accuracy: 0.922\n",
            "[Epoch 127, Batch 100/372] Train Loss: 0.491, Train Accuracy: 1.000\n",
            "[Epoch 127, Batch 200/372] Train Loss: 1.727, Train Accuracy: 0.664\n",
            "[Epoch 127, Batch 300/372] Train Loss: 0.600, Train Accuracy: 0.969\n",
            "Epoch 127 Validation Accuracy: 0.926\n",
            "[Epoch 128, Batch 100/372] Train Loss: 0.685, Train Accuracy: 0.094\n",
            "[Epoch 128, Batch 200/372] Train Loss: 1.275, Train Accuracy: 0.148\n",
            "[Epoch 128, Batch 300/372] Train Loss: 1.781, Train Accuracy: 0.289\n",
            "Epoch 128 Validation Accuracy: 0.929\n",
            "[Epoch 129, Batch 100/372] Train Loss: 0.961, Train Accuracy: 0.133\n",
            "[Epoch 129, Batch 200/372] Train Loss: 0.437, Train Accuracy: 0.109\n",
            "[Epoch 129, Batch 300/372] Train Loss: 1.754, Train Accuracy: 0.500\n",
            "Epoch 129 Validation Accuracy: 0.934\n",
            "[Epoch 130, Batch 100/372] Train Loss: 0.660, Train Accuracy: 0.070\n",
            "[Epoch 130, Batch 200/372] Train Loss: 1.262, Train Accuracy: 0.234\n",
            "[Epoch 130, Batch 300/372] Train Loss: 1.675, Train Accuracy: 0.227\n",
            "Epoch 130 Validation Accuracy: 0.926\n",
            "[Epoch 131, Batch 100/372] Train Loss: 0.528, Train Accuracy: 0.102\n",
            "[Epoch 131, Batch 200/372] Train Loss: 1.533, Train Accuracy: 0.578\n",
            "[Epoch 131, Batch 300/372] Train Loss: 0.849, Train Accuracy: 0.961\n",
            "Epoch 131 Validation Accuracy: 0.932\n",
            "[Epoch 132, Batch 100/372] Train Loss: 1.414, Train Accuracy: 0.211\n",
            "[Epoch 132, Batch 200/372] Train Loss: 0.505, Train Accuracy: 0.109\n",
            "[Epoch 132, Batch 300/372] Train Loss: 0.327, Train Accuracy: 0.992\n",
            "Epoch 132 Validation Accuracy: 0.929\n",
            "[Epoch 133, Batch 100/372] Train Loss: 0.702, Train Accuracy: 0.102\n",
            "[Epoch 133, Batch 200/372] Train Loss: 1.144, Train Accuracy: 0.906\n",
            "[Epoch 133, Batch 300/372] Train Loss: 0.788, Train Accuracy: 0.141\n",
            "Epoch 133 Validation Accuracy: 0.928\n",
            "[Epoch 134, Batch 100/372] Train Loss: 0.594, Train Accuracy: 0.977\n",
            "[Epoch 134, Batch 200/372] Train Loss: 0.685, Train Accuracy: 0.070\n",
            "[Epoch 134, Batch 300/372] Train Loss: 0.896, Train Accuracy: 0.914\n",
            "Epoch 134 Validation Accuracy: 0.934\n",
            "[Epoch 135, Batch 100/372] Train Loss: 0.498, Train Accuracy: 0.125\n",
            "[Epoch 135, Batch 200/372] Train Loss: 1.886, Train Accuracy: 0.391\n",
            "[Epoch 135, Batch 300/372] Train Loss: 0.655, Train Accuracy: 0.977\n",
            "Epoch 135 Validation Accuracy: 0.928\n",
            "[Epoch 136, Batch 100/372] Train Loss: 0.640, Train Accuracy: 0.062\n",
            "[Epoch 136, Batch 200/372] Train Loss: 0.681, Train Accuracy: 1.000\n",
            "[Epoch 136, Batch 300/372] Train Loss: 0.471, Train Accuracy: 0.984\n",
            "Epoch 136 Validation Accuracy: 0.932\n",
            "[Epoch 137, Batch 100/372] Train Loss: 2.020, Train Accuracy: 0.352\n",
            "[Epoch 137, Batch 200/372] Train Loss: 1.208, Train Accuracy: 0.172\n",
            "[Epoch 137, Batch 300/372] Train Loss: 1.919, Train Accuracy: 0.633\n",
            "Epoch 137 Validation Accuracy: 0.929\n",
            "[Epoch 138, Batch 100/372] Train Loss: 0.459, Train Accuracy: 0.984\n",
            "[Epoch 138, Batch 200/372] Train Loss: 1.774, Train Accuracy: 0.297\n",
            "[Epoch 138, Batch 300/372] Train Loss: 0.620, Train Accuracy: 0.148\n",
            "Epoch 138 Validation Accuracy: 0.932\n",
            "[Epoch 139, Batch 100/372] Train Loss: 0.513, Train Accuracy: 0.977\n",
            "[Epoch 139, Batch 200/372] Train Loss: 0.970, Train Accuracy: 0.938\n",
            "[Epoch 139, Batch 300/372] Train Loss: 0.630, Train Accuracy: 0.102\n",
            "Epoch 139 Validation Accuracy: 0.927\n",
            "[Epoch 140, Batch 100/372] Train Loss: 0.470, Train Accuracy: 0.992\n",
            "[Epoch 140, Batch 200/372] Train Loss: 0.867, Train Accuracy: 0.969\n",
            "[Epoch 140, Batch 300/372] Train Loss: 0.419, Train Accuracy: 0.109\n",
            "Epoch 140 Validation Accuracy: 0.936\n",
            "[Epoch 141, Batch 100/372] Train Loss: 0.669, Train Accuracy: 1.000\n",
            "[Epoch 141, Batch 200/372] Train Loss: 0.974, Train Accuracy: 0.945\n",
            "[Epoch 141, Batch 300/372] Train Loss: 0.454, Train Accuracy: 0.078\n",
            "Epoch 141 Validation Accuracy: 0.926\n",
            "[Epoch 142, Batch 100/372] Train Loss: 0.414, Train Accuracy: 0.070\n",
            "[Epoch 142, Batch 200/372] Train Loss: 0.461, Train Accuracy: 0.992\n",
            "[Epoch 142, Batch 300/372] Train Loss: 0.401, Train Accuracy: 0.094\n",
            "Epoch 142 Validation Accuracy: 0.927\n",
            "[Epoch 143, Batch 100/372] Train Loss: 1.489, Train Accuracy: 0.859\n",
            "[Epoch 143, Batch 200/372] Train Loss: 0.424, Train Accuracy: 0.992\n",
            "[Epoch 143, Batch 300/372] Train Loss: 1.810, Train Accuracy: 0.305\n",
            "Epoch 143 Validation Accuracy: 0.930\n",
            "[Epoch 144, Batch 100/372] Train Loss: 0.748, Train Accuracy: 0.094\n",
            "[Epoch 144, Batch 200/372] Train Loss: 0.429, Train Accuracy: 0.117\n",
            "[Epoch 144, Batch 300/372] Train Loss: 2.002, Train Accuracy: 0.672\n",
            "Epoch 144 Validation Accuracy: 0.928\n",
            "[Epoch 145, Batch 100/372] Train Loss: 1.765, Train Accuracy: 0.250\n",
            "[Epoch 145, Batch 200/372] Train Loss: 1.802, Train Accuracy: 0.453\n",
            "[Epoch 145, Batch 300/372] Train Loss: 1.655, Train Accuracy: 0.797\n",
            "Epoch 145 Validation Accuracy: 0.928\n",
            "[Epoch 146, Batch 100/372] Train Loss: 1.765, Train Accuracy: 0.352\n",
            "[Epoch 146, Batch 200/372] Train Loss: 0.438, Train Accuracy: 0.125\n",
            "[Epoch 146, Batch 300/372] Train Loss: 0.984, Train Accuracy: 0.094\n",
            "Epoch 146 Validation Accuracy: 0.922\n",
            "[Epoch 147, Batch 100/372] Train Loss: 0.508, Train Accuracy: 1.000\n",
            "[Epoch 147, Batch 200/372] Train Loss: 0.492, Train Accuracy: 0.992\n",
            "[Epoch 147, Batch 300/372] Train Loss: 1.851, Train Accuracy: 0.250\n",
            "Epoch 147 Validation Accuracy: 0.928\n",
            "[Epoch 148, Batch 100/372] Train Loss: 0.510, Train Accuracy: 0.188\n",
            "[Epoch 148, Batch 200/372] Train Loss: 1.295, Train Accuracy: 0.156\n",
            "[Epoch 148, Batch 300/372] Train Loss: 1.084, Train Accuracy: 0.156\n",
            "Epoch 148 Validation Accuracy: 0.928\n",
            "[Epoch 149, Batch 100/372] Train Loss: 0.867, Train Accuracy: 0.094\n",
            "[Epoch 149, Batch 200/372] Train Loss: 0.453, Train Accuracy: 0.086\n",
            "[Epoch 149, Batch 300/372] Train Loss: 0.302, Train Accuracy: 0.984\n",
            "Epoch 149 Validation Accuracy: 0.929\n",
            "[Epoch 150, Batch 100/372] Train Loss: 0.619, Train Accuracy: 0.984\n",
            "[Epoch 150, Batch 200/372] Train Loss: 1.037, Train Accuracy: 0.164\n",
            "[Epoch 150, Batch 300/372] Train Loss: 1.325, Train Accuracy: 0.148\n",
            "Epoch 150 Validation Accuracy: 0.921\n",
            "Checkpoint saved at epoch 150: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_150.tar\n",
            "[Epoch 151, Batch 100/372] Train Loss: 1.488, Train Accuracy: 0.789\n",
            "[Epoch 151, Batch 200/372] Train Loss: 0.544, Train Accuracy: 0.977\n",
            "[Epoch 151, Batch 300/372] Train Loss: 0.409, Train Accuracy: 1.000\n",
            "Epoch 151 Validation Accuracy: 0.929\n",
            "[Epoch 152, Batch 100/372] Train Loss: 0.418, Train Accuracy: 1.000\n",
            "[Epoch 152, Batch 200/372] Train Loss: 1.495, Train Accuracy: 0.180\n",
            "[Epoch 152, Batch 300/372] Train Loss: 0.548, Train Accuracy: 0.070\n",
            "Epoch 152 Validation Accuracy: 0.930\n",
            "[Epoch 153, Batch 100/372] Train Loss: 1.038, Train Accuracy: 0.945\n",
            "[Epoch 153, Batch 200/372] Train Loss: 1.279, Train Accuracy: 0.906\n",
            "[Epoch 153, Batch 300/372] Train Loss: 1.663, Train Accuracy: 0.273\n",
            "Epoch 153 Validation Accuracy: 0.931\n",
            "[Epoch 154, Batch 100/372] Train Loss: 0.362, Train Accuracy: 0.969\n",
            "[Epoch 154, Batch 200/372] Train Loss: 1.767, Train Accuracy: 0.289\n",
            "[Epoch 154, Batch 300/372] Train Loss: 1.492, Train Accuracy: 0.234\n",
            "Epoch 154 Validation Accuracy: 0.920\n",
            "[Epoch 155, Batch 100/372] Train Loss: 1.286, Train Accuracy: 0.867\n",
            "[Epoch 155, Batch 200/372] Train Loss: 1.898, Train Accuracy: 0.594\n",
            "[Epoch 155, Batch 300/372] Train Loss: 1.307, Train Accuracy: 0.828\n",
            "Epoch 155 Validation Accuracy: 0.931\n",
            "[Epoch 156, Batch 100/372] Train Loss: 0.383, Train Accuracy: 0.977\n",
            "[Epoch 156, Batch 200/372] Train Loss: 1.417, Train Accuracy: 0.883\n",
            "[Epoch 156, Batch 300/372] Train Loss: 1.793, Train Accuracy: 0.688\n",
            "Epoch 156 Validation Accuracy: 0.929\n",
            "[Epoch 157, Batch 100/372] Train Loss: 0.369, Train Accuracy: 0.984\n",
            "[Epoch 157, Batch 200/372] Train Loss: 0.578, Train Accuracy: 0.086\n",
            "[Epoch 157, Batch 300/372] Train Loss: 1.777, Train Accuracy: 0.375\n",
            "Epoch 157 Validation Accuracy: 0.935\n",
            "[Epoch 158, Batch 100/372] Train Loss: 0.329, Train Accuracy: 0.086\n",
            "[Epoch 158, Batch 200/372] Train Loss: 0.503, Train Accuracy: 0.961\n",
            "[Epoch 158, Batch 300/372] Train Loss: 0.343, Train Accuracy: 0.102\n",
            "Epoch 158 Validation Accuracy: 0.928\n",
            "[Epoch 159, Batch 100/372] Train Loss: 1.137, Train Accuracy: 0.125\n",
            "[Epoch 159, Batch 200/372] Train Loss: 0.379, Train Accuracy: 0.109\n",
            "[Epoch 159, Batch 300/372] Train Loss: 0.391, Train Accuracy: 0.992\n",
            "Epoch 159 Validation Accuracy: 0.932\n",
            "[Epoch 160, Batch 100/372] Train Loss: 1.769, Train Accuracy: 0.250\n",
            "[Epoch 160, Batch 200/372] Train Loss: 1.505, Train Accuracy: 0.172\n",
            "[Epoch 160, Batch 300/372] Train Loss: 0.404, Train Accuracy: 1.000\n",
            "Epoch 160 Validation Accuracy: 0.922\n",
            "[Epoch 161, Batch 100/372] Train Loss: 1.474, Train Accuracy: 0.812\n",
            "[Epoch 161, Batch 200/372] Train Loss: 0.796, Train Accuracy: 0.125\n",
            "[Epoch 161, Batch 300/372] Train Loss: 0.370, Train Accuracy: 0.992\n",
            "Epoch 161 Validation Accuracy: 0.925\n",
            "[Epoch 162, Batch 100/372] Train Loss: 0.653, Train Accuracy: 0.961\n",
            "[Epoch 162, Batch 200/372] Train Loss: 0.555, Train Accuracy: 0.094\n",
            "[Epoch 162, Batch 300/372] Train Loss: 0.619, Train Accuracy: 0.977\n",
            "Epoch 162 Validation Accuracy: 0.927\n",
            "[Epoch 163, Batch 100/372] Train Loss: 1.628, Train Accuracy: 0.250\n",
            "[Epoch 163, Batch 200/372] Train Loss: 0.557, Train Accuracy: 0.977\n",
            "[Epoch 163, Batch 300/372] Train Loss: 0.450, Train Accuracy: 0.992\n",
            "Epoch 163 Validation Accuracy: 0.928\n",
            "[Epoch 164, Batch 100/372] Train Loss: 0.413, Train Accuracy: 0.117\n",
            "[Epoch 164, Batch 200/372] Train Loss: 1.266, Train Accuracy: 0.914\n",
            "[Epoch 164, Batch 300/372] Train Loss: 1.066, Train Accuracy: 0.078\n",
            "Epoch 164 Validation Accuracy: 0.928\n",
            "[Epoch 165, Batch 100/372] Train Loss: 0.982, Train Accuracy: 0.938\n",
            "[Epoch 165, Batch 200/372] Train Loss: 0.956, Train Accuracy: 0.164\n",
            "[Epoch 165, Batch 300/372] Train Loss: 0.707, Train Accuracy: 0.984\n",
            "Epoch 165 Validation Accuracy: 0.927\n",
            "[Epoch 166, Batch 100/372] Train Loss: 0.382, Train Accuracy: 0.977\n",
            "[Epoch 166, Batch 200/372] Train Loss: 1.653, Train Accuracy: 0.477\n",
            "[Epoch 166, Batch 300/372] Train Loss: 1.100, Train Accuracy: 0.141\n",
            "Epoch 166 Validation Accuracy: 0.932\n",
            "[Epoch 167, Batch 100/372] Train Loss: 0.422, Train Accuracy: 0.086\n",
            "[Epoch 167, Batch 200/372] Train Loss: 1.182, Train Accuracy: 0.141\n",
            "[Epoch 167, Batch 300/372] Train Loss: 0.726, Train Accuracy: 0.109\n",
            "Epoch 167 Validation Accuracy: 0.925\n",
            "[Epoch 168, Batch 100/372] Train Loss: 1.757, Train Accuracy: 0.609\n",
            "[Epoch 168, Batch 200/372] Train Loss: 0.470, Train Accuracy: 0.078\n",
            "[Epoch 168, Batch 300/372] Train Loss: 0.715, Train Accuracy: 0.961\n",
            "Epoch 168 Validation Accuracy: 0.926\n",
            "[Epoch 169, Batch 100/372] Train Loss: 0.463, Train Accuracy: 0.094\n",
            "[Epoch 169, Batch 200/372] Train Loss: 0.828, Train Accuracy: 0.977\n",
            "[Epoch 169, Batch 300/372] Train Loss: 1.755, Train Accuracy: 0.406\n",
            "Epoch 169 Validation Accuracy: 0.930\n",
            "[Epoch 170, Batch 100/372] Train Loss: 1.689, Train Accuracy: 0.719\n",
            "[Epoch 170, Batch 200/372] Train Loss: 1.880, Train Accuracy: 0.664\n",
            "[Epoch 170, Batch 300/372] Train Loss: 0.344, Train Accuracy: 0.070\n",
            "Epoch 170 Validation Accuracy: 0.928\n",
            "[Epoch 171, Batch 100/372] Train Loss: 1.960, Train Accuracy: 0.414\n",
            "[Epoch 171, Batch 200/372] Train Loss: 1.912, Train Accuracy: 0.312\n",
            "[Epoch 171, Batch 300/372] Train Loss: 0.438, Train Accuracy: 0.984\n",
            "Epoch 171 Validation Accuracy: 0.926\n",
            "[Epoch 172, Batch 100/372] Train Loss: 1.550, Train Accuracy: 0.172\n",
            "[Epoch 172, Batch 200/372] Train Loss: 0.498, Train Accuracy: 0.977\n",
            "[Epoch 172, Batch 300/372] Train Loss: 1.282, Train Accuracy: 0.852\n",
            "Epoch 172 Validation Accuracy: 0.931\n",
            "[Epoch 173, Batch 100/372] Train Loss: 0.965, Train Accuracy: 0.094\n",
            "[Epoch 173, Batch 200/372] Train Loss: 1.148, Train Accuracy: 0.141\n",
            "[Epoch 173, Batch 300/372] Train Loss: 1.439, Train Accuracy: 0.734\n",
            "Epoch 173 Validation Accuracy: 0.928\n",
            "[Epoch 174, Batch 100/372] Train Loss: 0.978, Train Accuracy: 0.930\n",
            "[Epoch 174, Batch 200/372] Train Loss: 0.850, Train Accuracy: 0.086\n",
            "[Epoch 174, Batch 300/372] Train Loss: 0.442, Train Accuracy: 0.984\n",
            "Epoch 174 Validation Accuracy: 0.931\n",
            "[Epoch 175, Batch 100/372] Train Loss: 1.125, Train Accuracy: 0.172\n",
            "[Epoch 175, Batch 200/372] Train Loss: 0.599, Train Accuracy: 0.148\n",
            "[Epoch 175, Batch 300/372] Train Loss: 1.648, Train Accuracy: 0.312\n",
            "Epoch 175 Validation Accuracy: 0.929\n",
            "Checkpoint saved at epoch 175: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_175.tar\n",
            "[Epoch 176, Batch 100/372] Train Loss: 0.688, Train Accuracy: 0.969\n",
            "[Epoch 176, Batch 200/372] Train Loss: 1.680, Train Accuracy: 0.570\n",
            "[Epoch 176, Batch 300/372] Train Loss: 0.376, Train Accuracy: 0.078\n",
            "Epoch 176 Validation Accuracy: 0.927\n",
            "[Epoch 177, Batch 100/372] Train Loss: 0.739, Train Accuracy: 0.102\n",
            "[Epoch 177, Batch 200/372] Train Loss: 1.740, Train Accuracy: 0.305\n",
            "[Epoch 177, Batch 300/372] Train Loss: 1.073, Train Accuracy: 0.195\n",
            "Epoch 177 Validation Accuracy: 0.930\n",
            "[Epoch 178, Batch 100/372] Train Loss: 1.365, Train Accuracy: 0.234\n",
            "[Epoch 178, Batch 200/372] Train Loss: 0.383, Train Accuracy: 0.992\n",
            "[Epoch 178, Batch 300/372] Train Loss: 0.319, Train Accuracy: 0.992\n",
            "Epoch 178 Validation Accuracy: 0.930\n",
            "[Epoch 179, Batch 100/372] Train Loss: 1.475, Train Accuracy: 0.875\n",
            "[Epoch 179, Batch 200/372] Train Loss: 1.688, Train Accuracy: 0.227\n",
            "[Epoch 179, Batch 300/372] Train Loss: 0.597, Train Accuracy: 0.984\n",
            "Epoch 179 Validation Accuracy: 0.927\n",
            "[Epoch 180, Batch 100/372] Train Loss: 1.345, Train Accuracy: 0.141\n",
            "[Epoch 180, Batch 200/372] Train Loss: 1.711, Train Accuracy: 0.695\n",
            "[Epoch 180, Batch 300/372] Train Loss: 1.940, Train Accuracy: 0.328\n",
            "Epoch 180 Validation Accuracy: 0.928\n",
            "[Epoch 181, Batch 100/372] Train Loss: 0.373, Train Accuracy: 0.125\n",
            "[Epoch 181, Batch 200/372] Train Loss: 0.399, Train Accuracy: 0.148\n",
            "[Epoch 181, Batch 300/372] Train Loss: 0.474, Train Accuracy: 0.086\n",
            "Epoch 181 Validation Accuracy: 0.929\n",
            "[Epoch 182, Batch 100/372] Train Loss: 0.754, Train Accuracy: 0.109\n",
            "[Epoch 182, Batch 200/372] Train Loss: 0.718, Train Accuracy: 0.148\n",
            "[Epoch 182, Batch 300/372] Train Loss: 1.608, Train Accuracy: 0.297\n",
            "Epoch 182 Validation Accuracy: 0.928\n",
            "[Epoch 183, Batch 100/372] Train Loss: 0.456, Train Accuracy: 0.992\n",
            "[Epoch 183, Batch 200/372] Train Loss: 0.480, Train Accuracy: 0.992\n",
            "[Epoch 183, Batch 300/372] Train Loss: 0.347, Train Accuracy: 0.148\n",
            "Epoch 183 Validation Accuracy: 0.927\n",
            "[Epoch 184, Batch 100/372] Train Loss: 1.228, Train Accuracy: 0.914\n",
            "[Epoch 184, Batch 200/372] Train Loss: 0.302, Train Accuracy: 0.117\n",
            "[Epoch 184, Batch 300/372] Train Loss: 0.674, Train Accuracy: 0.992\n",
            "Epoch 184 Validation Accuracy: 0.926\n",
            "[Epoch 185, Batch 100/372] Train Loss: 0.843, Train Accuracy: 0.945\n",
            "[Epoch 185, Batch 200/372] Train Loss: 0.553, Train Accuracy: 0.156\n",
            "[Epoch 185, Batch 300/372] Train Loss: 1.258, Train Accuracy: 0.898\n",
            "Epoch 185 Validation Accuracy: 0.932\n",
            "[Epoch 186, Batch 100/372] Train Loss: 0.824, Train Accuracy: 0.945\n",
            "[Epoch 186, Batch 200/372] Train Loss: 1.384, Train Accuracy: 0.656\n",
            "[Epoch 186, Batch 300/372] Train Loss: 1.067, Train Accuracy: 0.078\n",
            "Epoch 186 Validation Accuracy: 0.928\n",
            "[Epoch 187, Batch 100/372] Train Loss: 1.184, Train Accuracy: 0.109\n",
            "[Epoch 187, Batch 200/372] Train Loss: 0.387, Train Accuracy: 0.125\n",
            "[Epoch 187, Batch 300/372] Train Loss: 1.601, Train Accuracy: 0.289\n",
            "Epoch 187 Validation Accuracy: 0.931\n",
            "[Epoch 188, Batch 100/372] Train Loss: 1.758, Train Accuracy: 0.328\n",
            "[Epoch 188, Batch 200/372] Train Loss: 0.368, Train Accuracy: 0.078\n",
            "[Epoch 188, Batch 300/372] Train Loss: 1.914, Train Accuracy: 0.516\n",
            "Epoch 188 Validation Accuracy: 0.928\n",
            "[Epoch 189, Batch 100/372] Train Loss: 0.505, Train Accuracy: 0.977\n",
            "[Epoch 189, Batch 200/372] Train Loss: 0.344, Train Accuracy: 1.000\n",
            "[Epoch 189, Batch 300/372] Train Loss: 1.129, Train Accuracy: 0.117\n",
            "Epoch 189 Validation Accuracy: 0.928\n",
            "[Epoch 190, Batch 100/372] Train Loss: 0.332, Train Accuracy: 1.000\n",
            "[Epoch 190, Batch 200/372] Train Loss: 1.747, Train Accuracy: 0.648\n",
            "[Epoch 190, Batch 300/372] Train Loss: 0.379, Train Accuracy: 0.977\n",
            "Epoch 190 Validation Accuracy: 0.928\n",
            "[Epoch 191, Batch 100/372] Train Loss: 0.505, Train Accuracy: 0.125\n",
            "[Epoch 191, Batch 200/372] Train Loss: 0.511, Train Accuracy: 0.125\n",
            "[Epoch 191, Batch 300/372] Train Loss: 0.434, Train Accuracy: 1.000\n",
            "Epoch 191 Validation Accuracy: 0.928\n",
            "[Epoch 192, Batch 100/372] Train Loss: 1.678, Train Accuracy: 0.281\n",
            "[Epoch 192, Batch 200/372] Train Loss: 1.631, Train Accuracy: 0.695\n",
            "[Epoch 192, Batch 300/372] Train Loss: 1.138, Train Accuracy: 0.906\n",
            "Epoch 192 Validation Accuracy: 0.928\n",
            "[Epoch 193, Batch 100/372] Train Loss: 0.363, Train Accuracy: 0.102\n",
            "[Epoch 193, Batch 200/372] Train Loss: 0.965, Train Accuracy: 0.141\n",
            "[Epoch 193, Batch 300/372] Train Loss: 0.547, Train Accuracy: 1.000\n",
            "Epoch 193 Validation Accuracy: 0.926\n",
            "[Epoch 194, Batch 100/372] Train Loss: 0.413, Train Accuracy: 0.977\n",
            "[Epoch 194, Batch 200/372] Train Loss: 1.588, Train Accuracy: 0.203\n",
            "[Epoch 194, Batch 300/372] Train Loss: 1.280, Train Accuracy: 0.820\n",
            "Epoch 194 Validation Accuracy: 0.927\n",
            "[Epoch 195, Batch 100/372] Train Loss: 1.791, Train Accuracy: 0.672\n",
            "[Epoch 195, Batch 200/372] Train Loss: 1.182, Train Accuracy: 0.188\n",
            "[Epoch 195, Batch 300/372] Train Loss: 1.528, Train Accuracy: 0.195\n",
            "Epoch 195 Validation Accuracy: 0.932\n",
            "[Epoch 196, Batch 100/372] Train Loss: 0.357, Train Accuracy: 0.117\n",
            "[Epoch 196, Batch 200/372] Train Loss: 1.680, Train Accuracy: 0.234\n",
            "[Epoch 196, Batch 300/372] Train Loss: 0.349, Train Accuracy: 0.117\n",
            "Epoch 196 Validation Accuracy: 0.930\n",
            "[Epoch 197, Batch 100/372] Train Loss: 0.360, Train Accuracy: 0.141\n",
            "[Epoch 197, Batch 200/372] Train Loss: 1.972, Train Accuracy: 0.414\n",
            "[Epoch 197, Batch 300/372] Train Loss: 0.688, Train Accuracy: 0.938\n",
            "Epoch 197 Validation Accuracy: 0.928\n",
            "[Epoch 198, Batch 100/372] Train Loss: 0.334, Train Accuracy: 0.102\n",
            "[Epoch 198, Batch 200/372] Train Loss: 1.345, Train Accuracy: 0.898\n",
            "[Epoch 198, Batch 300/372] Train Loss: 0.243, Train Accuracy: 0.984\n",
            "Epoch 198 Validation Accuracy: 0.931\n",
            "[Epoch 199, Batch 100/372] Train Loss: 0.667, Train Accuracy: 0.117\n",
            "[Epoch 199, Batch 200/372] Train Loss: 0.452, Train Accuracy: 0.984\n",
            "[Epoch 199, Batch 300/372] Train Loss: 1.180, Train Accuracy: 0.914\n",
            "Epoch 199 Validation Accuracy: 0.932\n",
            "[Epoch 200, Batch 100/372] Train Loss: 1.799, Train Accuracy: 0.461\n",
            "[Epoch 200, Batch 200/372] Train Loss: 1.002, Train Accuracy: 0.953\n",
            "[Epoch 200, Batch 300/372] Train Loss: 0.649, Train Accuracy: 0.984\n",
            "Epoch 200 Validation Accuracy: 0.928\n",
            "Checkpoint saved at epoch 200: checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_200.tar\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Unsupported qscheme: per_channel_affine",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[43], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     63\u001b[0m prepared_student\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 65\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_student\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Final model save\u001b[39;00m\n\u001b[0;32m     68\u001b[0m final_save_path \u001b[38;5;241m=\u001b[39m checkpoints_path_student \u001b[38;5;241m+\u001b[39m utils\u001b[38;5;241m.\u001b[39mhparamToString(hparam) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:659\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[0;32m    658\u001b[0m     module \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(module)\n\u001b[1;32m--> 659\u001b[0m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[0;32m    668\u001b[0m     _remove_qconfig(module)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:716\u001b[0m, in \u001b[0;36m_convert\u001b[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule)\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping\n\u001b[0;32m    715\u001b[0m     ):\n\u001b[1;32m--> 716\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[0;32m    720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(\n\u001b[0;32m    725\u001b[0m         mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant\n\u001b[0;32m    726\u001b[0m     )\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:716\u001b[0m, in \u001b[0;36m_convert\u001b[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule)\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping\n\u001b[0;32m    715\u001b[0m     ):\n\u001b[1;32m--> 716\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[0;32m    720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(\n\u001b[0;32m    725\u001b[0m         mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant\n\u001b[0;32m    726\u001b[0m     )\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:724\u001b[0m, in \u001b[0;36m_convert\u001b[1;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule)\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping\n\u001b[0;32m    715\u001b[0m     ):\n\u001b[0;32m    716\u001b[0m         _convert(\n\u001b[0;32m    717\u001b[0m             mod,\n\u001b[0;32m    718\u001b[0m             mapping,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    722\u001b[0m             use_precomputed_fake_quant\u001b[38;5;241m=\u001b[39muse_precomputed_fake_quant,\n\u001b[0;32m    723\u001b[0m         )\n\u001b[1;32m--> 724\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    729\u001b[0m     module\u001b[38;5;241m.\u001b[39m_modules[key] \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:766\u001b[0m, in \u001b[0;36mswap_module\u001b[1;34m(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    764\u001b[0m sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(qmod\u001b[38;5;241m.\u001b[39mfrom_float)\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_precomputed_fake_quant\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m--> 766\u001b[0m     new_mod \u001b[38;5;241m=\u001b[39m \u001b[43mqmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    770\u001b[0m     new_mod \u001b[38;5;241m=\u001b[39m qmod\u001b[38;5;241m.\u001b[39mfrom_float(mod)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\nn\\intrinsic\\quantized\\modules\\conv_relu.py:172\u001b[0m, in \u001b[0;36mConvReLU2d.from_float\u001b[1;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mod\u001b[38;5;241m.\u001b[39mbn\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39mbn\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     mod\u001b[38;5;241m.\u001b[39mweight, mod\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m fuse_conv_bn_weights(\n\u001b[0;32m    164\u001b[0m         mod\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    165\u001b[0m         mod\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         mod\u001b[38;5;241m.\u001b[39mbn\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:607\u001b[0m, in \u001b[0;36mConv2d.from_float\u001b[1;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_float\u001b[39m(\u001b[38;5;28mcls\u001b[39m, mod, use_precomputed_fake_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;124;03m          utilities or provided by the user\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConvNd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:323\u001b[0m, in \u001b[0;36m_ConvNd.from_float\u001b[1;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[0;32m    321\u001b[0m         mod \u001b[38;5;241m=\u001b[39m mod[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    322\u001b[0m     weight_post_process \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mqconfig\u001b[38;5;241m.\u001b[39mweight()\n\u001b[1;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_qconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_post_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_post_process\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:267\u001b[0m, in \u001b[0;36m_ConvNd.get_qconv\u001b[1;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[0;32m    256\u001b[0m qconv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    257\u001b[0m     mod\u001b[38;5;241m.\u001b[39min_channels,\n\u001b[0;32m    258\u001b[0m     mod\u001b[38;5;241m.\u001b[39mout_channels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     mod\u001b[38;5;241m.\u001b[39mpadding_mode,\n\u001b[0;32m    266\u001b[0m )\n\u001b[1;32m--> 267\u001b[0m \u001b[43mqconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weight_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    269\u001b[0m     activation_post_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m activation_post_process\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat\n\u001b[0;32m    271\u001b[0m ):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qconv  \u001b[38;5;66;03m# dynamic quantization doesn't need scale/zero_point\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py:568\u001b[0m, in \u001b[0;36mConv2d.set_weight_bias\u001b[1;34m(self, w, b)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_weight_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m, w: torch\u001b[38;5;241m.\u001b[39mTensor, b: Optional[torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_prepack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mquantized\u001b[38;5;241m.\u001b[39mconv2d_prepack(\n\u001b[0;32m    573\u001b[0m             w, b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    574\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Unsupported qscheme: per_channel_affine"
          ]
        }
      ],
      "source": [
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "checkpoints_path_student = 'checkpoints_student_QAT/'\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "pruning_factors = [0]\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "    student_net.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
        "    prepared_student = torch.quantization.prepare_qat(student_net)\n",
        "    prepared_student.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(prepared_student)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "    results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparamMixup(\n",
        "            teacher_net, prepared_student, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=True, checkpoint_save_path= checkpoints_path_student, resume_checkpoint=False,\n",
        "            optimizer_choice='sgd'\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    prepared_student.eval()\n",
        "    \n",
        "    quantized_model = torch.quantization.convert(prepared_student)\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': quantized_model.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device) # 'cpu'\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_21196\\1265263037.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(f'checkpoints_student_QAT/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_{cp}.tar')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.896\n",
            "test accuracy:  0.9161\n",
            "test accuracy:  0.9178\n",
            "test accuracy:  0.9196\n",
            "test accuracy:  0.9227\n",
            "test accuracy:  0.9195\n",
            "test accuracy:  0.9226\n",
            "test accuracy:  0.921\n"
          ]
        }
      ],
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "from torch.quantization import fuse_modules\n",
        "\n",
        "checkpoints = [x for x in range(25, 201, 25)]\n",
        "test_accs = []\n",
        "\n",
        "for cp in checkpoints:\n",
        "    student_net = networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "    checkpoint = torch.load(f'checkpoints_student_Van/T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_{cp}.tar')\n",
        "    student_net.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
        "    student_net = torch.quantization.prepare_qat(student_net)\n",
        "    \n",
        "    student_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    student_net.to(fast_device)\n",
        "    student_net.eval()\n",
        "\n",
        "    student_net.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
        "\n",
        "    student_net_prepared = torch.ao.quantization.prepare(student_net)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in train_loader:\n",
        "            inputs = inputs.to(fast_device)\n",
        "            student_net_prepared(inputs)  # Run a forward pass to collect activation statistics\n",
        "    student_net_prepared.to('cpu')\n",
        "\n",
        "    student_net_int8 = torch.ao.quantization.convert(student_net_prepared)\n",
        "    reproducibilitySeed()\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net_int8, test_loader, 'cpu')\n",
        "    print('test accuracy: ', test_accuracy)\n",
        "    test_accs.append(test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=1.0, angle_ratio=0.5, dist_ratio=(0.5,), dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 11173962 23520842\n",
            "Epoch 1, Batch 100: Loss = 10.8462\n",
            "Epoch 1, Batch 200: Loss = 7.9141\n",
            "Epoch 1, Batch 300: Loss = 6.9008\n",
            "Epoch 1: Validation Loss = 1.0877, Validation Accuracy = 0.63%\n",
            "Epoch 2, Batch 100: Loss = 5.4554\n",
            "Epoch 2, Batch 200: Loss = 4.1714\n",
            "Epoch 2, Batch 300: Loss = 4.5779\n",
            "Epoch 2: Validation Loss = 0.7812, Validation Accuracy = 0.72%\n",
            "Epoch 3, Batch 100: Loss = 4.5319\n",
            "Epoch 3, Batch 200: Loss = 3.5200\n",
            "Epoch 3, Batch 300: Loss = 3.8894\n",
            "Epoch 3: Validation Loss = 0.6203, Validation Accuracy = 0.79%\n",
            "Epoch 4, Batch 100: Loss = 3.0337\n",
            "Epoch 4, Batch 200: Loss = 3.8023\n",
            "Epoch 4, Batch 300: Loss = 3.1403\n",
            "Epoch 4: Validation Loss = 0.5890, Validation Accuracy = 0.80%\n",
            "Epoch 5, Batch 100: Loss = 3.4799\n",
            "Epoch 5, Batch 200: Loss = 3.7533\n",
            "Epoch 5, Batch 300: Loss = 3.2624\n",
            "Epoch 5: Validation Loss = 0.5326, Validation Accuracy = 0.82%\n",
            "Epoch 6, Batch 100: Loss = 4.0533\n",
            "Epoch 6, Batch 200: Loss = 3.9168\n",
            "Epoch 6, Batch 300: Loss = 4.1164\n",
            "Epoch 6: Validation Loss = 0.4839, Validation Accuracy = 0.83%\n",
            "Epoch 7, Batch 100: Loss = 3.2820\n",
            "Epoch 7, Batch 200: Loss = 3.0447\n",
            "Epoch 7, Batch 300: Loss = 2.5394\n",
            "Epoch 7: Validation Loss = 0.4810, Validation Accuracy = 0.84%\n",
            "Epoch 8, Batch 100: Loss = 3.3147\n",
            "Epoch 8, Batch 200: Loss = 4.3885\n",
            "Epoch 8, Batch 300: Loss = 2.5549\n",
            "Epoch 8: Validation Loss = 0.4714, Validation Accuracy = 0.84%\n",
            "Epoch 9, Batch 100: Loss = 3.7395\n",
            "Epoch 9, Batch 200: Loss = 3.2032\n",
            "Epoch 9, Batch 300: Loss = 3.8698\n",
            "Epoch 9: Validation Loss = 0.5384, Validation Accuracy = 0.82%\n",
            "Epoch 10, Batch 100: Loss = 3.1211\n",
            "Epoch 10, Batch 200: Loss = 2.8608\n",
            "Epoch 10, Batch 300: Loss = 4.8699\n",
            "Epoch 10: Validation Loss = 0.5050, Validation Accuracy = 0.83%\n",
            "Epoch 11, Batch 100: Loss = 3.2219\n",
            "Epoch 11, Batch 200: Loss = 3.9728\n",
            "Epoch 11, Batch 300: Loss = 3.2008\n",
            "Epoch 11: Validation Loss = 0.4929, Validation Accuracy = 0.83%\n",
            "Epoch 12, Batch 100: Loss = 3.5293\n",
            "Epoch 12, Batch 200: Loss = 2.5384\n",
            "Epoch 12, Batch 300: Loss = 3.8110\n",
            "Epoch 12: Validation Loss = 0.4319, Validation Accuracy = 0.87%\n",
            "Epoch 13, Batch 100: Loss = 3.6581\n",
            "Epoch 13, Batch 200: Loss = 2.1645\n",
            "Epoch 13, Batch 300: Loss = 2.0195\n",
            "Epoch 13: Validation Loss = 0.4552, Validation Accuracy = 0.86%\n",
            "Epoch 14, Batch 100: Loss = 3.0390\n",
            "Epoch 14, Batch 200: Loss = 4.1890\n",
            "Epoch 14, Batch 300: Loss = 3.4142\n",
            "Epoch 14: Validation Loss = 0.4270, Validation Accuracy = 0.87%\n",
            "Epoch 15, Batch 100: Loss = 2.7701\n",
            "Epoch 15, Batch 200: Loss = 3.5085\n",
            "Epoch 15, Batch 300: Loss = 2.9880\n",
            "Epoch 15: Validation Loss = 0.4668, Validation Accuracy = 0.87%\n",
            "Epoch 16, Batch 100: Loss = 2.7172\n",
            "Epoch 16, Batch 200: Loss = 2.1474\n",
            "Epoch 16, Batch 300: Loss = 2.8031\n",
            "Epoch 16: Validation Loss = 0.4758, Validation Accuracy = 0.86%\n",
            "Epoch 17, Batch 100: Loss = 2.7576\n",
            "Epoch 17, Batch 200: Loss = 2.5447\n",
            "Epoch 17, Batch 300: Loss = 2.9399\n",
            "Epoch 17: Validation Loss = 0.4764, Validation Accuracy = 0.86%\n",
            "Epoch 18, Batch 100: Loss = 2.2464\n",
            "Epoch 18, Batch 200: Loss = 2.7398\n",
            "Epoch 18, Batch 300: Loss = 3.0850\n",
            "Epoch 18: Validation Loss = 0.4846, Validation Accuracy = 0.87%\n",
            "Epoch 19, Batch 100: Loss = 2.2945\n",
            "Epoch 19, Batch 200: Loss = 1.9478\n",
            "Epoch 19, Batch 300: Loss = 1.6040\n",
            "Epoch 19: Validation Loss = 0.4518, Validation Accuracy = 0.88%\n",
            "Epoch 20, Batch 100: Loss = 1.8708\n",
            "Epoch 20, Batch 200: Loss = 2.3696\n",
            "Epoch 20, Batch 300: Loss = 1.6139\n",
            "Epoch 20: Validation Loss = 0.4526, Validation Accuracy = 0.88%\n",
            "Epoch 21, Batch 100: Loss = 1.7257\n",
            "Epoch 21, Batch 200: Loss = 1.9110\n",
            "Epoch 21, Batch 300: Loss = 2.4245\n",
            "Epoch 21: Validation Loss = 0.5032, Validation Accuracy = 0.88%\n",
            "Epoch 22, Batch 100: Loss = 2.1402\n",
            "Epoch 22, Batch 200: Loss = 2.4432\n",
            "Epoch 22, Batch 300: Loss = 2.0286\n",
            "Epoch 22: Validation Loss = 0.5253, Validation Accuracy = 0.88%\n",
            "Epoch 23, Batch 100: Loss = 1.0289\n",
            "Epoch 23, Batch 200: Loss = 2.4412\n",
            "Epoch 23, Batch 300: Loss = 2.0596\n",
            "Epoch 23: Validation Loss = 0.5339, Validation Accuracy = 0.88%\n",
            "Epoch 24, Batch 100: Loss = 1.7521\n",
            "Epoch 24, Batch 200: Loss = 1.8299\n",
            "Epoch 24, Batch 300: Loss = 1.9561\n",
            "Epoch 24: Validation Loss = 0.5350, Validation Accuracy = 0.88%\n",
            "Epoch 25, Batch 100: Loss = 1.1484\n",
            "Epoch 25, Batch 200: Loss = 0.8184\n",
            "Epoch 25, Batch 300: Loss = 1.9237\n",
            "Epoch 25: Validation Loss = 0.5482, Validation Accuracy = 0.88%\n",
            "Checkpoint saved at: checkpoints_student/checkpoint_epoch_25.pth\n",
            "Epoch 26, Batch 100: Loss = 1.7324\n",
            "Epoch 26, Batch 200: Loss = 1.6223\n",
            "Epoch 26, Batch 300: Loss = 1.7353\n",
            "Epoch 26: Validation Loss = 0.6126, Validation Accuracy = 0.88%\n",
            "Epoch 27, Batch 100: Loss = 1.9053\n",
            "Epoch 27, Batch 200: Loss = 2.3277\n",
            "Epoch 27, Batch 300: Loss = 2.0487\n",
            "Epoch 27: Validation Loss = 0.5941, Validation Accuracy = 0.88%\n",
            "Epoch 28, Batch 100: Loss = 1.3187\n",
            "Epoch 28, Batch 200: Loss = 2.0089\n",
            "Epoch 28, Batch 300: Loss = 1.2275\n",
            "Epoch 28: Validation Loss = 0.5580, Validation Accuracy = 0.89%\n",
            "Epoch 29, Batch 100: Loss = 2.4250\n",
            "Epoch 29, Batch 200: Loss = 1.4135\n",
            "Epoch 29, Batch 300: Loss = 1.5065\n",
            "Epoch 29: Validation Loss = 0.5836, Validation Accuracy = 0.88%\n",
            "Epoch 30, Batch 100: Loss = 1.2179\n",
            "Epoch 30, Batch 200: Loss = 1.8056\n",
            "Epoch 30, Batch 300: Loss = 1.2113\n",
            "Epoch 30: Validation Loss = 0.6212, Validation Accuracy = 0.88%\n",
            "Epoch 31, Batch 100: Loss = 1.8033\n",
            "Epoch 31, Batch 200: Loss = 1.8045\n",
            "Epoch 31, Batch 300: Loss = 1.7103\n",
            "Epoch 31: Validation Loss = 0.6317, Validation Accuracy = 0.89%\n",
            "Epoch 32, Batch 100: Loss = 1.9026\n",
            "Epoch 32, Batch 200: Loss = 1.6407\n",
            "Epoch 32, Batch 300: Loss = 0.9113\n",
            "Epoch 32: Validation Loss = 0.6177, Validation Accuracy = 0.89%\n",
            "Epoch 33, Batch 100: Loss = 2.1022\n",
            "Epoch 33, Batch 200: Loss = 1.7019\n",
            "Epoch 33, Batch 300: Loss = 2.2042\n",
            "Epoch 33: Validation Loss = 0.6031, Validation Accuracy = 0.89%\n",
            "Epoch 34, Batch 100: Loss = 2.0035\n",
            "Epoch 34, Batch 200: Loss = 2.0024\n",
            "Epoch 34, Batch 300: Loss = 1.4056\n",
            "Epoch 34: Validation Loss = 0.6109, Validation Accuracy = 0.89%\n",
            "Epoch 35, Batch 100: Loss = 2.0010\n",
            "Epoch 35, Batch 200: Loss = 1.9029\n",
            "Epoch 35, Batch 300: Loss = 1.3049\n",
            "Epoch 35: Validation Loss = 0.6087, Validation Accuracy = 0.90%\n",
            "Epoch 36, Batch 100: Loss = 1.4057\n",
            "Epoch 36, Batch 200: Loss = 1.4005\n",
            "Epoch 36, Batch 300: Loss = 1.1005\n",
            "Epoch 36: Validation Loss = 0.6365, Validation Accuracy = 0.89%\n",
            "Epoch 37, Batch 100: Loss = 0.9006\n",
            "Epoch 37, Batch 200: Loss = 1.3005\n",
            "Epoch 37, Batch 300: Loss = 1.3005\n",
            "Epoch 37: Validation Loss = 0.6140, Validation Accuracy = 0.90%\n",
            "Epoch 38, Batch 100: Loss = 1.3003\n",
            "Epoch 38, Batch 200: Loss = 1.6005\n",
            "Epoch 38, Batch 300: Loss = 1.1005\n",
            "Epoch 38: Validation Loss = 0.6325, Validation Accuracy = 0.90%\n",
            "Epoch 39, Batch 100: Loss = 1.4018\n",
            "Epoch 39, Batch 200: Loss = 1.1012\n",
            "Epoch 39, Batch 300: Loss = 0.8001\n",
            "Epoch 39: Validation Loss = 0.6533, Validation Accuracy = 0.90%\n",
            "Epoch 40, Batch 100: Loss = 2.3013\n",
            "Epoch 40, Batch 200: Loss = 1.4004\n",
            "Epoch 40, Batch 300: Loss = 1.3006\n",
            "Epoch 40: Validation Loss = 0.6519, Validation Accuracy = 0.89%\n",
            "Epoch 41, Batch 100: Loss = 0.9009\n",
            "Epoch 41, Batch 200: Loss = 1.2008\n",
            "Epoch 41, Batch 300: Loss = 1.4001\n",
            "Epoch 41: Validation Loss = 0.6806, Validation Accuracy = 0.89%\n",
            "Epoch 42, Batch 100: Loss = 1.2003\n",
            "Epoch 42, Batch 200: Loss = 1.6002\n",
            "Epoch 42, Batch 300: Loss = 1.5013\n",
            "Epoch 42: Validation Loss = 0.6758, Validation Accuracy = 0.90%\n",
            "Epoch 43, Batch 100: Loss = 0.6003\n",
            "Epoch 43, Batch 200: Loss = 0.7001\n",
            "Epoch 43, Batch 300: Loss = 1.1003\n",
            "Epoch 43: Validation Loss = 0.6623, Validation Accuracy = 0.90%\n",
            "Epoch 44, Batch 100: Loss = 1.7001\n",
            "Epoch 44, Batch 200: Loss = 1.3002\n",
            "Epoch 44, Batch 300: Loss = 1.2004\n",
            "Epoch 44: Validation Loss = 0.6890, Validation Accuracy = 0.90%\n",
            "Epoch 45, Batch 100: Loss = 1.5001\n",
            "Epoch 45, Batch 200: Loss = 1.2002\n",
            "Epoch 45, Batch 300: Loss = 1.0001\n",
            "Epoch 45: Validation Loss = 0.7015, Validation Accuracy = 0.89%\n",
            "Epoch 46, Batch 100: Loss = 1.4002\n",
            "Epoch 46, Batch 200: Loss = 0.5007\n",
            "Epoch 46, Batch 300: Loss = 1.1001\n",
            "Epoch 46: Validation Loss = 0.7076, Validation Accuracy = 0.89%\n",
            "Epoch 47, Batch 100: Loss = 1.0007\n",
            "Epoch 47, Batch 200: Loss = 1.0003\n",
            "Epoch 47, Batch 300: Loss = 0.4003\n",
            "Epoch 47: Validation Loss = 0.7168, Validation Accuracy = 0.90%\n",
            "Epoch 48, Batch 100: Loss = 1.3003\n",
            "Epoch 48, Batch 200: Loss = 0.8002\n",
            "Epoch 48, Batch 300: Loss = 0.8002\n",
            "Epoch 48: Validation Loss = 0.7032, Validation Accuracy = 0.90%\n",
            "Epoch 49, Batch 100: Loss = 1.1001\n",
            "Epoch 49, Batch 200: Loss = 1.4002\n",
            "Epoch 49, Batch 300: Loss = 1.0002\n",
            "Epoch 49: Validation Loss = 0.7065, Validation Accuracy = 0.90%\n",
            "Epoch 50, Batch 100: Loss = 1.1003\n",
            "Epoch 50, Batch 200: Loss = 0.8002\n",
            "Epoch 50, Batch 300: Loss = 1.6002\n",
            "Epoch 50: Validation Loss = 0.6811, Validation Accuracy = 0.90%\n",
            "Checkpoint saved at: checkpoints_student/checkpoint_epoch_50.pth\n",
            "Epoch 51, Batch 100: Loss = 1.5001\n",
            "Epoch 51, Batch 200: Loss = 1.0002\n",
            "Epoch 51, Batch 300: Loss = 1.0001\n",
            "Epoch 51: Validation Loss = 0.7011, Validation Accuracy = 0.90%\n",
            "Epoch 52, Batch 100: Loss = 1.0001\n",
            "Epoch 52, Batch 200: Loss = 1.4003\n",
            "Epoch 52, Batch 300: Loss = 1.3002\n",
            "Epoch 52: Validation Loss = 0.7318, Validation Accuracy = 0.90%\n",
            "Epoch 53, Batch 100: Loss = 0.9002\n",
            "Epoch 53, Batch 200: Loss = 1.0002\n",
            "Epoch 53, Batch 300: Loss = 1.1003\n",
            "Epoch 53: Validation Loss = 0.6826, Validation Accuracy = 0.90%\n",
            "Epoch 54, Batch 100: Loss = 1.4001\n",
            "Epoch 54, Batch 200: Loss = 1.5001\n",
            "Epoch 54, Batch 300: Loss = 0.6002\n",
            "Epoch 54: Validation Loss = 0.7347, Validation Accuracy = 0.89%\n",
            "Epoch 55, Batch 100: Loss = 1.3002\n",
            "Epoch 55, Batch 200: Loss = 1.2002\n",
            "Epoch 55, Batch 300: Loss = 1.4001\n",
            "Epoch 55: Validation Loss = 0.7445, Validation Accuracy = 0.90%\n",
            "Epoch 56, Batch 100: Loss = 1.5001\n",
            "Epoch 56, Batch 200: Loss = 1.1002\n",
            "Epoch 56, Batch 300: Loss = 1.4002\n",
            "Epoch 56: Validation Loss = 0.7692, Validation Accuracy = 0.89%\n",
            "Epoch 57, Batch 100: Loss = 1.0002\n",
            "Epoch 57, Batch 200: Loss = 0.7002\n",
            "Epoch 57, Batch 300: Loss = 0.6002\n",
            "Epoch 57: Validation Loss = 0.7272, Validation Accuracy = 0.89%\n",
            "Epoch 58, Batch 100: Loss = 0.7001\n",
            "Epoch 58, Batch 200: Loss = 1.1002\n",
            "Epoch 58, Batch 300: Loss = 0.9001\n",
            "Epoch 58: Validation Loss = 0.7283, Validation Accuracy = 0.90%\n",
            "Epoch 59, Batch 100: Loss = 1.1001\n",
            "Epoch 59, Batch 200: Loss = 1.0002\n",
            "Epoch 59, Batch 300: Loss = 1.3002\n",
            "Epoch 59: Validation Loss = 0.7650, Validation Accuracy = 0.90%\n",
            "Epoch 60, Batch 100: Loss = 1.6001\n",
            "Epoch 60, Batch 200: Loss = 1.4002\n",
            "Epoch 60, Batch 300: Loss = 1.2001\n",
            "Epoch 60: Validation Loss = 0.7307, Validation Accuracy = 0.90%\n",
            "Epoch 61, Batch 100: Loss = 0.9002\n",
            "Epoch 61, Batch 200: Loss = 1.2001\n",
            "Epoch 61, Batch 300: Loss = 1.6001\n",
            "Epoch 61: Validation Loss = 0.7414, Validation Accuracy = 0.90%\n",
            "Epoch 62, Batch 100: Loss = 1.2001\n",
            "Epoch 62, Batch 200: Loss = 1.0001\n",
            "Epoch 62, Batch 300: Loss = 1.7001\n",
            "Epoch 62: Validation Loss = 0.7355, Validation Accuracy = 0.90%\n",
            "Epoch 63, Batch 100: Loss = 1.1002\n",
            "Epoch 63, Batch 200: Loss = 0.8002\n",
            "Epoch 63, Batch 300: Loss = 1.7000\n",
            "Epoch 63: Validation Loss = 0.7315, Validation Accuracy = 0.89%\n",
            "Epoch 64, Batch 100: Loss = 1.0001\n",
            "Epoch 64, Batch 200: Loss = 1.4001\n",
            "Epoch 64, Batch 300: Loss = 0.8001\n",
            "Epoch 64: Validation Loss = 0.7468, Validation Accuracy = 0.90%\n",
            "Epoch 65, Batch 100: Loss = 0.9002\n",
            "Epoch 65, Batch 200: Loss = 0.8001\n",
            "Epoch 65, Batch 300: Loss = 1.0001\n",
            "Epoch 65: Validation Loss = 0.7548, Validation Accuracy = 0.90%\n",
            "Epoch 66, Batch 100: Loss = 1.0002\n",
            "Epoch 66, Batch 200: Loss = 0.7002\n",
            "Epoch 66, Batch 300: Loss = 0.9000\n",
            "Epoch 66: Validation Loss = 0.7893, Validation Accuracy = 0.89%\n",
            "Epoch 67, Batch 100: Loss = 1.6002\n",
            "Epoch 67, Batch 200: Loss = 1.5001\n",
            "Epoch 67, Batch 300: Loss = 1.2001\n",
            "Epoch 67: Validation Loss = 0.7711, Validation Accuracy = 0.89%\n",
            "Epoch 68, Batch 100: Loss = 0.8000\n",
            "Epoch 68, Batch 200: Loss = 1.3001\n",
            "Epoch 68, Batch 300: Loss = 0.8001\n",
            "Epoch 68: Validation Loss = 0.7603, Validation Accuracy = 0.90%\n",
            "Epoch 69, Batch 100: Loss = 0.5001\n",
            "Epoch 69, Batch 200: Loss = 0.9001\n",
            "Epoch 69, Batch 300: Loss = 0.5001\n",
            "Epoch 69: Validation Loss = 0.7392, Validation Accuracy = 0.90%\n",
            "Epoch 70, Batch 100: Loss = 1.1001\n",
            "Epoch 70, Batch 200: Loss = 1.0002\n",
            "Epoch 70, Batch 300: Loss = 0.9001\n",
            "Epoch 70: Validation Loss = 0.8044, Validation Accuracy = 0.89%\n",
            "Epoch 71, Batch 100: Loss = 1.2000\n",
            "Epoch 71, Batch 200: Loss = 1.2001\n",
            "Epoch 71, Batch 300: Loss = 1.3002\n",
            "Epoch 71: Validation Loss = 0.7770, Validation Accuracy = 0.89%\n",
            "Epoch 72, Batch 100: Loss = 0.9001\n",
            "Epoch 72, Batch 200: Loss = 0.2001\n",
            "Epoch 72, Batch 300: Loss = 1.5001\n",
            "Epoch 72: Validation Loss = 0.7748, Validation Accuracy = 0.89%\n",
            "Epoch 73, Batch 100: Loss = 1.1002\n",
            "Epoch 73, Batch 200: Loss = 0.7001\n",
            "Epoch 73, Batch 300: Loss = 0.7001\n",
            "Epoch 73: Validation Loss = 0.7703, Validation Accuracy = 0.90%\n",
            "Epoch 74, Batch 100: Loss = 1.3001\n",
            "Epoch 74, Batch 200: Loss = 0.9001\n",
            "Epoch 74, Batch 300: Loss = 0.9001\n",
            "Epoch 74: Validation Loss = 0.7814, Validation Accuracy = 0.89%\n",
            "Epoch 75, Batch 100: Loss = 1.0001\n",
            "Epoch 75, Batch 200: Loss = 1.3000\n",
            "Epoch 75, Batch 300: Loss = 1.0001\n",
            "Epoch 75: Validation Loss = 0.7791, Validation Accuracy = 0.89%\n",
            "Checkpoint saved at: checkpoints_student/checkpoint_epoch_75.pth\n",
            "Epoch 76, Batch 100: Loss = 1.3001\n",
            "Epoch 76, Batch 200: Loss = 1.1000\n",
            "Epoch 76, Batch 300: Loss = 1.2001\n",
            "Epoch 76: Validation Loss = 0.7750, Validation Accuracy = 0.90%\n",
            "Epoch 77, Batch 100: Loss = 0.7001\n",
            "Epoch 77, Batch 200: Loss = 0.9001\n",
            "Epoch 77, Batch 300: Loss = 0.7001\n",
            "Epoch 77: Validation Loss = 0.7349, Validation Accuracy = 0.90%\n",
            "Epoch 78, Batch 100: Loss = 0.7001\n",
            "Epoch 78, Batch 200: Loss = 1.1001\n",
            "Epoch 78, Batch 300: Loss = 1.1001\n",
            "Epoch 78: Validation Loss = 0.7628, Validation Accuracy = 0.89%\n",
            "Epoch 79, Batch 100: Loss = 1.3001\n",
            "Epoch 79, Batch 200: Loss = 0.8000\n",
            "Epoch 79, Batch 300: Loss = 0.4000\n",
            "Epoch 79: Validation Loss = 0.7567, Validation Accuracy = 0.90%\n",
            "Epoch 80, Batch 100: Loss = 1.2002\n",
            "Epoch 80, Batch 200: Loss = 1.1001\n",
            "Epoch 80, Batch 300: Loss = 0.7000\n",
            "Epoch 80: Validation Loss = 0.7726, Validation Accuracy = 0.90%\n",
            "Epoch 81, Batch 100: Loss = 0.9002\n",
            "Epoch 81, Batch 200: Loss = 1.0001\n",
            "Epoch 81, Batch 300: Loss = 1.1001\n",
            "Epoch 81: Validation Loss = 0.7846, Validation Accuracy = 0.90%\n",
            "Epoch 82, Batch 100: Loss = 1.2001\n",
            "Epoch 82, Batch 200: Loss = 0.3001\n",
            "Epoch 82, Batch 300: Loss = 1.0001\n",
            "Epoch 82: Validation Loss = 0.7595, Validation Accuracy = 0.90%\n",
            "Epoch 83, Batch 100: Loss = 1.2001\n",
            "Epoch 83, Batch 200: Loss = 1.0001\n",
            "Epoch 83, Batch 300: Loss = 1.0001\n",
            "Epoch 83: Validation Loss = 0.7536, Validation Accuracy = 0.89%\n",
            "Epoch 84, Batch 100: Loss = 0.8001\n",
            "Epoch 84, Batch 200: Loss = 1.3001\n",
            "Epoch 84, Batch 300: Loss = 0.7001\n",
            "Epoch 84: Validation Loss = 0.7969, Validation Accuracy = 0.89%\n",
            "Epoch 85, Batch 100: Loss = 1.1000\n",
            "Epoch 85, Batch 200: Loss = 0.7001\n",
            "Epoch 85, Batch 300: Loss = 0.9001\n",
            "Epoch 85: Validation Loss = 0.7934, Validation Accuracy = 0.89%\n",
            "Epoch 86, Batch 100: Loss = 0.9000\n",
            "Epoch 86, Batch 200: Loss = 0.9001\n",
            "Epoch 86, Batch 300: Loss = 0.8000\n",
            "Epoch 86: Validation Loss = 0.7526, Validation Accuracy = 0.90%\n",
            "Epoch 87, Batch 100: Loss = 0.7002\n",
            "Epoch 87, Batch 200: Loss = 1.3001\n",
            "Epoch 87, Batch 300: Loss = 1.4001\n",
            "Epoch 87: Validation Loss = 0.7654, Validation Accuracy = 0.90%\n",
            "Epoch 88, Batch 100: Loss = 1.2001\n",
            "Epoch 88, Batch 200: Loss = 0.5001\n",
            "Epoch 88, Batch 300: Loss = 0.6002\n",
            "Epoch 88: Validation Loss = 0.7464, Validation Accuracy = 0.90%\n",
            "Epoch 89, Batch 100: Loss = 0.9001\n",
            "Epoch 89, Batch 200: Loss = 0.8000\n",
            "Epoch 89, Batch 300: Loss = 1.0001\n",
            "Epoch 89: Validation Loss = 0.7599, Validation Accuracy = 0.90%\n",
            "Epoch 90, Batch 100: Loss = 1.0001\n",
            "Epoch 90, Batch 200: Loss = 0.7001\n",
            "Epoch 90, Batch 300: Loss = 0.6001\n",
            "Epoch 90: Validation Loss = 0.7818, Validation Accuracy = 0.89%\n",
            "Epoch 91, Batch 100: Loss = 0.9001\n",
            "Epoch 91, Batch 200: Loss = 0.6001\n",
            "Epoch 91, Batch 300: Loss = 1.7000\n",
            "Epoch 91: Validation Loss = 0.7744, Validation Accuracy = 0.89%\n",
            "Epoch 92, Batch 100: Loss = 1.1001\n",
            "Epoch 92, Batch 200: Loss = 0.8000\n",
            "Epoch 92, Batch 300: Loss = 0.9001\n",
            "Epoch 92: Validation Loss = 0.7783, Validation Accuracy = 0.89%\n",
            "Epoch 93, Batch 100: Loss = 1.1001\n",
            "Epoch 93, Batch 200: Loss = 1.4001\n",
            "Epoch 93, Batch 300: Loss = 0.4000\n",
            "Epoch 93: Validation Loss = 0.7721, Validation Accuracy = 0.89%\n",
            "Epoch 94, Batch 100: Loss = 0.9001\n",
            "Epoch 94, Batch 200: Loss = 0.9001\n",
            "Epoch 94, Batch 300: Loss = 1.1001\n",
            "Epoch 94: Validation Loss = 0.7879, Validation Accuracy = 0.89%\n",
            "Epoch 95, Batch 100: Loss = 0.8001\n",
            "Epoch 95, Batch 200: Loss = 1.0001\n",
            "Epoch 95, Batch 300: Loss = 1.2000\n",
            "Epoch 95: Validation Loss = 0.8231, Validation Accuracy = 0.89%\n",
            "Epoch 96, Batch 100: Loss = 1.5001\n",
            "Epoch 96, Batch 200: Loss = 0.7001\n",
            "Epoch 96, Batch 300: Loss = 1.3001\n",
            "Epoch 96: Validation Loss = 0.7862, Validation Accuracy = 0.89%\n",
            "Epoch 97, Batch 100: Loss = 1.0001\n",
            "Epoch 97, Batch 200: Loss = 0.9001\n",
            "Epoch 97, Batch 300: Loss = 1.5001\n",
            "Epoch 97: Validation Loss = 0.7729, Validation Accuracy = 0.90%\n",
            "Epoch 98, Batch 100: Loss = 1.3000\n",
            "Epoch 98, Batch 200: Loss = 1.5001\n",
            "Epoch 98, Batch 300: Loss = 0.6001\n",
            "Epoch 98: Validation Loss = 0.7584, Validation Accuracy = 0.90%\n",
            "Epoch 99, Batch 100: Loss = 0.7001\n",
            "Epoch 99, Batch 200: Loss = 0.8000\n",
            "Epoch 99, Batch 300: Loss = 0.7000\n",
            "Epoch 99: Validation Loss = 0.7761, Validation Accuracy = 0.89%\n",
            "Epoch 100, Batch 100: Loss = 0.6000\n",
            "Epoch 100, Batch 200: Loss = 0.9001\n",
            "Epoch 100, Batch 300: Loss = 0.7001\n",
            "Epoch 100: Validation Loss = 0.7736, Validation Accuracy = 0.90%\n",
            "Checkpoint saved at: checkpoints_student/checkpoint_epoch_100.pth\n",
            "Epoch 101, Batch 100: Loss = 1.3001\n",
            "Epoch 101, Batch 200: Loss = 0.9001\n",
            "Epoch 101, Batch 300: Loss = 0.7000\n",
            "Epoch 101: Validation Loss = 0.7943, Validation Accuracy = 0.90%\n",
            "Epoch 102, Batch 100: Loss = 0.9000\n",
            "Epoch 102, Batch 200: Loss = 0.5001\n",
            "Epoch 102, Batch 300: Loss = 1.1000\n",
            "Epoch 102: Validation Loss = 0.8054, Validation Accuracy = 0.90%\n",
            "Epoch 103, Batch 100: Loss = 0.8000\n",
            "Epoch 103, Batch 200: Loss = 0.9001\n",
            "Epoch 103, Batch 300: Loss = 1.3000\n",
            "Epoch 103: Validation Loss = 0.7745, Validation Accuracy = 0.89%\n",
            "Epoch 104, Batch 100: Loss = 1.0001\n",
            "Epoch 104, Batch 200: Loss = 1.0000\n",
            "Epoch 104, Batch 300: Loss = 0.6001\n",
            "Epoch 104: Validation Loss = 0.8237, Validation Accuracy = 0.89%\n",
            "Epoch 105, Batch 100: Loss = 0.5000\n",
            "Epoch 105, Batch 200: Loss = 0.7001\n",
            "Epoch 105, Batch 300: Loss = 0.9000\n",
            "Epoch 105: Validation Loss = 0.8142, Validation Accuracy = 0.89%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m student_params_num \u001b[38;5;241m=\u001b[39m count_parameters(prepared_student)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(pruning_factor, student_params_num, count_parameters(teacher_net))\n\u001b[1;32m---> 57\u001b[0m results_distill[(hparam_tuple, pruning_factor)] \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainStudentOnHparamAT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepared_student\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfast_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfast_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcheckpoints_path_student\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msgd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     66\u001b[0m prepared_student\u001b[38;5;241m.\u001b[39meval()\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\utils.py:841\u001b[0m, in \u001b[0;36mtrainStudentOnHparamAT\u001b[1;34m(teacher_net, student_net, hparam, num_epochs, train_loader, val_loader, print_every, fast_device, quant, checkpoint_save_path, resume_checkpoint, optimizer_choice)\u001b[0m\n\u001b[0;32m    838\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(fast_device), labels\u001b[38;5;241m.\u001b[39mto(fast_device)\n\u001b[0;32m    839\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 841\u001b[0m student_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mstudent_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    843\u001b[0m     teacher_outputs \u001b[38;5;241m=\u001b[39m teacher_net(inputs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\networks.py:105\u001b[0m, in \u001b[0;36mStudentNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    104\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant(x)\n\u001b[1;32m--> 105\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdequant(x)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\networks.py:27\u001b[0m, in \u001b[0;36mTeacherNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\quantized_resnet18.py:17\u001b[0m, in \u001b[0;36mQuantizedBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     15\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 17\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:147\u001b[0m, in \u001b[0;36m_observer_forward_hook\u001b[1;34m(self, input, output)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_observer_forward_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, output):\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward hook that calls observer on the output\"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\fake_quantize.py:408\u001b[0m, in \u001b[0;36mFusedMovingAvgObsFakeQuantize.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfused_moving_avg_obs_fake_quant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserver_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_quant_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maveraging_constant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mch_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_per_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_symmetric_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "pruning_factor = 0\n",
        "\n",
        "\n",
        "checkpoints_path_student = 'checkpoints_student/'\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparam['dist_ratio'] = 0.5,\n",
        "    hparam['angle_ratio'] = 0.5\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "pruning_factors = [0]\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "    student_net.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
        "    prepared_student = torch.quantization.prepare_qat(student_net)\n",
        "    prepared_student.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(prepared_student)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "    results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparamAT(\n",
        "            teacher_net, prepared_student, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=True, checkpoint_save_path= checkpoints_path_student, resume_checkpoint=False,\n",
        "            optimizer_choice='sgd'\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    prepared_student.eval()\n",
        "    \n",
        "    quantized_model = torch.quantization.convert(prepared_student)\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': quantized_model.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device) # 'cpu'\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_10944\\538120021.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(f'checkpoints_student/checkpoint_epoch_{cp}.pth')\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.8745\n",
            "test accuracy:  0.8901\n",
            "test accuracy:  0.8906\n",
            "test accuracy:  0.89\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "from torch.quantization import fuse_modules\n",
        "\n",
        "checkpoints = [x for x in range(25, 101, 25)]\n",
        "test_accs = []\n",
        "\n",
        "for cp in checkpoints:\n",
        "    student_net = networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "    checkpoint = torch.load(f'checkpoints_student/checkpoint_epoch_{cp}.pth')\n",
        "    student_net.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
        "    student_net = torch.quantization.prepare_qat(student_net)\n",
        "    \n",
        "    student_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    student_net.to(fast_device)\n",
        "    student_net.eval()\n",
        "\n",
        "    student_net.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
        "\n",
        "    student_net_prepared = torch.ao.quantization.prepare(student_net)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in train_loader:\n",
        "            inputs = inputs.to(fast_device)\n",
        "            student_net_prepared(inputs)  # Run a forward pass to collect activation statistics\n",
        "    student_net_prepared.to(fast_device)\n",
        "\n",
        "    #student_net_int8 = torch.ao.quantization.convert(student_net_prepared)\n",
        "    reproducibilitySeed()\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net_prepared, test_loader, fast_device)\n",
        "    print('test accuracy: ', test_accuracy)\n",
        "    test_accs.append(test_accuracy)\n",
        "\n",
        "# Plotting the test accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(checkpoints, test_accs, marker='o', linestyle='-', color='b')\n",
        "plt.title('Test Accuracy of Quantized Models at Different Checkpoints')\n",
        "plt.xlabel('Checkpoint Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xticks(checkpoints)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student 0 test accuracy at epoch 0: 0.4302\n",
            "Student 1 test accuracy at epoch 0: 0.7696\n",
            "Student 0 test accuracy at epoch 1: 0.5102\n",
            "Student 1 test accuracy at epoch 1: 0.8331\n",
            "Student 0 test accuracy at epoch 2: 0.5591\n",
            "Student 1 test accuracy at epoch 2: 0.8506\n",
            "Student 0 test accuracy at epoch 3: 0.5937\n",
            "Student 1 test accuracy at epoch 3: 0.8554\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 200\n",
        "print_every = 100\n",
        "\n",
        "# Setup for the hyperparameters and training configurations\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "pruning_factor = 0\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {\n",
        "        'alpha': hparam_tuple[0],\n",
        "        'T': hparam_tuple[1],\n",
        "        'dropout_input': hparam_tuple[2][0],\n",
        "        'dropout_hidden': hparam_tuple[2][1],\n",
        "        'weight_decay': hparam_tuple[3],\n",
        "        'lr_decay': hparam_tuple[4],\n",
        "        'momentum': hparam_tuple[5],\n",
        "        'lr': hparam_tuple[6]\n",
        "    }\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "# Training and logging setup\n",
        "csv_file = os.path.join(checkpoints_path_student_dml, \"results_student.csv\")\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Create multiple student models and their optimizers\n",
        "student_models = [networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=False, fuse=False, qat=False, dif_arch=False),  networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=False, fuse=False, qat=False, dif_arch=True)]  # Create multiple instances for DML\n",
        "optimizers = [optim.SGD(student.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0) for student in student_models]\n",
        "\n",
        "def trainDML(student_models, hparam, num_epochs, train_loader, val_loader, optimizers, fast_device=torch.device('cuda:0')):\n",
        "    for student in student_models:\n",
        "        student.to(fast_device).train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for data, labels in train_loader:\n",
        "            data, labels = data.to(fast_device), labels.to(fast_device)\n",
        "\n",
        "            # Zero the parameter gradients for all optimizers at the start of the batch processing\n",
        "            for optimizer in optimizers:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            outputs = [student(data) for student in student_models]\n",
        "            losses = []\n",
        "\n",
        "            # Calculate losses for all students but do not yet backpropagate\n",
        "            for i, student_output in enumerate(outputs):\n",
        "                loss = criterion(student_output, labels)  # Standard classification loss\n",
        "                dml_loss = sum(F.mse_loss(F.softmax(student_output, dim=1), F.softmax(other_output, dim=1))\n",
        "                               for j, other_output in enumerate(outputs) if i != j)\n",
        "                total_loss = loss + dml_loss / (len(student_models) - 1)  # Normalize DML loss\n",
        "                losses.append(total_loss)\n",
        "\n",
        "            # Now backpropagate for all students\n",
        "            for i, loss in enumerate(losses):\n",
        "                loss.backward(retain_graph=True if i < len(student_models) - 1 else False)  # Retain graph for all but last loss\n",
        "\n",
        "            # Step the optimizers after all gradients are calculated\n",
        "            for optimizer in optimizers:\n",
        "                optimizer.step()\n",
        "\n",
        "        reproducibilitySeed()\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_models[0], test_loader, fast_device)\n",
        "        print(f'Student {0} test accuracy at epoch {epoch}: {test_accuracy}')\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_models[1], test_loader, fast_device)\n",
        "        print(f'Student {1} test accuracy at epoch {epoch}: {test_accuracy}')\n",
        "\n",
        "        if (epoch + 1) % 25 == 0:\n",
        "            for idx, student in enumerate(student_models):\n",
        "                torch.save(student.state_dict(), f\"{checkpoints_path_student_dml}student_{idx}_epoch_{epoch}.pth\")\n",
        "                print(f\"Checkpoint saved for Student {idx} at Epoch {epoch + 1}: {checkpoints_path_student_dml}student_{idx}_epoch_{epoch}.pth\")\n",
        "\n",
        "        # Add validation and additional logging as necessary\n",
        "\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "# Make sure to call this function with the correct parameters and dataloaders\n",
        "trainDML(student_models, hparam, 200, train_loader, val_loader, optimizers)\n",
        "# Further steps such as evaluation and logging results to CSV as shown above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV files\n",
        "quant_teacher = pd.read_csv(\"checkpoints_teacher/results_teacher_quantization.csv\")\n",
        "quant_student_nokd = pd.read_csv(\"checkpoints_student/checkpoints_student_NoKD/results_student_quantization.csv\")\n",
        "quant_student_van = pd.read_csv(\"checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\")\n",
        "\n",
        "# Add a row with original accuracy to both dataframes\n",
        "new_quant_teacher = pd.DataFrame({\"Bits\": [32], \"Quantized Test Accuracy\": [0.9225]})\n",
        "quant_teacher = pd.concat([quant_teacher, new_quant_teacher], ignore_index=True)\n",
        "\n",
        "new_quant_student_nokd = pd.DataFrame({\"Bits\": [32], \"Quantized Test Accuracy\": [0.8891]})\n",
        "quant_student_nokd = pd.concat([quant_student_nokd, new_quant_student_nokd], ignore_index=True)\n",
        "\n",
        "new_quant_student_van = pd.DataFrame({\"Bits\": [32], \"Quantized Test Accuracy\": [0.9152]})\n",
        "quant_student_van = pd.concat([quant_student_van, new_quant_student_van], ignore_index=True)\n",
        "\n",
        "# Plot both lines sharing the same axes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(quant_teacher[\"Bits\"], quant_teacher[\"Quantized Test Accuracy\"], marker='o', label=\"Teacher Model\")\n",
        "plt.plot(quant_student_nokd[\"Bits\"], quant_student_nokd[\"Quantized Test Accuracy\"], marker='o', label=\"Student Model without KD\")\n",
        "plt.plot(quant_student_van[\"Bits\"], quant_student_van[\"Quantized Test Accuracy\"], marker='o', label=\"Student Model with VKD\")\n",
        "\n",
        "# Add horizontal lines for original accuracy\n",
        "plt.axhline(y=new_quant_teacher[\"Quantized Test Accuracy\"].values[0], color='blue', linestyle='--', alpha=0.5)\n",
        "plt.axhline(y=new_quant_student_nokd[\"Quantized Test Accuracy\"].values[0], color='orange', linestyle='--', alpha=0.5)\n",
        "plt.axhline(y=new_quant_student_van[\"Quantized Test Accuracy\"].values[0], color='green', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Test Accuracy vs Bits Size\")\n",
        "plt.xlabel(\"Bits Size\")\n",
        "plt.ylabel(\"Quantized Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Method\", loc=\"best\")\n",
        "\n",
        "# Save the plot as PNG\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/teacher_student_quant_acc_comparison.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Original accuracies\n",
        "original_acc_teacher = 0.9225\n",
        "original_acc_student_nokd = 0.8891\n",
        "original_acc_student_van = 0.9152\n",
        "\n",
        "# Adjusting quantized test accuracy by subtracting the original accuracy\n",
        "quant_teacher['Quantized Test Accuracy Gap'] = quant_teacher['Quantized Test Accuracy'] - original_acc_teacher\n",
        "quant_student_nokd['Quantized Test Accuracy Gap'] = quant_student_nokd['Quantized Test Accuracy'] - original_acc_student_nokd\n",
        "quant_student_van['Quantized Test Accuracy Gap'] = quant_student_van['Quantized Test Accuracy'] - original_acc_student_van\n",
        "\n",
        "# Plot both lines sharing the same axes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(quant_teacher[\"Bits\"], quant_teacher[\"Quantized Test Accuracy Gap\"], marker='o', label=\"Teacher Model\")\n",
        "plt.plot(quant_student_nokd[\"Bits\"], quant_student_nokd[\"Quantized Test Accuracy Gap\"], marker='o', label=\"Student Model without KD\")\n",
        "plt.plot(quant_student_van[\"Bits\"], quant_student_van[\"Quantized Test Accuracy Gap\"], marker='o', label=\"Student Model with VKD\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Test Accuracy Gap vs Bits Size\")\n",
        "plt.xlabel(\"Bits Size\")\n",
        "plt.ylabel(\"Quantized Test Accuracy Gap\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Method\", loc=\"best\")\n",
        "\n",
        "# Save the plot as PNG\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/gap_teacher_student_quant_acc_comparison.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
