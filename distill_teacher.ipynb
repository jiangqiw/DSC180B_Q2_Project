{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bREGbUT_Y8F"
      },
      "source": [
        "### Import required packages and limit GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcqwxR8_Y8I",
        "outputId": "26140e84-9279-479e-cc80-7c9a0b1a8fd5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "#sys.path.append('/content/KD')\n",
        "# Import the module\n",
        "import networks\n",
        "import utils\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n73sKlgl_Y8K"
      },
      "outputs": [],
      "source": [
        "use_gpu = True    # set use_gpu to True if system has gpu\n",
        "gpu_id = 0        # id of gpu to be used\n",
        "cpu_device = torch.device('cpu')\n",
        "# fast_device is where computation (training, inference) happens\n",
        "fast_device = torch.device('cpu')\n",
        "if use_gpu:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
        "    fast_device = torch.device('cuda:' + str(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DAfPa7mw_Y8L"
      },
      "outputs": [],
      "source": [
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    if use_gpu:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o0sxuxkJbUEI"
      },
      "outputs": [],
      "source": [
        "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
        "checkpoints_path_student = 'checkpoints_student_QAT/'\n",
        "if not os.path.exists(checkpoints_path_teacher):\n",
        "    os.makedirs(checkpoints_path_teacher)\n",
        "if not os.path.exists(checkpoints_path_student):\n",
        "    os.makedirs(checkpoints_path_student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCz4Pup_Y8M"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import PIL\n",
        "\n",
        "# Set up transformations for CIFAR-10\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        #transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
        "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "import torchvision as tv\n",
        "preprocess_train = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((160, 160), interpolation=PIL.Image.BILINEAR),  # It's the default, just being explicit for the reader.\n",
        "    tv.transforms.RandomCrop((128, 128)),\n",
        "    tv.transforms.RandomHorizontalFlip(),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "preprocess_eval = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((128, 128), interpolation=PIL.Image.BILINEAR),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "# Split the training dataset into training and validation\n",
        "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
        "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8vAtxV_Y8N",
        "outputId": "797e7d9e-fa75-47c3-977a-22b6ef78b28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set up transformations for CIFAR-100\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        #transforms.RandomCrop(32, padding=4),  # Randomly crop with padding of 4 pixels\n",
        "        transforms.RandomHorizontalFlip(),     # Random horizontal flip\n",
        "        transforms.ToTensor(),                 # Convert to PyTorch tensor\n",
        "        transforms.Normalize(\n",
        "            (0.5071, 0.4867, 0.4408),         # Mean for CIFAR-100\n",
        "            (0.2675, 0.2565, 0.2761)          # Standard deviation for CIFAR-100\n",
        "        )  # Normalize images\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),                 # Convert to PyTorch tensor\n",
        "        transforms.Normalize(\n",
        "            (0.5071, 0.4867, 0.4408),         # Mean for CIFAR-100\n",
        "            (0.2675, 0.2565, 0.2761)          # Standard deviation for CIFAR-100\n",
        "        )  # Normalize images\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "train_val_dataset = torchvision.datasets.CIFAR100(root='./CIFAR100_dataset/', train=True,\n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./CIFAR100_dataset/', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "# Split the training dataset into training and validation\n",
        "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
        "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 512\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jywk1DS_Y8O"
      },
      "source": [
        "### Train teacher network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6wDSA64C_Y8R"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "print_every = 100    # Interval size for which to print statistics of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEnJ1A1_Y8T",
        "outputId": "3d5687b1-f814-41bf-9be6-8bd6d3c86577",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m reproducibilitySeed()\n\u001b[0;32m     38\u001b[0m teacher_net \u001b[38;5;241m=\u001b[39m networks\u001b[38;5;241m.\u001b[39mTeacherNetwork()\n\u001b[1;32m---> 39\u001b[0m teacher_net \u001b[38;5;241m=\u001b[39m \u001b[43mteacher_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfast_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m hparam_tuple \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mhparamDictToTuple(hparam)\n\u001b[0;32m     42\u001b[0m results[hparam_tuple] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtrainTeacherOnHparam(teacher_net, hparam, num_epochs, train_val_loader, \u001b[38;5;28;01mNone\u001b[39;00m, print_every\u001b[38;5;241m=\u001b[39mprint_every, fast_device\u001b[38;5;241m=\u001b[39mfast_device)\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define hyperparameter ranges\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-3]\n",
        "momentums = [0.90]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "\n",
        "# Prepare the list of hyperparameters\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {\n",
        "        'dropout_input': hparam_tuple[0][0],\n",
        "        'dropout_hidden': hparam_tuple[0][1],\n",
        "        'weight_decay': hparam_tuple[1],\n",
        "        'lr_decay': hparam_tuple[2],\n",
        "        'momentum': hparam_tuple[3],\n",
        "        'lr': hparam_tuple[4]\n",
        "    }\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "# Results dictionary\n",
        "results = {}\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = \"checkpoints_teacher/results_teacher\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam))\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    teacher_net = networks.TeacherNetwork()\n",
        "    teacher_net = teacher_net.to(fast_device)\n",
        "\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "    results[hparam_tuple] = utils.trainTeacherOnHparam(teacher_net, hparam, num_epochs, train_val_loader, None, print_every=print_every, fast_device=fast_device)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Save model\n",
        "    save_path = checkpoints_path_teacher + utils.hparamToString(hparam) + '_final.tar'\n",
        "    torch.save({\n",
        "        'results': results[hparam_tuple],\n",
        "        'model_state_dict': teacher_net.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'],\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load pre-trained teacher network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9752\n"
          ]
        }
      ],
      "source": [
        "# Path to the saved model\n",
        "teacher_path = \"checkpoints_teacher/dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001_final.tar\"\n",
        "\n",
        "# Initialize the network\n",
        "teacher_net = networks.TeacherNetworkBiT()\n",
        "teacher_net = teacher_net.to(fast_device)\n",
        "\n",
        "\n",
        "# pre-trained teacher accuracy\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_15720\\1847993978.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9616\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the teacher networks\n",
        "teacher_net_1 = networks.TeacherNetwork50()\n",
        "checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n",
        "\n",
        "\n",
        "teacher_net_1.model.load_state_dict(checkpoint)\n",
        "teacher_net_2 = networks.TeacherNetworkBiT()\n",
        "\n",
        "# Create the ensemble model\n",
        "teacher_net = networks.EnsembleModel(teacher_net_1, teacher_net_2)\n",
        "\n",
        "# Move the ensemble model to the appropriate device (e.g., GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "teacher_net = teacher_net.to(device)\n",
        "\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, device)\n",
        "print('test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_61408\\1010970965.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n"
          ]
        }
      ],
      "source": [
        "teacher_net = networks.TeacherNetwork50()\n",
        "checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n",
        "\n",
        "\n",
        "teacher_net.model.load_state_dict(checkpoint)\n",
        "\n",
        "teacher_net = teacher_net.to(fast_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayk6sDh7UXz"
      },
      "source": [
        "### Student Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Student Network (with training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hlvtw4Xkxhoh"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "print_every = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of trainable parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters.\n",
        "    \"\"\"\n",
        "    return sum((p.data != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def count_zero_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters that are exactly zero.\n",
        "    \"\"\"\n",
        "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23520842"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_parameters(teacher_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAXvRE-7a9bC",
        "outputId": "86382da5-7836-4b1f-e4e2-a1dd2ec8f8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=7, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.0005, lr_decay=0.95, momentum=0.9, weight_decay=0.0001 and pruning factor 0\n",
            "0 11173962 23520842\n",
            "[Epoch 51, Batch 100/372] Train Loss: 0.173, Train Accuracy: 0.141\n",
            "[Epoch 51, Batch 200/372] Train Loss: 0.318, Train Accuracy: 0.297\n",
            "[Epoch 51, Batch 300/372] Train Loss: 0.142, Train Accuracy: 0.977\n",
            "Epoch 51 Validation Accuracy: 0.938\n",
            "[Epoch 52, Batch 100/372] Train Loss: 0.147, Train Accuracy: 0.984\n",
            "[Epoch 52, Batch 200/372] Train Loss: 0.203, Train Accuracy: 0.117\n",
            "[Epoch 52, Batch 300/372] Train Loss: 0.355, Train Accuracy: 0.297\n",
            "Epoch 52 Validation Accuracy: 0.938\n",
            "[Epoch 53, Batch 100/372] Train Loss: 0.167, Train Accuracy: 0.977\n",
            "[Epoch 53, Batch 200/372] Train Loss: 0.233, Train Accuracy: 0.867\n",
            "[Epoch 53, Batch 300/372] Train Loss: 0.195, Train Accuracy: 0.922\n",
            "Epoch 53 Validation Accuracy: 0.937\n",
            "[Epoch 54, Batch 100/372] Train Loss: 0.289, Train Accuracy: 0.531\n",
            "[Epoch 54, Batch 200/372] Train Loss: 0.220, Train Accuracy: 0.914\n",
            "[Epoch 54, Batch 300/372] Train Loss: 0.126, Train Accuracy: 0.086\n",
            "Epoch 54 Validation Accuracy: 0.943\n",
            "[Epoch 55, Batch 100/372] Train Loss: 0.150, Train Accuracy: 0.094\n",
            "[Epoch 55, Batch 200/372] Train Loss: 0.163, Train Accuracy: 0.969\n",
            "[Epoch 55, Batch 300/372] Train Loss: 0.186, Train Accuracy: 0.094\n",
            "Epoch 55 Validation Accuracy: 0.933\n",
            "[Epoch 56, Batch 100/372] Train Loss: 0.059, Train Accuracy: 0.102\n",
            "[Epoch 56, Batch 200/372] Train Loss: 0.027, Train Accuracy: 0.227\n",
            "[Epoch 56, Batch 300/372] Train Loss: 0.016, Train Accuracy: 0.641\n",
            "Epoch 56 Validation Accuracy: 0.702\n",
            "[Epoch 57, Batch 100/372] Train Loss: 0.015, Train Accuracy: 0.156\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m student_params_num \u001b[38;5;241m=\u001b[39m count_parameters(student_net)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(pruning_factor, student_params_num, count_parameters(teacher_net))\n\u001b[1;32m---> 56\u001b[0m results_distill[(hparam_tuple, pruning_factor)] \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainStudentOnHparamMixup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfast_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfast_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcheckpoints_path_student\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstudent_BiT_no_QAT\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mT=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.0005, lr_decay=0.95, momentum=0.9, weight_decay=0.0001_checkpoint_epoch_50.tar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Final model save\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\daniel\\dsc180b\\DSC180B_Q2_Project\\utils.py:408\u001b[0m, in \u001b[0;36mtrainStudentOnHparamMixup\u001b[1;34m(teacher_net, student_net, hparam, num_epochs, train_loader, val_loader, print_every, fast_device, quant, mixup_alpha, checkpoint_save_path, resume_checkpoint)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;66;03m# Perform one training step with mixup\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m55\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m65\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mstudentTrainStepMixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudentLossFn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixup_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_teacher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacherLossFn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacherLossFn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m studentTrainStepMixup(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha, mixup_alpha\u001b[38;5;241m=\u001b[39mmixup_alpha)\n",
            "File \u001b[1;32mc:\\Users\\daniel\\dsc180b\\DSC180B_Q2_Project\\utils.py:280\u001b[0m, in \u001b[0;36mstudentTrainStepMixup\u001b[1;34m(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha, mixup_alpha, update_teacher, teacher_optimizer, teacherLossFn)\u001b[0m\n\u001b[0;32m    274\u001b[0m mixed_X, mixed_teacher_logits, mixed_labels, lam \u001b[38;5;241m=\u001b[39m mixup_function_matching(\n\u001b[0;32m    275\u001b[0m     X, teacher_logits, y_onehot, alpha\u001b[38;5;241m=\u001b[39mmixup_alpha\n\u001b[0;32m    276\u001b[0m )\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Forward pass through the student network\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m student_logits \u001b[38;5;241m=\u001b[39m \u001b[43mstudent_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixed_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Compute loss with mixup for the student network\u001b[39;00m\n\u001b[0;32m    283\u001b[0m student_loss \u001b[38;5;241m=\u001b[39m studentLossFn(mixed_teacher_logits, student_logits, mixed_labels, T, alpha)\n",
            "File \u001b[1;32mc:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1732\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1729\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[0;32m   1730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1734\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 400\n",
        "\n",
        "\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [7]\n",
        "alphas = [1.0]\n",
        "learning_rates = [5e-4]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-4]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "checkpoints_path_student = 'student_teacher_learn_BiT_longer/'\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "pruning_factors = [0]\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for pruning_factor in pruning_factors:\n",
        "    for hparam in hparams_list:\n",
        "        print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "        # Measure training time\n",
        "        start_time = time.time()\n",
        "\n",
        "        reproducibilitySeed()\n",
        "        student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=False, fuse=False, qat=False, dif_arch=True)\n",
        "        student_net.to(fast_device)\n",
        "        hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "        # Count parameters\n",
        "        student_params_num = count_parameters(student_net)\n",
        "        \n",
        "        print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "        results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparamMixup(\n",
        "                teacher_net, student_net, hparam, num_epochs,\n",
        "                train_loader, val_loader,\n",
        "                print_every=print_every,\n",
        "                fast_device=fast_device, quant=False, checkpoint_save_path= checkpoints_path_student, resume_checkpoint='student_BiT_no_QAT\\T=5, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.0005, lr_decay=0.95, momentum=0.9, weight_decay=0.0001_checkpoint_epoch_50.tar'\n",
        "            )\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Final model save\n",
        "        final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
        "        torch.save({\n",
        "            'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "            'model_state_dict': student_net.state_dict(),\n",
        "            'epoch': num_epochs\n",
        "        }, final_save_path)\n",
        "\n",
        "        # Calculate test accuracy\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "        print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "        # Write results to CSV\n",
        "        with open(csv_file, mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\n",
        "                hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "                hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "                test_accuracy, training_time\n",
        "            ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "c:\\Users\\daniel\\dsc180b\\DSC180B_Q2_Project\\utils.py:350: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume_checkpoint)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 11173962 23520842\n",
            "[Epoch 201, Batch 100/372] Train Loss: 1.751, Train Accuracy: 0.102\n",
            "[Epoch 201, Batch 200/372] Train Loss: 2.935, Train Accuracy: 0.383\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 400\n",
        "\n",
        "\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "checkpoints_path_student = 'student_resnet50_cosine_scheduler/'\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill = {}\n",
        "pruning_factors = [0]\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for pruning_factor in pruning_factors:\n",
        "    for hparam in hparams_list:\n",
        "        print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "        # Measure training time\n",
        "        start_time = time.time()\n",
        "\n",
        "        reproducibilitySeed()\n",
        "        student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "        student_net.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
        "        prepared_student = torch.quantization.prepare_qat(student_net)\n",
        "        prepared_student.to(fast_device)\n",
        "        hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "        # Count parameters\n",
        "        student_params_num = count_parameters(prepared_student)\n",
        "        \n",
        "        print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "        results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparamMixup(\n",
        "                teacher_net, prepared_student, hparam, num_epochs,\n",
        "                train_loader, val_loader,\n",
        "                print_every=print_every,\n",
        "                fast_device=fast_device, quant=True, checkpoint_save_path= checkpoints_path_student, resume_checkpoint='student_resnet50_cosine_scheduler\\T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0_checkpoint_epoch_200.tar',\n",
        "                optimizer_choice='sgd'\n",
        "            )\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        prepared_student.to('cpu')\n",
        "        prepared_student.eval()\n",
        "        \n",
        "        quantized_model = torch.quantization.convert(prepared_student)\n",
        "\n",
        "        # Final model save\n",
        "        final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + '.tar'\n",
        "        torch.save({\n",
        "            'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "            'model_state_dict': quantized_model.state_dict(),\n",
        "            'epoch': num_epochs\n",
        "        }, final_save_path)\n",
        "\n",
        "        # Calculate test accuracy\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, 'cpu')\n",
        "        print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "        # Write results to CSV\n",
        "        with open(csv_file, mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\n",
        "                hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "                hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "                test_accuracy, training_time\n",
        "            ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_46452\\2442132776.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  info = torch.load('checkpoints_student_QAT\\T=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001_pruning_0_final.tar')['results']\n"
          ]
        }
      ],
      "source": [
        "info = torch.load('checkpoints_student_QAT\\T=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001_pruning_0_final.tar')['results']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1fe6efb91d0>]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(info['val_acc'])\n",
        "plt.plot(info['train_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Student Network (without training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05 10623029 11181642\n",
            "Test accuracy:  0.8617\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.1\n",
            "0.1 10064428 11181642\n",
            "Test accuracy:  0.8622\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.15\n",
            "0.15 9505825 11181642\n",
            "Test accuracy:  0.862\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.2\n",
            "0.2 8947224 11181642\n",
            "Test accuracy:  0.8614\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.25\n",
            "0.25 8388631 11181642\n",
            "Test accuracy:  0.8595\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.3\n",
            "0.3 7830025 11181642\n",
            "Test accuracy:  0.8583\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.35\n",
            "0.35 7271420 11181642\n",
            "Test accuracy:  0.8582\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.4\n",
            "0.4 6712818 11181642\n",
            "Test accuracy:  0.8565\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.45\n",
            "0.45 6154222 11181642\n",
            "Test accuracy:  0.8553\n",
            "Training without hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001 and pruning factor 0.5\n",
            "0.5 5595620 11181642\n",
            "Test accuracy:  0.8534\n",
            "Results saved to checkpoints_student/results_student_wo\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter ranges\n",
        "learning_rates = [1e-2]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-3]\n",
        "momentums = [0.90]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "\n",
        "# Prepare the list of hyperparameters\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {\n",
        "        'dropout_input': hparam_tuple[0][0],\n",
        "        'dropout_hidden': hparam_tuple[0][1],\n",
        "        'weight_decay': hparam_tuple[1],\n",
        "        'lr_decay': hparam_tuple[2],\n",
        "        'momentum': hparam_tuple[3],\n",
        "        'lr': hparam_tuple[4]\n",
        "    }\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "# Results dictionary\n",
        "results = {}\n",
        "pruning_factors = [i/20 for i in range(1, 20)]\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = \"checkpoints_student/results_student_wo.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Trainable Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for pruning_factor in pruning_factors:\n",
        "    for hparam in hparams_list:\n",
        "        print('Training without hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "        # Measure training time\n",
        "        start_time = time.time()\n",
        "\n",
        "        reproducibilitySeed()\n",
        "        student_net_wo = networks.StudentNetwork(pruning_factor, teacher_net)\n",
        "        student_net_wo = student_net_wo.to(fast_device)\n",
        "        #hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "        # Count parameters\n",
        "        student_params_num = count_parameters(student_net_wo)\n",
        "        print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "\n",
        "        # Train the student network\n",
        "        #results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs,\n",
        "                                                                                    #train_val_loader, None,\n",
        "                                                                                    #print_every=print_every,\n",
        "                                                                                    #fast_device=fast_device)\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Save model\n",
        "        #save_path = checkpoints_path_student + utils.hparamToString(hparam) + f'_pruning_{pruning_factor}_w/o_final.tar'\n",
        "        #torch.save({\n",
        "            #'results': results_distill[(hparam_tuple, pruning_factor)],\n",
        "            #'model_state_dict': student_net.state_dict(),\n",
        "            #'epoch': num_epochs\n",
        "        #}, save_path)\n",
        "\n",
        "        # Calculate test accuracy\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net_wo, test_loader, fast_device)\n",
        "        print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "        # Write results to CSV\n",
        "        with open(csv_file, mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\n",
        "                hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "                hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "                test_accuracy, training_time\n",
        "            ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"your_checkpoint.tar\")\n",
        "\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(test_model, test_loader, fast_device)\n",
        "print('Test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqOQ_vv4flkh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "result = pd.DataFrame(columns=['Pruning Factor', 'Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iActiWzaIgPY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import networks  # Ensure the correct import of your networks module\n",
        "import utils  # Utilities for hyperparameter string conversion and more\n",
        "\n",
        "\n",
        "# Define your hyperparameters\n",
        "t = [10]\n",
        "alpha = [0.5]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "weight_decays = [1e-5]\n",
        "learning_rate_decays = [0.95]\n",
        "momentums = [0.9]\n",
        "learning_rates = [1e-2]\n",
        "pruning_factors = [i/32 for i in range(1, 33)]\n",
        "#pruning_factors = [0.1, 0.2]  # Example pruning factors\n",
        "\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(t, alpha, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {\n",
        "        'T': hparam_tuple[0],\n",
        "        'alpha': hparam_tuple[1],\n",
        "        'dropout_input': hparam_tuple[2][0],\n",
        "        'dropout_hidden': hparam_tuple[2][1],\n",
        "        'weight_decay': hparam_tuple[3],\n",
        "        'lr_decay': hparam_tuple[4],\n",
        "        'momentum': hparam_tuple[5],\n",
        "        'lr': hparam_tuple[6]\n",
        "    }\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "# Define the path to your checkpoints\n",
        "checkpoints_path_student = \"../content/checkpoints_student/\"\n",
        "\n",
        "# Load and set up each student model based on hyperparameters and pruning factor\n",
        "for hparam in hparams_list:\n",
        "    for prune_factor in pruning_factors:\n",
        "        filename = utils.hparamToString(hparam) + f'_pruning_{prune_factor}_final.tar'\n",
        "        load_path = checkpoints_path_student + filename\n",
        "\n",
        "        # Load the student network\n",
        "        student_net = networks.StudentNetwork(prune_amount=prune_factor)\n",
        "        student_net.load_state_dict(torch.load(load_path, map_location=fast_device, weights_only=True)['model_state_dict'])\n",
        "        student_net = student_net.to(fast_device)  # Move to the appropriate device, again adjust as needed\n",
        "\n",
        "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "\n",
        "        # Create a new DataFrame from the data to be added\n",
        "        new_data = pd.DataFrame({'Pruning Factor': [prune_factor], 'Accuracy': [test_accuracy]})\n",
        "        # Use concat to add the new data to the existing DataFrame\n",
        "        result = pd.concat([result, new_data], ignore_index=True)\n",
        "        print('student test accuracy for ' + f'pruning factor = {prune_factor}:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "dBh4uVqoeAno",
        "outputId": "b721ad18-ccd4-45cb-adc9-21cd1d549150"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d3956de329d1>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pruning Factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy vs Pruning Factor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pruning Factor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(result['Pruning Factor'], result['Accuracy'], marker='o')\n",
        "plt.title('Accuracy vs Pruning Factor')\n",
        "plt.xlabel('Pruning Factor')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq2518KJeA5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8QIxar6eBGE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdENhUOdeBSo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VZ89F7hMfnc",
        "outputId": "276e914c-e088-4363-90a2-1db91be81b9f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "StudentNetwork.__init__() missing 1 required positional argument: 'teacher_net'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming teacher_net and student_net are instances of TeacherNetwork and StudentNetwork, respectively\u001b[39;00m\n\u001b[0;32m      2\u001b[0m teacher_net \u001b[38;5;241m=\u001b[39m networks\u001b[38;5;241m.\u001b[39mTeacherNetwork()\n\u001b[1;32m----> 3\u001b[0m student_net \u001b[38;5;241m=\u001b[39m \u001b[43mnetworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStudentNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate and print the total number of parameters for both models\u001b[39;00m\n\u001b[0;32m      6\u001b[0m teacher_total_params \u001b[38;5;241m=\u001b[39m count_parameters(teacher_net)\n",
            "\u001b[1;31mTypeError\u001b[0m: StudentNetwork.__init__() missing 1 required positional argument: 'teacher_net'"
          ]
        }
      ],
      "source": [
        "# Assuming teacher_net and student_net are instances of TeacherNetwork and StudentNetwork, respectively\n",
        "teacher_net = networks.TeacherNetwork()\n",
        "student_net = networks.StudentNetwork(0.2)\n",
        "\n",
        "# Calculate and print the total number of parameters for both models\n",
        "teacher_total_params = count_parameters(teacher_net)\n",
        "student_total_params = count_parameters(student_net)\n",
        "\n",
        "# Calculate and print the number of zero parameters for both models\n",
        "teacher_zero_params = count_zero_parameters(teacher_net)\n",
        "student_zero_params = count_zero_parameters(student_net)\n",
        "\n",
        "print(f\"Teacher Network: {teacher_total_params} total parameters, {teacher_zero_params} are zero.\")\n",
        "print(f\"Student Network: {student_total_params} total parameters, {student_zero_params} are zero.\")\n",
        "\n",
        "# Optionally, calculate the percentage of zero parameters in each model\n",
        "teacher_zero_percent = 100 * teacher_zero_params / teacher_total_params\n",
        "student_zero_percent = 100 * student_zero_params / student_total_params\n",
        "\n",
        "print(f\"Percentage of zero parameters in Teacher Network: {teacher_zero_percent:.2f}%\")\n",
        "print(f\"Percentage of zero parameters in Student Network: {student_zero_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L97WQ1QFOQkM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Classifier",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
