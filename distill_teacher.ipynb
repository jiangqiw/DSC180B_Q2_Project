{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bREGbUT_Y8F"
      },
      "source": [
        "### Import required packages and limit GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcqwxR8_Y8I",
        "outputId": "26140e84-9279-479e-cc80-7c9a0b1a8fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import csv\n",
        "\n",
        "# Import the module\n",
        "import networks\n",
        "import utils\n",
        "from quantize_neural_net import QuantizeNeuralNet\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "n73sKlgl_Y8K"
      },
      "outputs": [],
      "source": [
        "use_gpu = True    # set use_gpu to True if system has gpu\n",
        "gpu_id = 0        # id of gpu to be used\n",
        "cpu_device = torch.device('cpu')\n",
        "# fast_device is where computation (training, inference) happens\n",
        "fast_device = torch.device('cpu')\n",
        "if use_gpu:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
        "    fast_device = torch.device('cuda:' + str(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DAfPa7mw_Y8L"
      },
      "outputs": [],
      "source": [
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    if use_gpu:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "o0sxuxkJbUEI"
      },
      "outputs": [],
      "source": [
        "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
        "checkpoints_path_student_nokd = 'checkpoints_student/checkpoints_student_NoKD/'\n",
        "checkpoints_path_student_van = 'checkpoints_student/checkpoints_student_VAN/'\n",
        "checkpoints_path_student_qat = 'checkpoints_student/checkpoints_student_QAT/'\n",
        "checkpoints_path_student_dml = 'checkpoints_student/checkpoints_student_DML/'\n",
        "if not os.path.exists(checkpoints_path_teacher):\n",
        "    os.makedirs(checkpoints_path_teacher)\n",
        "if not os.path.exists(checkpoints_path_student_nokd):\n",
        "    os.makedirs(checkpoints_path_student_nokd)\n",
        "if not os.path.exists(checkpoints_path_student_van):\n",
        "    os.makedirs(checkpoints_path_student_van)\n",
        "if not os.path.exists(checkpoints_path_student_qat):\n",
        "    os.makedirs(checkpoints_path_student_qat)\n",
        "if not os.path.exists(checkpoints_path_student_dml):\n",
        "    os.makedirs(checkpoints_path_student_dml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCz4Pup_Y8M"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import PIL\n",
        "\n",
        "# Set up transformations for CIFAR-10\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        #transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
        "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "    ]\n",
        ")\n",
        "\n",
        "import torchvision as tv\n",
        "preprocess_train = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((160, 160), interpolation=PIL.Image.BILINEAR),  # It's the default, just being explicit for the reader.\n",
        "    tv.transforms.RandomCrop((128, 128)),\n",
        "    tv.transforms.RandomHorizontalFlip(),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "preprocess_eval = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((128, 128), interpolation=PIL.Image.BILINEAR),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
        "                                            download=True, transform=transform_train)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "# Split the training dataset into training and validation\n",
        "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
        "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 128\n",
        "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of trainable parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters.\n",
        "    \"\"\"\n",
        "    return sum((p.data != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def count_zero_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of trainable parameters that are exactly zero.\n",
        "    \"\"\"\n",
        "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_bit_size(model):\n",
        "    \"\"\"\n",
        "    Calculate the effective bit size of a quantized model.\n",
        "    \n",
        "    Parameters:\n",
        "        model: nn.Module\n",
        "            The quantized neural network model.\n",
        "    \n",
        "    Returns:\n",
        "        float: The average bit size across all layers.\n",
        "    \"\"\"\n",
        "    total_bits = 0\n",
        "    total_params = 0\n",
        "    \n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Calculate unique values and their count\n",
        "            unique_values = torch.unique(param.data).cpu().numpy()\n",
        "            num_unique_values = len(unique_values)\n",
        "            \n",
        "            # Calculate bit size for this layer\n",
        "            layer_bits = np.ceil(np.log2(num_unique_values)) if num_unique_values > 1 else 1\n",
        "            total_bits += layer_bits * param.numel()\n",
        "            total_params += param.numel()\n",
        "    \n",
        "    # Return average bit size across all parameters\n",
        "    return total_bits / total_params if total_params > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scalar(bits):\n",
        "    if 26<bits <=32:\n",
        "        return 3.5\n",
        "    elif 20< bits <= 26:\n",
        "        return 3\n",
        "    elif 16< bits <= 20:\n",
        "        return 2.5\n",
        "    elif 8< bits <= 16:\n",
        "        return 2\n",
        "    elif 4< bits <= 8:\n",
        "        return 1.5\n",
        "    elif 3< bits <= 4:\n",
        "        return 1.16\n",
        "    else:\n",
        "        return 0.5 # only for student 2-3 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teacher Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load pre-trained teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9225\n"
          ]
        }
      ],
      "source": [
        "import detectors\n",
        "import timm\n",
        "\n",
        "teacher_net = timm.create_model(\"resnet50_cifar10\", pretrained=True)\n",
        "\n",
        "teacher_net = teacher_net.to(fast_device)\n",
        "# pre-trained teacher accuracy\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\1025170478.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy:  0.9225\n"
          ]
        }
      ],
      "source": [
        "# another way load teacher\n",
        "teacher_net = networks.TeacherNetwork50()\n",
        "\n",
        "checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n",
        "\n",
        "teacher_net.model.load_state_dict(checkpoint)\n",
        "teacher_net.to(fast_device)\n",
        "\n",
        "reproducibilitySeed()\n",
        "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
        "print('test accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantized Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_teacher/results_teacher_quantization.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Effective Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Sparsity\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 376.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 237.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2605.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 189.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 190.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 415.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2813.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 192.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 408.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2759.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 174.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 199.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1784.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 527.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 58.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1746.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2875.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 641.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1623.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2938.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 644.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1719.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2929.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 686.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 977.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2873.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1157.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 337.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2260.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3331.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1155.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2209.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3185.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1177.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2295.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3380.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1093.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2297.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3488.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1132.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2323.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3140.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1129.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1753.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2438.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1345.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 578.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2876.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3392.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1598.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2866.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3442.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1681.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3430.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 3, Effective Quantized Bit Size: 4.012658050251773\n",
            "Bits 3, Quantized Test Accuracy: 0.9129\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 340.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 161.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2636.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 185.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 194.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 425.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2918.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 188.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 430.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2753.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 189.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 225.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2281.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 667.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:04<00:00, 60.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1686.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3116.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 678.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1694.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2970.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 658.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1677.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3402.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 677.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1053.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2927.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1136.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:01<00:00, 341.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2288.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3479.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1155.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2365.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3477.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1151.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2364.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3431.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1151.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2360.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3380.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1159.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 2336.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3549.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1190.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 1724.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3252.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1729.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:01<00:00, 657.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 2963.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3473.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1708.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3007.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3439.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1730.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 3389.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 2, Effective Quantized Bit Size: 3.0149168979579897\n",
            "Bits 2, Quantized Test Accuracy: 0.909\n",
            "Results saved to checkpoints_teacher/results_teacher_quantization.csv\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"checkpoints_teacher/results_teacher_quantization.csv\"\n",
        "range1 = range(32, 20, -6)\n",
        "range2= range(20, 8, -4) \n",
        "range3= range(8, 4, -2)\n",
        "range4= range(4, 1, -1)\n",
        "bits_list = list(range1) + list(range2) + list(range3) + list(range4)\n",
        "bits_list= range(3, 1, -1)\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        teacher_net.model,\n",
        "        'resnet50',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar= 1.16, # scalar(bits)\n",
        "        cnn_alphabet_scalar= 1.16, #scalar(bits),\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network(False)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "    sparsity = utils.eval_sparsity(quantized_model)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, effective_bit_size, 0.9225, quantized_test_accuracy, sparsity,  training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayk6sDh7UXz"
      },
      "source": [
        "## Student Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Without KD "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n",
            "0 11173962 23520842\n",
            "epoch: 0 validation accuracy: 0.110\n",
            "[1,   100/  372] train loss: 1.450 train accuracy: 0.453\n",
            "[1,   200/  372] train loss: 0.954 train accuracy: 0.703\n",
            "[1,   300/  372] train loss: 0.751 train accuracy: 0.758\n",
            "epoch: 1 validation accuracy: 0.742\n",
            "[2,   100/  372] train loss: 0.602 train accuracy: 0.773\n",
            "[2,   200/  372] train loss: 0.441 train accuracy: 0.852\n",
            "[2,   300/  372] train loss: 0.438 train accuracy: 0.852\n",
            "epoch: 2 validation accuracy: 0.826\n",
            "[3,   100/  372] train loss: 0.491 train accuracy: 0.828\n",
            "[3,   200/  372] train loss: 0.349 train accuracy: 0.883\n",
            "[3,   300/  372] train loss: 0.368 train accuracy: 0.875\n",
            "epoch: 3 validation accuracy: 0.862\n",
            "[4,   100/  372] train loss: 0.361 train accuracy: 0.898\n",
            "[4,   200/  372] train loss: 0.385 train accuracy: 0.867\n",
            "[4,   300/  372] train loss: 0.267 train accuracy: 0.891\n",
            "epoch: 4 validation accuracy: 0.864\n",
            "[5,   100/  372] train loss: 0.312 train accuracy: 0.898\n",
            "[5,   200/  372] train loss: 0.227 train accuracy: 0.922\n",
            "[5,   300/  372] train loss: 0.216 train accuracy: 0.945\n",
            "epoch: 5 validation accuracy: 0.873\n",
            "[6,   100/  372] train loss: 0.229 train accuracy: 0.930\n",
            "[6,   200/  372] train loss: 0.149 train accuracy: 0.945\n",
            "[6,   300/  372] train loss: 0.229 train accuracy: 0.930\n",
            "epoch: 6 validation accuracy: 0.881\n",
            "[7,   100/  372] train loss: 0.230 train accuracy: 0.922\n",
            "[7,   200/  372] train loss: 0.220 train accuracy: 0.922\n",
            "[7,   300/  372] train loss: 0.158 train accuracy: 0.945\n",
            "epoch: 7 validation accuracy: 0.890\n",
            "[8,   100/  372] train loss: 0.182 train accuracy: 0.930\n",
            "[8,   200/  372] train loss: 0.153 train accuracy: 0.930\n",
            "[8,   300/  372] train loss: 0.127 train accuracy: 0.961\n",
            "epoch: 8 validation accuracy: 0.893\n",
            "[9,   100/  372] train loss: 0.216 train accuracy: 0.945\n",
            "[9,   200/  372] train loss: 0.136 train accuracy: 0.945\n",
            "[9,   300/  372] train loss: 0.167 train accuracy: 0.945\n",
            "epoch: 9 validation accuracy: 0.889\n",
            "[10,   100/  372] train loss: 0.174 train accuracy: 0.922\n",
            "[10,   200/  372] train loss: 0.099 train accuracy: 0.961\n",
            "[10,   300/  372] train loss: 0.076 train accuracy: 0.977\n",
            "epoch: 10 validation accuracy: 0.893\n",
            "[11,   100/  372] train loss: 0.061 train accuracy: 0.977\n",
            "[11,   200/  372] train loss: 0.112 train accuracy: 0.977\n",
            "[11,   300/  372] train loss: 0.145 train accuracy: 0.969\n",
            "epoch: 11 validation accuracy: 0.893\n",
            "[12,   100/  372] train loss: 0.061 train accuracy: 0.984\n",
            "[12,   200/  372] train loss: 0.056 train accuracy: 0.984\n",
            "[12,   300/  372] train loss: 0.152 train accuracy: 0.945\n",
            "epoch: 12 validation accuracy: 0.894\n",
            "[13,   100/  372] train loss: 0.073 train accuracy: 0.984\n",
            "[13,   200/  372] train loss: 0.069 train accuracy: 0.977\n",
            "[13,   300/  372] train loss: 0.125 train accuracy: 0.938\n",
            "epoch: 13 validation accuracy: 0.897\n",
            "[14,   100/  372] train loss: 0.039 train accuracy: 1.000\n",
            "[14,   200/  372] train loss: 0.095 train accuracy: 0.977\n",
            "[14,   300/  372] train loss: 0.021 train accuracy: 1.000\n",
            "epoch: 14 validation accuracy: 0.888\n",
            "[15,   100/  372] train loss: 0.062 train accuracy: 0.984\n",
            "[15,   200/  372] train loss: 0.034 train accuracy: 1.000\n",
            "[15,   300/  372] train loss: 0.123 train accuracy: 0.969\n",
            "epoch: 15 validation accuracy: 0.890\n",
            "[16,   100/  372] train loss: 0.029 train accuracy: 0.992\n",
            "[16,   200/  372] train loss: 0.027 train accuracy: 1.000\n",
            "[16,   300/  372] train loss: 0.046 train accuracy: 0.977\n",
            "epoch: 16 validation accuracy: 0.889\n",
            "[17,   100/  372] train loss: 0.042 train accuracy: 0.992\n",
            "[17,   200/  372] train loss: 0.027 train accuracy: 1.000\n",
            "[17,   300/  372] train loss: 0.035 train accuracy: 0.992\n",
            "epoch: 17 validation accuracy: 0.890\n",
            "[18,   100/  372] train loss: 0.043 train accuracy: 0.992\n",
            "[18,   200/  372] train loss: 0.032 train accuracy: 1.000\n",
            "[18,   300/  372] train loss: 0.037 train accuracy: 1.000\n",
            "epoch: 18 validation accuracy: 0.894\n",
            "[19,   100/  372] train loss: 0.066 train accuracy: 0.977\n",
            "[19,   200/  372] train loss: 0.055 train accuracy: 0.992\n",
            "[19,   300/  372] train loss: 0.049 train accuracy: 0.984\n",
            "epoch: 19 validation accuracy: 0.901\n",
            "[20,   100/  372] train loss: 0.055 train accuracy: 0.984\n",
            "[20,   200/  372] train loss: 0.036 train accuracy: 1.000\n",
            "[20,   300/  372] train loss: 0.013 train accuracy: 1.000\n",
            "epoch: 20 validation accuracy: 0.898\n",
            "Checkpoint saved Epoch 20: checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth\n",
            "Test accuracy:  0.8891\n",
            "Results saved to checkpoints_student/checkpoints_student_NoKD/results_student.csv\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "print_every = 100\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [0.0] # only use label for training\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill_nokd = {}\n",
        "pruning_factor = 0\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student_nokd + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=False, fuse=False, qat=False, dif_arch=True)\n",
        "    student_net.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(student_net)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "    results_distill_nokd[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(\n",
        "            teacher_net, student_net, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=False,\n",
        "            checkpoint_save_path = checkpoints_path_student_nokd\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student_nokd + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill_nokd[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': quantized_model.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_student/checkpoints_student_nokd/results_student_quantization.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Effective Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Sparsity\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_14284\\2355955617.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth')\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth')\n",
        "student_net = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "student_net = student_net.to(fast_device)\n",
        "student_net.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "\n",
        "csv_file = \"checkpoints_student/checkpoints_student_nokd/results_student_quantization.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 253.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2422.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2139.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2112.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2172.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1704.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3005.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 316.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2640.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3167.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2429.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3195.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 859.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3000.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3172.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2977.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3095.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1139.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3133.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3160.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2984.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 32, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 32, Quantized Test Accuracy: 0.8648\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 339.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 928.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2431.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2365.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2251.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1433.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2726.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 309.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3185.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3039.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2413.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2648.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 816.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3323.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3250.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2839.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2970.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1474.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3119.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2798.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2835.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 28, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 28, Quantized Test Accuracy: 0.8839\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 295.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 877.34it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2386.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2046.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2110.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1687.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2871.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 330.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2335.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3155.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2422.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3276.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 917.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2605.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3081.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2697.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2834.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1073.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2734.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2882.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3695.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 24, Effective Quantized Bit Size: 20.223940621956654\n",
            "Bits 24, Quantized Test Accuracy: 0.8746\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 353.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1371.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2667.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2793.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2443.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1828.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3415.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 352.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3612.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3634.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2841.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3211.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 1081.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3541.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3603.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3207.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3062.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1356.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3115.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3275.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3214.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 20, Effective Quantized Bit Size: 17.898076259790393\n",
            "Bits 20, Quantized Test Accuracy: 0.8651\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 366.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 953.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2663.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2696.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2251.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1928.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3096.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 352.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3251.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3623.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2729.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3666.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 983.42it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3319.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3402.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3247.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3216.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1581.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3591.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3513.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3683.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 16, Effective Quantized Bit Size: 14.82808192832587\n",
            "Bits 16, Quantized Test Accuracy: 0.8572\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 398.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1515.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2880.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2873.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2576.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1528.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3220.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 346.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3497.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3118.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2353.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3446.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 907.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3805.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3649.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3398.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3380.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1647.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3705.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3638.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2915.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 14, Effective Quantized Bit Size: 13.354393007601065\n",
            "Bits 14, Quantized Test Accuracy: 0.8773\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 283.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 157/576 [00:00<00:01, 415.81it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Measure training time\u001b[39;00m\n\u001b[0;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 31\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_network\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Check quantized model bit size\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\quantize_neural_net.py:181\u001b[0m, in \u001b[0;36mQuantizeNeuralNet.quantize_network\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    177\u001b[0m     W \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mview(W\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# shape (out_channels, in_channesl/groups*k_size[0]*k_size[1])\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# each row of W is a neuron (vectorized sliding block)\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     Q, quantize_error, relative_quantize_error, quantize_adder, relative_adder \u001b[38;5;241m=\u001b[39m \u001b[43mStepAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                                \u001b[49m\u001b[43manalog_layer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mquantized_layer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m                                \u001b[49m\u001b[43manalog_layer_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_alphabet_step_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_boundary_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_percentile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstochastic_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantized_network_layers[layer_idx]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m Q\u001b[38;5;241m.\u001b[39mreshape(W_shape)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\step_algorithm.py:213\u001b[0m, in \u001b[0;36mStepAlgorithm._quantize_layer\u001b[1;34m(W, analog_layer_input, quantized_layer_input, m, step_size, boundary_idx, percentile, reg, lamb, groups, stochastic_quantization, device)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of groups: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m# no group convolutio\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[43mStepAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalog_layer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantized_layer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m              \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     quantize_adder \u001b[38;5;241m=\u001b[39m U\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    217\u001b[0m     relative_adder \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(quantize_adder, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m (torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(analog_layer_input \u001b[38;5;241m@\u001b[39m W\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\17598\\Downloads\\DSC180B_Q2_Project\\step_algorithm.py:144\u001b[0m, in \u001b[0;36mStepAlgorithm._quantization\u001b[1;34m(W, Q, U, analog_layer_input, quantized_layer_input, quantizer, step_size, boundary_idx, lamb)\u001b[0m\n\u001b[0;32m    142\u001b[0m norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(quantized_layer_input[:, t], \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     q_arg \u001b[38;5;241m=\u001b[39m \u001b[43mU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_layer_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m norm\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m    146\u001b[0m     q_arg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(U[:, \u001b[38;5;241m0\u001b[39m])\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create two range objects\n",
        "range1 = range(32, 16,-4)\n",
        "range2= range(16, 8, -2)\n",
        "range3= range(8, 0, -1)\n",
        "bits_list = list(range1) + list(range2) + list(range3)\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        student_net.model,\n",
        "        'resnet18',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=3.5,\n",
        "        cnn_alphabet_scalar=3.5,\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network(False)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    sparsity = utils.eval_sparsity(quantized_model)\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits,effective_bit_size, 0.8891, quantized_test_accuracy,sparsity, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hparamsT=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.001, lr_decay=0.95, momentum=0.9, weight_decay=0.0 and pruning factor 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 11173962 23520842\n",
            "epoch: 0 validation accuracy: 0.110\n",
            "[1,   100/  372] train loss: 5.777 train accuracy: 0.680\n",
            "[1,   200/  372] train loss: 3.589 train accuracy: 0.797\n",
            "[1,   300/  372] train loss: 2.916 train accuracy: 0.836\n",
            "epoch: 1 validation accuracy: 0.858\n",
            "[2,   100/  372] train loss: 1.893 train accuracy: 0.906\n",
            "[2,   200/  372] train loss: 1.805 train accuracy: 0.953\n",
            "[2,   300/  372] train loss: 1.338 train accuracy: 0.930\n",
            "epoch: 2 validation accuracy: 0.888\n",
            "[3,   100/  372] train loss: 1.538 train accuracy: 0.922\n",
            "[3,   200/  372] train loss: 1.118 train accuracy: 0.930\n",
            "[3,   300/  372] train loss: 1.191 train accuracy: 0.953\n",
            "epoch: 3 validation accuracy: 0.901\n",
            "[4,   100/  372] train loss: 1.134 train accuracy: 0.938\n",
            "[4,   200/  372] train loss: 1.383 train accuracy: 0.938\n",
            "[4,   300/  372] train loss: 0.837 train accuracy: 0.953\n",
            "epoch: 4 validation accuracy: 0.907\n",
            "[5,   100/  372] train loss: 0.899 train accuracy: 0.953\n",
            "[5,   200/  372] train loss: 0.848 train accuracy: 0.977\n",
            "[5,   300/  372] train loss: 0.939 train accuracy: 0.977\n",
            "epoch: 5 validation accuracy: 0.913\n",
            "[6,   100/  372] train loss: 0.723 train accuracy: 0.961\n",
            "[6,   200/  372] train loss: 0.649 train accuracy: 0.969\n",
            "[6,   300/  372] train loss: 0.942 train accuracy: 0.906\n",
            "epoch: 6 validation accuracy: 0.913\n",
            "[7,   100/  372] train loss: 0.838 train accuracy: 0.938\n",
            "[7,   200/  372] train loss: 0.711 train accuracy: 0.977\n",
            "[7,   300/  372] train loss: 0.526 train accuracy: 0.977\n",
            "epoch: 7 validation accuracy: 0.910\n",
            "[8,   100/  372] train loss: 0.614 train accuracy: 0.977\n",
            "[8,   200/  372] train loss: 0.495 train accuracy: 0.961\n",
            "[8,   300/  372] train loss: 0.501 train accuracy: 0.984\n",
            "epoch: 8 validation accuracy: 0.914\n",
            "[9,   100/  372] train loss: 0.716 train accuracy: 0.969\n",
            "[9,   200/  372] train loss: 0.581 train accuracy: 0.992\n",
            "[9,   300/  372] train loss: 0.667 train accuracy: 0.969\n",
            "epoch: 9 validation accuracy: 0.915\n",
            "[10,   100/  372] train loss: 0.491 train accuracy: 0.977\n",
            "[10,   200/  372] train loss: 0.463 train accuracy: 0.992\n",
            "[10,   300/  372] train loss: 0.399 train accuracy: 1.000\n",
            "epoch: 10 validation accuracy: 0.918\n",
            "[11,   100/  372] train loss: 0.376 train accuracy: 0.977\n",
            "[11,   200/  372] train loss: 0.467 train accuracy: 0.977\n",
            "[11,   300/  372] train loss: 0.424 train accuracy: 0.977\n",
            "epoch: 11 validation accuracy: 0.916\n",
            "[12,   100/  372] train loss: 0.385 train accuracy: 0.992\n",
            "[12,   200/  372] train loss: 0.358 train accuracy: 1.000\n",
            "[12,   300/  372] train loss: 0.636 train accuracy: 0.977\n",
            "epoch: 12 validation accuracy: 0.916\n",
            "[13,   100/  372] train loss: 0.394 train accuracy: 0.969\n",
            "[13,   200/  372] train loss: 0.454 train accuracy: 0.969\n",
            "[13,   300/  372] train loss: 0.384 train accuracy: 0.984\n",
            "epoch: 13 validation accuracy: 0.916\n",
            "[14,   100/  372] train loss: 0.389 train accuracy: 0.977\n",
            "[14,   200/  372] train loss: 0.268 train accuracy: 0.984\n",
            "[14,   300/  372] train loss: 0.333 train accuracy: 0.992\n",
            "epoch: 14 validation accuracy: 0.915\n",
            "[15,   100/  372] train loss: 0.305 train accuracy: 0.984\n",
            "[15,   200/  372] train loss: 0.368 train accuracy: 0.992\n",
            "[15,   300/  372] train loss: 0.410 train accuracy: 0.984\n",
            "epoch: 15 validation accuracy: 0.918\n",
            "[16,   100/  372] train loss: 0.358 train accuracy: 0.977\n",
            "[16,   200/  372] train loss: 0.308 train accuracy: 0.977\n",
            "[16,   300/  372] train loss: 0.328 train accuracy: 0.992\n",
            "epoch: 16 validation accuracy: 0.918\n",
            "[17,   100/  372] train loss: 0.326 train accuracy: 0.984\n",
            "[17,   200/  372] train loss: 0.304 train accuracy: 0.977\n",
            "[17,   300/  372] train loss: 0.347 train accuracy: 0.992\n",
            "epoch: 17 validation accuracy: 0.919\n",
            "[18,   100/  372] train loss: 0.355 train accuracy: 0.992\n",
            "[18,   200/  372] train loss: 0.341 train accuracy: 0.984\n",
            "[18,   300/  372] train loss: 0.448 train accuracy: 0.969\n",
            "epoch: 18 validation accuracy: 0.919\n",
            "[19,   100/  372] train loss: 0.359 train accuracy: 0.969\n",
            "[19,   200/  372] train loss: 0.300 train accuracy: 0.984\n",
            "[19,   300/  372] train loss: 0.390 train accuracy: 0.977\n",
            "epoch: 19 validation accuracy: 0.922\n",
            "[20,   100/  372] train loss: 0.409 train accuracy: 1.000\n",
            "[20,   200/  372] train loss: 0.376 train accuracy: 1.000\n",
            "[20,   300/  372] train loss: 0.324 train accuracy: 1.000\n",
            "epoch: 20 validation accuracy: 0.919\n",
            "Checkpoint saved Epoch 20: checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth\n",
            "Test accuracy:  0.9152\n",
            "Results saved to checkpoints_student/checkpoints_student_VAN/results_student.csv\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "print_every = 100\n",
        "\n",
        "# Hypothetical setup, please adjust according to actual import paths and methods\n",
        "temperatures = [4]\n",
        "alphas = [1.0]\n",
        "learning_rates = [1e-3]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [0.0]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0.0, 0.0)]\n",
        "hparams_list = []\n",
        "\n",
        "\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "\n",
        "results_distill_van = {}\n",
        "pruning_factor = 0\n",
        "\n",
        "# CSV file setup\n",
        "csv_file = checkpoints_path_student_van + \"results_student.csv\"\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Alpha\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\", \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\", \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"])\n",
        "\n",
        "# Training and logging\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + utils.hparamToString(hparam) + f' and pruning factor {pruning_factor}')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    reproducibilitySeed()\n",
        "    student_net = networks.StudentNetwork(pruning_factor, teacher_net, q=False, fuse=False, qat=False, dif_arch=True)\n",
        "    student_net.to(fast_device)\n",
        "    hparam_tuple = utils.hparamDictToTuple(hparam)\n",
        "\n",
        "    # Count parameters\n",
        "    student_params_num = count_parameters(student_net)\n",
        "    \n",
        "    print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
        "\n",
        "    results_distill_van[(hparam_tuple, pruning_factor)] = utils.trainStudentOnHparam(\n",
        "            teacher_net, student_net, hparam, num_epochs,\n",
        "            train_loader, val_loader,\n",
        "            print_every=print_every,\n",
        "            fast_device=fast_device, quant=False,\n",
        "            checkpoint_save_path = checkpoints_path_student_van\n",
        "        )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final model save\n",
        "    final_save_path = checkpoints_path_student_van + utils.hparamToString(hparam) + '.tar'\n",
        "    torch.save({\n",
        "        'results': results_distill_van[(hparam_tuple, pruning_factor)],\n",
        "        'model_state_dict': student_net.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }, final_save_path)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
        "    print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            hparam['alpha'], hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'], hparam['weight_decay'],\n",
        "            hparam['lr_decay'], hparam['momentum'], hparam['lr'], pruning_factor, student_params_num,\n",
        "            test_accuracy, training_time\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\4284167774.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth')\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.9152)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth')\n",
        "student_net = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "student_net = student_net.to(fast_device)\n",
        "student_net.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 468.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.36030864471104e-05.\n",
            "The relative quantization error of layer 0 is 6.605812785664966e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2863.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 2.864307680283673e-05.\n",
            "The relative quantization error of layer 1 is 5.615928699853612e-08.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2645.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.0018663207301869988.\n",
            "The relative quantization error of layer 2 is 7.389583061012672e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2349.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.008297314867377281.\n",
            "The relative quantization error of layer 3 is 1.575097667227965e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2146.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.01427796296775341.\n",
            "The relative quantization error of layer 4 is 7.784031186020002e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1635.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.07713501155376434.\n",
            "The relative quantization error of layer 5 is 0.00011128201003884897.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2348.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.017091138288378716.\n",
            "The relative quantization error of layer 6 is 0.00010836483852472156.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 289.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 0.06724771112203598.\n",
            "The relative quantization error of layer 7 is 8.59245119499974e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3011.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 0.03573352470993996.\n",
            "The relative quantization error of layer 8 is 0.00015179328329395503.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2007.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 0.3910129964351654.\n",
            "The relative quantization error of layer 9 is 0.004108721856027842.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1693.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 1.1218458414077759.\n",
            "The relative quantization error of layer 10 is 0.0029467481654137373.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2801.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 0.2774665355682373.\n",
            "The relative quantization error of layer 11 is 0.00226909713819623.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 639.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 1.1822123527526855.\n",
            "The relative quantization error of layer 12 is 0.005076434463262558.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2944.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 0.2831265330314636.\n",
            "The relative quantization error of layer 13 is 0.0015700763324275613.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3247.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.25704264640808105.\n",
            "The relative quantization error of layer 14 is 0.0043380726128816605.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2925.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 1.8196834325790405.\n",
            "The relative quantization error of layer 15 is 0.0073904008604586124.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3264.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.26572462916374207.\n",
            "The relative quantization error of layer 16 is 0.004299271386116743.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1478.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 4.5316643714904785.\n",
            "The relative quantization error of layer 17 is 0.027248134836554527.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2961.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 2.9444611072540283.\n",
            "The relative quantization error of layer 18 is 0.01611419953405857.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2896.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.576486825942993.\n",
            "The relative quantization error of layer 19 is 0.07378851622343063.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3291.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 20.869115829467773.\n",
            "The relative quantization error of layer 20 is 0.1517668515443802.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 32, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 32, Quantized Test Accuracy: 0.9077\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 386.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.510650119802449e-05.\n",
            "The relative quantization error of layer 0 is 7.142136126958576e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1599.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 3.1875162676442415e-05.\n",
            "The relative quantization error of layer 1 is 6.238116867507415e-08.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2691.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.0023221371229737997.\n",
            "The relative quantization error of layer 2 is 9.217949809681159e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2587.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.008370032534003258.\n",
            "The relative quantization error of layer 3 is 1.577568764332682e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2364.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.013959144242107868.\n",
            "The relative quantization error of layer 4 is 7.637334056198597e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1679.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.07520314306020737.\n",
            "The relative quantization error of layer 5 is 0.0001093394384952262.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2855.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.017280880361795425.\n",
            "The relative quantization error of layer 6 is 0.00010739310528151691.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 347.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 1.654805302619934.\n",
            "The relative quantization error of layer 7 is 0.0021192256826907396.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3263.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 0.24487829208374023.\n",
            "The relative quantization error of layer 8 is 0.0010277826804667711.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3138.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 0.20870441198349.\n",
            "The relative quantization error of layer 9 is 0.0022163712419569492.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2585.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 0.7008858323097229.\n",
            "The relative quantization error of layer 10 is 0.0018530241213738918.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3289.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 0.15397131443023682.\n",
            "The relative quantization error of layer 11 is 0.0012669701827690005.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 885.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 0.7141439914703369.\n",
            "The relative quantization error of layer 12 is 0.003066528122872114.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2983.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 0.1693495213985443.\n",
            "The relative quantization error of layer 13 is 0.0009701083181425929.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2915.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.08247531950473785.\n",
            "The relative quantization error of layer 14 is 0.0013870905386283994.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2945.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 0.4419059753417969.\n",
            "The relative quantization error of layer 15 is 0.001810988294892013.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2724.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.07231494039297104.\n",
            "The relative quantization error of layer 16 is 0.001170000177808106.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1062.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 3.404083490371704.\n",
            "The relative quantization error of layer 17 is 0.020578565075993538.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2658.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 2.2283501625061035.\n",
            "The relative quantization error of layer 18 is 0.012283334508538246.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:02<00:00, 2254.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.4780850410461426.\n",
            "The relative quantization error of layer 19 is 0.06991027295589447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 1937.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 18.315767288208008.\n",
            "The relative quantization error of layer 20 is 0.13194690644741058.\n",
            "\n",
            "Bits 26, Effective Quantized Bit Size: 20.487868492840768\n",
            "Bits 26, Quantized Test Accuracy: 0.9077\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 352.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.00038985462742857635.\n",
            "The relative quantization error of layer 0 is 1.1130387065350078e-06.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2799.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.0006373797077685595.\n",
            "The relative quantization error of layer 1 is 1.2470223964555771e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2850.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.007059975061565638.\n",
            "The relative quantization error of layer 2 is 2.7682017389452085e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2708.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.03110429085791111.\n",
            "The relative quantization error of layer 3 is 5.91895732213743e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2448.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.03084140457212925.\n",
            "The relative quantization error of layer 4 is 0.00016925815725699067.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1973.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.13884326815605164.\n",
            "The relative quantization error of layer 5 is 0.0002011173201026395.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3177.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.02474050037562847.\n",
            "The relative quantization error of layer 6 is 0.00015650168643333018.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 342.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 21.268274307250977.\n",
            "The relative quantization error of layer 7 is 0.027239497750997543.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3068.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 3.473527431488037.\n",
            "The relative quantization error of layer 8 is 0.014517538249492645.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3273.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 2.4825737476348877.\n",
            "The relative quantization error of layer 9 is 0.02617497555911541.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2433.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 8.485986709594727.\n",
            "The relative quantization error of layer 10 is 0.022657575085759163.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3146.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 1.8516674041748047.\n",
            "The relative quantization error of layer 11 is 0.015218243934214115.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 846.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 8.650568962097168.\n",
            "The relative quantization error of layer 12 is 0.03723304718732834.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3066.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 1.9689115285873413.\n",
            "The relative quantization error of layer 13 is 0.011260324157774448.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3172.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.9665667414665222.\n",
            "The relative quantization error of layer 14 is 0.016051309183239937.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2742.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 3.9064273834228516.\n",
            "The relative quantization error of layer 15 is 0.016074908897280693.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3128.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.6073002815246582.\n",
            "The relative quantization error of layer 16 is 0.009635881520807743.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1402.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 8.903268814086914.\n",
            "The relative quantization error of layer 17 is 0.05387834459543228.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3208.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 3.7123188972473145.\n",
            "The relative quantization error of layer 18 is 0.02032514475286007.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3097.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.7783260345458984.\n",
            "The relative quantization error of layer 19 is 0.08140332251787186.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3072.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 21.944419860839844.\n",
            "The relative quantization error of layer 20 is 0.15984410047531128.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 20, Effective Quantized Bit Size: 18.267575279028154\n",
            "Bits 20, Quantized Test Accuracy: 0.9043\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 352.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.005111537408083677.\n",
            "The relative quantization error of layer 0 is 1.5037662706163246e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1073.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.08350162953138351.\n",
            "The relative quantization error of layer 1 is 0.00016411887190770358.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2708.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.19526876509189606.\n",
            "The relative quantization error of layer 2 is 0.0007682752911932766.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2692.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.6603153944015503.\n",
            "The relative quantization error of layer 3 is 0.0012569476384669542.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2553.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.31439661979675293.\n",
            "The relative quantization error of layer 4 is 0.0017184874741360545.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1775.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.7898777723312378.\n",
            "The relative quantization error of layer 5 is 0.0011384824756532907.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3067.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.12790459394454956.\n",
            "The relative quantization error of layer 6 is 0.000800012843683362.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 347.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 40.73300552368164.\n",
            "The relative quantization error of layer 7 is 0.05229352042078972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3232.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 6.815683364868164.\n",
            "The relative quantization error of layer 8 is 0.028628258034586906.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3194.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 2.832270383834839.\n",
            "The relative quantization error of layer 9 is 0.029669491574168205.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2280.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 12.33023738861084.\n",
            "The relative quantization error of layer 10 is 0.032719727605581284.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2726.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 2.219709873199463.\n",
            "The relative quantization error of layer 11 is 0.018339361995458603.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 745.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.526009559631348.\n",
            "The relative quantization error of layer 12 is 0.05379394069314003.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2083.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 2.42484188079834.\n",
            "The relative quantization error of layer 13 is 0.013645613566040993.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2339.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 1.2309632301330566.\n",
            "The relative quantization error of layer 14 is 0.02116083912551403.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2079.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 5.597582817077637.\n",
            "The relative quantization error of layer 15 is 0.022825364023447037.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2486.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.8120697736740112.\n",
            "The relative quantization error of layer 16 is 0.013208535499870777.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1821.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 12.532596588134766.\n",
            "The relative quantization error of layer 17 is 0.07512877136468887.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2949.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 5.179078102111816.\n",
            "The relative quantization error of layer 18 is 0.028661813586950302.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2925.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.1343295574188232.\n",
            "The relative quantization error of layer 19 is 0.08820817619562149.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2984.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 24.578527450561523.\n",
            "The relative quantization error of layer 20 is 0.17717735469341278.\n",
            "\n",
            "Bits 16, Effective Quantized Bit Size: 15.57551099601019\n",
            "Bits 16, Quantized Test Accuracy: 0.9026\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 325.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.08316044509410858.\n",
            "The relative quantization error of layer 0 is 0.00023359069018624723.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 914.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.15455986559391022.\n",
            "The relative quantization error of layer 1 is 0.00030271903960965574.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2114.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.23636572062969208.\n",
            "The relative quantization error of layer 2 is 0.0009314347989857197.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2288.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.7346803545951843.\n",
            "The relative quantization error of layer 3 is 0.0013932643923908472.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2364.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.34344786405563354.\n",
            "The relative quantization error of layer 4 is 0.0018673305166885257.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1818.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 1.0086207389831543.\n",
            "The relative quantization error of layer 5 is 0.001477147568948567.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2895.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.17497780919075012.\n",
            "The relative quantization error of layer 6 is 0.001099943183362484.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 296.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 40.97596740722656.\n",
            "The relative quantization error of layer 7 is 0.052592016756534576.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2562.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 7.0949249267578125.\n",
            "The relative quantization error of layer 8 is 0.029837096109986305.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1858.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 3.10638165473938.\n",
            "The relative quantization error of layer 9 is 0.03242683783173561.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 1745.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 12.755586624145508.\n",
            "The relative quantization error of layer 10 is 0.03397800400853157.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2881.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 2.3169424533843994.\n",
            "The relative quantization error of layer 11 is 0.019110174849629402.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 787.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 12.858644485473633.\n",
            "The relative quantization error of layer 12 is 0.05539127066731453.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2282.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 2.6681058406829834.\n",
            "The relative quantization error of layer 13 is 0.015126652084290981.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2407.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 1.2815895080566406.\n",
            "The relative quantization error of layer 14 is 0.021497521549463272.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2567.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 5.775449752807617.\n",
            "The relative quantization error of layer 15 is 0.023810921236872673.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2360.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.8893428444862366.\n",
            "The relative quantization error of layer 16 is 0.014211148954927921.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1597.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 12.95311450958252.\n",
            "The relative quantization error of layer 17 is 0.07812675833702087.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3354.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 4.897251605987549.\n",
            "The relative quantization error of layer 18 is 0.02688286267220974.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3007.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.2507944107055664.\n",
            "The relative quantization error of layer 19 is 0.08868188410997391.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2908.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 26.43056297302246.\n",
            "The relative quantization error of layer 20 is 0.19489270448684692.\n",
            "\n",
            "Bits 12, Effective Quantized Bit Size: 12.144265391273033\n",
            "Bits 12, Quantized Test Accuracy: 0.9021\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 354.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 1.6957980394363403.\n",
            "The relative quantization error of layer 0 is 0.004974424839019775.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 990.93it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 3.7627859115600586.\n",
            "The relative quantization error of layer 1 is 0.007369927130639553.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1864.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 3.028160333633423.\n",
            "The relative quantization error of layer 2 is 0.011920551769435406.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1602.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 11.575591087341309.\n",
            "The relative quantization error of layer 3 is 0.021892433986067772.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2147.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 5.559032917022705.\n",
            "The relative quantization error of layer 4 is 0.030082030221819878.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1483.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 14.491621017456055.\n",
            "The relative quantization error of layer 5 is 0.020925600081682205.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2701.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 2.800699472427368.\n",
            "The relative quantization error of layer 6 is 0.017805658280849457.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 326.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 68.39308166503906.\n",
            "The relative quantization error of layer 7 is 0.0878351554274559.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3029.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 10.935529708862305.\n",
            "The relative quantization error of layer 8 is 0.04576161503791809.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2989.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 4.594747066497803.\n",
            "The relative quantization error of layer 9 is 0.04884791746735573.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2249.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 20.367515563964844.\n",
            "The relative quantization error of layer 10 is 0.053942736238241196.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2473.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 4.10217809677124.\n",
            "The relative quantization error of layer 11 is 0.0337643027305603.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 711.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 20.513347625732422.\n",
            "The relative quantization error of layer 12 is 0.08817160874605179.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2783.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 4.553573131561279.\n",
            "The relative quantization error of layer 13 is 0.02591133862733841.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2509.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.3849778175354004.\n",
            "The relative quantization error of layer 14 is 0.03941047191619873.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2641.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 10.520792961120605.\n",
            "The relative quantization error of layer 15 is 0.04301517456769943.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2528.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.5580731630325317.\n",
            "The relative quantization error of layer 16 is 0.025309620425105095.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 851.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 22.65961456298828.\n",
            "The relative quantization error of layer 17 is 0.13666889071464539.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2521.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.418839931488037.\n",
            "The relative quantization error of layer 18 is 0.035100214183330536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2667.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8145570755004883.\n",
            "The relative quantization error of layer 19 is 0.10899676382541656.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2635.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 32.068084716796875.\n",
            "The relative quantization error of layer 20 is 0.23370645940303802.\n",
            "\n",
            "Bits 8, Effective Quantized Bit Size: 8.633652414425608\n",
            "Bits 8, Quantized Test Accuracy: 0.8896\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 409.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 4.173623085021973.\n",
            "The relative quantization error of layer 0 is 0.011807788163423538.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2788.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.038405895233154.\n",
            "The relative quantization error of layer 1 is 0.013770471327006817.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2635.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 6.343954563140869.\n",
            "The relative quantization error of layer 2 is 0.02501145750284195.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2631.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 15.749892234802246.\n",
            "The relative quantization error of layer 3 is 0.0298826452344656.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2299.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 7.763983249664307.\n",
            "The relative quantization error of layer 4 is 0.04251343384385109.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1748.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 26.787782669067383.\n",
            "The relative quantization error of layer 5 is 0.03879544138908386.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2841.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 5.494165420532227.\n",
            "The relative quantization error of layer 6 is 0.03427610546350479.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 361.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 74.30039978027344.\n",
            "The relative quantization error of layer 7 is 0.09521587193012238.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3021.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 13.504745483398438.\n",
            "The relative quantization error of layer 8 is 0.05695110559463501.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2935.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 6.421019077301025.\n",
            "The relative quantization error of layer 9 is 0.06675368547439575.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2257.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 25.43597412109375.\n",
            "The relative quantization error of layer 10 is 0.06726601719856262.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2979.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 5.019538879394531.\n",
            "The relative quantization error of layer 11 is 0.04136580973863602.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 770.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 26.294021606445312.\n",
            "The relative quantization error of layer 12 is 0.1131100207567215.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2984.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 6.096246719360352.\n",
            "The relative quantization error of layer 13 is 0.03396002575755119.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3168.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 2.8269007205963135.\n",
            "The relative quantization error of layer 14 is 0.04805105924606323.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2935.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 11.606557846069336.\n",
            "The relative quantization error of layer 15 is 0.04746337607502937.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2805.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.6916977167129517.\n",
            "The relative quantization error of layer 16 is 0.02749895304441452.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1476.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 25.4346923828125.\n",
            "The relative quantization error of layer 17 is 0.15189436078071594.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3045.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 6.542300224304199.\n",
            "The relative quantization error of layer 18 is 0.03522324562072754.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3155.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.8516011238098145.\n",
            "The relative quantization error of layer 19 is 0.11020226031541824.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3333.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 28.770797729492188.\n",
            "The relative quantization error of layer 20 is 0.21060839295387268.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 6, Effective Quantized Bit Size: 6.970047687650987\n",
            "Bits 6, Quantized Test Accuracy: 0.8889\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 323.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 12.613716125488281.\n",
            "The relative quantization error of layer 0 is 0.03586762771010399.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 975.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 21.841196060180664.\n",
            "The relative quantization error of layer 1 is 0.04292134940624237.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2550.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 19.15380859375.\n",
            "The relative quantization error of layer 2 is 0.07561244815587997.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2568.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 41.889713287353516.\n",
            "The relative quantization error of layer 3 is 0.07918142527341843.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2266.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 21.066287994384766.\n",
            "The relative quantization error of layer 4 is 0.11511281132698059.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1753.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 75.92147827148438.\n",
            "The relative quantization error of layer 5 is 0.10871194303035736.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3103.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 16.00674819946289.\n",
            "The relative quantization error of layer 6 is 0.09893001616001129.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 357.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 138.79835510253906.\n",
            "The relative quantization error of layer 7 is 0.17782823741436005.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3237.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 29.51850700378418.\n",
            "The relative quantization error of layer 8 is 0.12414858490228653.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3195.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 14.760207176208496.\n",
            "The relative quantization error of layer 9 is 0.1551770120859146.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2450.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 50.30558395385742.\n",
            "The relative quantization error of layer 10 is 0.13351565599441528.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3182.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 10.917845726013184.\n",
            "The relative quantization error of layer 11 is 0.09114833921194077.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 932.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 52.53106689453125.\n",
            "The relative quantization error of layer 12 is 0.22566021978855133.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2842.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 12.942109107971191.\n",
            "The relative quantization error of layer 13 is 0.07308231294155121.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3012.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 5.942807674407959.\n",
            "The relative quantization error of layer 14 is 0.09883397072553635.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2891.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 22.676332473754883.\n",
            "The relative quantization error of layer 15 is 0.0933929979801178.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3027.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 3.606963872909546.\n",
            "The relative quantization error of layer 16 is 0.05891253799200058.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1458.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 50.28490447998047.\n",
            "The relative quantization error of layer 17 is 0.3085641860961914.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2950.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 9.688961029052734.\n",
            "The relative quantization error of layer 18 is 0.053016990423202515.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3188.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.714892864227295.\n",
            "The relative quantization error of layer 19 is 0.1341092437505722.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3328.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 47.739898681640625.\n",
            "The relative quantization error of layer 20 is 0.35376426577568054.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 4, Effective Quantized Bit Size: 5.002805629730976\n",
            "Bits 4, Quantized Test Accuracy: 0.8429\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 425.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 70.40301513671875.\n",
            "The relative quantization error of layer 0 is 0.19996210932731628.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 975.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 52.480125427246094.\n",
            "The relative quantization error of layer 1 is 0.10314023494720459.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2557.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 42.26392364501953.\n",
            "The relative quantization error of layer 2 is 0.16648802161216736.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2500.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 84.62139129638672.\n",
            "The relative quantization error of layer 3 is 0.15995052456855774.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2307.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 42.187923431396484.\n",
            "The relative quantization error of layer 4 is 0.22962534427642822.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1885.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 160.69677734375.\n",
            "The relative quantization error of layer 5 is 0.23759859800338745.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3005.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 26.051761627197266.\n",
            "The relative quantization error of layer 6 is 0.1640135496854782.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 354.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 272.9278259277344.\n",
            "The relative quantization error of layer 7 is 0.34920454025268555.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3100.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 46.667457580566406.\n",
            "The relative quantization error of layer 8 is 0.19760586321353912.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3032.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 22.51421546936035.\n",
            "The relative quantization error of layer 9 is 0.23585309088230133.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2401.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 79.72732543945312.\n",
            "The relative quantization error of layer 10 is 0.21237467229366302.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3297.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 16.214279174804688.\n",
            "The relative quantization error of layer 11 is 0.13168741762638092.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 918.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 78.3974380493164.\n",
            "The relative quantization error of layer 12 is 0.3386556804180145.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3059.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 19.160293579101562.\n",
            "The relative quantization error of layer 13 is 0.10811004042625427.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2949.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 8.825282096862793.\n",
            "The relative quantization error of layer 14 is 0.14691655337810516.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2888.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 32.441558837890625.\n",
            "The relative quantization error of layer 15 is 0.13158808648586273.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2821.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 4.9526448249816895.\n",
            "The relative quantization error of layer 16 is 0.07748710364103317.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1317.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 66.84712219238281.\n",
            "The relative quantization error of layer 17 is 0.40843838453292847.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3117.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.102926254272461.\n",
            "The relative quantization error of layer 18 is 0.06687898188829422.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3183.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.582021713256836.\n",
            "The relative quantization error of layer 19 is 0.1608550250530243.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3072.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 59.158287048339844.\n",
            "The relative quantization error of layer 20 is 0.42750343680381775.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 3, Effective Quantized Bit Size: 4.003665664873391\n",
            "Bits 3, Quantized Test Accuracy: 0.8127\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 444.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 73.20574951171875.\n",
            "The relative quantization error of layer 0 is 0.2060285061597824.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2665.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 59.507259368896484.\n",
            "The relative quantization error of layer 1 is 0.11679545789957047.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2727.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 51.26262664794922.\n",
            "The relative quantization error of layer 2 is 0.2026539295911789.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2674.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 101.92119598388672.\n",
            "The relative quantization error of layer 3 is 0.19194194674491882.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2509.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 49.80514907836914.\n",
            "The relative quantization error of layer 4 is 0.27189868688583374.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1763.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 196.62130737304688.\n",
            "The relative quantization error of layer 5 is 0.2835323214530945.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3015.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 33.86567687988281.\n",
            "The relative quantization error of layer 6 is 0.21493594348430634.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 351.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 307.122802734375.\n",
            "The relative quantization error of layer 7 is 0.394155889749527.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3132.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 59.689476013183594.\n",
            "The relative quantization error of layer 8 is 0.24986152350902557.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3081.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 28.07240104675293.\n",
            "The relative quantization error of layer 9 is 0.2972509264945984.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2321.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 94.70299530029297.\n",
            "The relative quantization error of layer 10 is 0.25190868973731995.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3107.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 19.89813232421875.\n",
            "The relative quantization error of layer 11 is 0.16315492987632751.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 877.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 94.70796966552734.\n",
            "The relative quantization error of layer 12 is 0.4089720547199249.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3385.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 23.654861450195312.\n",
            "The relative quantization error of layer 13 is 0.13515181839466095.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3293.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 10.579644203186035.\n",
            "The relative quantization error of layer 14 is 0.180562824010849.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2761.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 38.38973617553711.\n",
            "The relative quantization error of layer 15 is 0.1559300422668457.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2988.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 6.241330146789551.\n",
            "The relative quantization error of layer 16 is 0.1018688753247261.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1279.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 82.4849624633789.\n",
            "The relative quantization error of layer 17 is 0.4878849983215332.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3212.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 13.976707458496094.\n",
            "The relative quantization error of layer 18 is 0.07759706676006317.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3268.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 6.478562355041504.\n",
            "The relative quantization error of layer 19 is 0.1831011027097702.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3370.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 71.95699310302734.\n",
            "The relative quantization error of layer 20 is 0.5261967182159424.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 2, Effective Quantized Bit Size: 3.0045257000158045\n",
            "Bits 2, Quantized Test Accuracy: 0.7187\n",
            "Results saved to checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\n"
          ]
        }
      ],
      "source": [
        "range1 = range(32, 20, -6)\n",
        "range2= range(20, 8, -4) \n",
        "range3= range(8, 4, -2)\n",
        "range4= range(4, 1, -1)\n",
        "bits_list = list(range1) + list(range2) + list(range3) + list(range4)\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        student_net.model,\n",
        "        'resnet18',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=scalar(bits),\n",
        "        cnn_alphabet_scalar=scalar(bits),\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, 0.9152, quantized_test_accuracy, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        " # Initialize CSV file for logging accuracies\n",
        "csv_file = os.path.join(checkpoints_path_student_dml, \"results_student.csv\")\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Epoch', 'Student ID', 'Valid Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainDML(student_models, beta, num_epochs, train_loader, valid_loader, optimizers, csv_file, fast_device=torch.device('cuda:0')):\n",
        "    for student in student_models:\n",
        "        student.to(fast_device).train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for data, labels in train_loader:\n",
        "            data, labels = data.to(fast_device), labels.to(fast_device)\n",
        "\n",
        "            # Zero the parameter gradients for all optimizers\n",
        "            for optimizer in optimizers:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            outputs = [student(data) for student in student_models]\n",
        "            losses = []\n",
        "\n",
        "            for i, student_output in enumerate(outputs):\n",
        "                loss = criterion(student_output, labels)\n",
        "                dml_loss = sum(F.mse_loss(F.softmax(student_output, dim=1), F.softmax(other_output, dim=1))\n",
        "                               for j, other_output in enumerate(outputs) if i != j)\n",
        "                total_loss = loss + beta * (dml_loss / (len(student_models) - 1))\n",
        "                losses.append(total_loss)\n",
        "\n",
        "            for i, loss in enumerate(losses):\n",
        "                loss.backward(retain_graph=True if i < len(student_models) - 1 else False)\n",
        "\n",
        "            for optimizer in optimizers:\n",
        "                optimizer.step()\n",
        "\n",
        "        # Evaluate and log the test accuracy after each epoch\n",
        "        with open(csv_file, mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            for idx, student in enumerate(student_models):\n",
        "                _, test_accuracy = utils.getLossAccuracyOnDataset(student, valid_loader, fast_device)\n",
        "                writer.writerow([epoch, idx, test_accuracy])\n",
        "                print(f'Student {idx} test accuracy at epoch {epoch}: {test_accuracy}')\n",
        "                \n",
        "                # Save checkpoints\n",
        "                torch.save(student.state_dict(), f\"{checkpoints_path_student_dml}student_{idx}_epoch_{epoch}.pth\")\n",
        "                print(f\"Checkpoint saved for Student {idx} at Epoch {epoch + 1}: {checkpoints_path_student_dml}student_{idx}_epoch_{epoch}.pth\")\n",
        "\n",
        "    print(\"Training completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\3866286448.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth')\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.8891)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_NoKD/student_epoch_19.pth')\n",
        "student_net = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "student_net = student_net.to(fast_device)\n",
        "student_net.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student 0 test accuracy at epoch 0: 0.8896\n",
            "Checkpoint saved for Student 0 at Epoch 1: checkpoints_student/checkpoints_student_DML/student_0_epoch_0.pth\n",
            "Student 1 test accuracy at epoch 0: 0.674\n",
            "Checkpoint saved for Student 1 at Epoch 1: checkpoints_student/checkpoints_student_DML/student_1_epoch_0.pth\n",
            "Student 0 test accuracy at epoch 1: 0.8904\n",
            "Checkpoint saved for Student 0 at Epoch 2: checkpoints_student/checkpoints_student_DML/student_0_epoch_1.pth\n",
            "Student 1 test accuracy at epoch 1: 0.7796\n",
            "Checkpoint saved for Student 1 at Epoch 2: checkpoints_student/checkpoints_student_DML/student_1_epoch_1.pth\n",
            "Student 0 test accuracy at epoch 2: 0.896\n",
            "Checkpoint saved for Student 0 at Epoch 3: checkpoints_student/checkpoints_student_DML/student_0_epoch_2.pth\n",
            "Student 1 test accuracy at epoch 2: 0.8128\n",
            "Checkpoint saved for Student 1 at Epoch 3: checkpoints_student/checkpoints_student_DML/student_1_epoch_2.pth\n",
            "Student 0 test accuracy at epoch 3: 0.8988\n",
            "Checkpoint saved for Student 0 at Epoch 4: checkpoints_student/checkpoints_student_DML/student_0_epoch_3.pth\n",
            "Student 1 test accuracy at epoch 3: 0.832\n",
            "Checkpoint saved for Student 1 at Epoch 4: checkpoints_student/checkpoints_student_DML/student_1_epoch_3.pth\n",
            "Student 0 test accuracy at epoch 4: 0.8936\n",
            "Checkpoint saved for Student 0 at Epoch 5: checkpoints_student/checkpoints_student_DML/student_0_epoch_4.pth\n",
            "Student 1 test accuracy at epoch 4: 0.8444\n",
            "Checkpoint saved for Student 1 at Epoch 5: checkpoints_student/checkpoints_student_DML/student_1_epoch_4.pth\n",
            "Student 0 test accuracy at epoch 5: 0.8972\n",
            "Checkpoint saved for Student 0 at Epoch 6: checkpoints_student/checkpoints_student_DML/student_0_epoch_5.pth\n",
            "Student 1 test accuracy at epoch 5: 0.8532\n",
            "Checkpoint saved for Student 1 at Epoch 6: checkpoints_student/checkpoints_student_DML/student_1_epoch_5.pth\n",
            "Student 0 test accuracy at epoch 6: 0.892\n",
            "Checkpoint saved for Student 0 at Epoch 7: checkpoints_student/checkpoints_student_DML/student_0_epoch_6.pth\n",
            "Student 1 test accuracy at epoch 6: 0.8612\n",
            "Checkpoint saved for Student 1 at Epoch 7: checkpoints_student/checkpoints_student_DML/student_1_epoch_6.pth\n",
            "Student 0 test accuracy at epoch 7: 0.894\n",
            "Checkpoint saved for Student 0 at Epoch 8: checkpoints_student/checkpoints_student_DML/student_0_epoch_7.pth\n",
            "Student 1 test accuracy at epoch 7: 0.8536\n",
            "Checkpoint saved for Student 1 at Epoch 8: checkpoints_student/checkpoints_student_DML/student_1_epoch_7.pth\n",
            "Student 0 test accuracy at epoch 8: 0.8984\n",
            "Checkpoint saved for Student 0 at Epoch 9: checkpoints_student/checkpoints_student_DML/student_0_epoch_8.pth\n",
            "Student 1 test accuracy at epoch 8: 0.8628\n",
            "Checkpoint saved for Student 1 at Epoch 9: checkpoints_student/checkpoints_student_DML/student_1_epoch_8.pth\n",
            "Student 0 test accuracy at epoch 9: 0.898\n",
            "Checkpoint saved for Student 0 at Epoch 10: checkpoints_student/checkpoints_student_DML/student_0_epoch_9.pth\n",
            "Student 1 test accuracy at epoch 9: 0.8676\n",
            "Checkpoint saved for Student 1 at Epoch 10: checkpoints_student/checkpoints_student_DML/student_1_epoch_9.pth\n",
            "Student 0 test accuracy at epoch 10: 0.8944\n",
            "Checkpoint saved for Student 0 at Epoch 11: checkpoints_student/checkpoints_student_DML/student_0_epoch_10.pth\n",
            "Student 1 test accuracy at epoch 10: 0.8676\n",
            "Checkpoint saved for Student 1 at Epoch 11: checkpoints_student/checkpoints_student_DML/student_1_epoch_10.pth\n",
            "Student 0 test accuracy at epoch 11: 0.8956\n",
            "Checkpoint saved for Student 0 at Epoch 12: checkpoints_student/checkpoints_student_DML/student_0_epoch_11.pth\n",
            "Student 1 test accuracy at epoch 11: 0.8564\n",
            "Checkpoint saved for Student 1 at Epoch 12: checkpoints_student/checkpoints_student_DML/student_1_epoch_11.pth\n",
            "Student 0 test accuracy at epoch 12: 0.8924\n",
            "Checkpoint saved for Student 0 at Epoch 13: checkpoints_student/checkpoints_student_DML/student_0_epoch_12.pth\n",
            "Student 1 test accuracy at epoch 12: 0.8624\n",
            "Checkpoint saved for Student 1 at Epoch 13: checkpoints_student/checkpoints_student_DML/student_1_epoch_12.pth\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[120], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m student_models \u001b[38;5;241m=\u001b[39m [student_net,  networks\u001b[38;5;241m.\u001b[39mStudentNetwork(pruning_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, teacher_net \u001b[38;5;241m=\u001b[39m teacher_net, q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, qat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dif_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]  \u001b[38;5;66;03m# Create multiple instances for DML\u001b[39;00m\n\u001b[0;32m      3\u001b[0m optimizers \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(student\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m student \u001b[38;5;129;01min\u001b[39;00m student_models]\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrainDML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_device\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[118], line 9\u001b[0m, in \u001b[0;36mtrainDML\u001b[1;34m(student_models, beta, num_epochs, train_loader, valid_loader, optimizers, csv_file, fast_device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m----> 9\u001b[0m         data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfast_device\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(fast_device)\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Zero the parameter gradients for all optimizers\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m optimizers:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create multiple student models and their optimizers\n",
        "student_models = [student_net,  networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=True, fuse=True, qat=True, dif_arch=True)]  # Create multiple instances for DML\n",
        "optimizers = [torch.optim.SGD(student.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0) for student in student_models]\n",
        "\n",
        "trainDML(student_models, 3, 20, train_loader, val_loader, optimizers, csv_file, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\2877924804.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_0_epoch_5.pth')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.8921)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_0_epoch_5.pth')\n",
        "student_net_0 = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "student_net_0 = student_net_0.to(fast_device)\n",
        "student_net_0.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net_0, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_9552\\1917126078.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_1_epoch_5.pth')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.9179)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_1_epoch_5.pth')\n",
        "student_net_1 = networks.StudentNetwork(pruning_factor=0.0, teacher_net = teacher_net, q=True, fuse=True, qat=True, dif_arch=True)\n",
        "student_net_1 = student_net_1.to(fast_device)\n",
        "student_net_1.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net_1, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student 0 test accuracy at epoch 0: 0.9248\n",
            "Checkpoint saved for Student 0 at Epoch 1: checkpoints_student/checkpoints_student_DML/student_0_epoch_0.pth\n",
            "Student 1 test accuracy at epoch 0: 0.9148\n",
            "Checkpoint saved for Student 1 at Epoch 1: checkpoints_student/checkpoints_student_DML/student_1_epoch_0.pth\n",
            "Student 0 test accuracy at epoch 1: 0.9304\n",
            "Checkpoint saved for Student 0 at Epoch 2: checkpoints_student/checkpoints_student_DML/student_0_epoch_1.pth\n",
            "Student 1 test accuracy at epoch 1: 0.9184\n",
            "Checkpoint saved for Student 1 at Epoch 2: checkpoints_student/checkpoints_student_DML/student_1_epoch_1.pth\n",
            "Student 0 test accuracy at epoch 2: 0.9312\n",
            "Checkpoint saved for Student 0 at Epoch 3: checkpoints_student/checkpoints_student_DML/student_0_epoch_2.pth\n",
            "Student 1 test accuracy at epoch 2: 0.918\n",
            "Checkpoint saved for Student 1 at Epoch 3: checkpoints_student/checkpoints_student_DML/student_1_epoch_2.pth\n",
            "Student 0 test accuracy at epoch 3: 0.9292\n",
            "Checkpoint saved for Student 0 at Epoch 4: checkpoints_student/checkpoints_student_DML/student_0_epoch_3.pth\n",
            "Student 1 test accuracy at epoch 3: 0.9156\n",
            "Checkpoint saved for Student 1 at Epoch 4: checkpoints_student/checkpoints_student_DML/student_1_epoch_3.pth\n",
            "Student 0 test accuracy at epoch 4: 0.9312\n",
            "Checkpoint saved for Student 0 at Epoch 5: checkpoints_student/checkpoints_student_DML/student_0_epoch_4.pth\n",
            "Student 1 test accuracy at epoch 4: 0.9204\n",
            "Checkpoint saved for Student 1 at Epoch 5: checkpoints_student/checkpoints_student_DML/student_1_epoch_4.pth\n",
            "Student 0 test accuracy at epoch 5: 0.9312\n",
            "Checkpoint saved for Student 0 at Epoch 6: checkpoints_student/checkpoints_student_DML/student_0_epoch_5.pth\n",
            "Student 1 test accuracy at epoch 5: 0.9184\n",
            "Checkpoint saved for Student 1 at Epoch 6: checkpoints_student/checkpoints_student_DML/student_1_epoch_5.pth\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m student_models \u001b[38;5;241m=\u001b[39m [student_net_0,  student_net_1]  \u001b[38;5;66;03m# Create multiple instances for DML\u001b[39;00m\n\u001b[0;32m      4\u001b[0m optimizers \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(student\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m student \u001b[38;5;129;01min\u001b[39;00m student_models]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrainDML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_device\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mtrainDML\u001b[1;34m(student_models, beta, num_epochs, train_loader, valid_loader, optimizers, csv_file, fast_device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m----> 9\u001b[0m         data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfast_device\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(fast_device)\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Zero the parameter gradients for all optimizers\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m optimizers:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "csv_file = os.path.join(checkpoints_path_student_dml, \"results_student.csv\")\n",
        "# Create multiple student models and their optimizers\n",
        "student_models = [student_net_0,  student_net_1]  # Create multiple instances for DML\n",
        "optimizers = [torch.optim.SGD(student.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0) for student in student_models]\n",
        "\n",
        "trainDML(student_models, 1, 20, train_loader, val_loader, optimizers, csv_file, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\307282889.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_0_epoch_15.pth')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.932)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check accuracy\n",
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_DML/student_0_epoch_15.pth')\n",
        "student_net = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "student_net = student_net.to(fast_device)\n",
        "student_net.load_state_dict(checkpoint)\n",
        "reproducibilitySeed()\n",
        "utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantization CSV file setup\n",
        "csv_file = \"checkpoints_student/checkpoints_student_DML/results_student_quantization_dml.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Bits\", \"Original Test Accuracy\", \"Quantized Test Accuracy\", \"Training Time (s)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 356.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.5961731807910837e-05.\n",
            "The relative quantization error of layer 0 is 6.826341092391885e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1060.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 3.022010605491232e-05.\n",
            "The relative quantization error of layer 1 is 5.239535738610357e-08.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2532.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.0016854492714628577.\n",
            "The relative quantization error of layer 2 is 5.9176677495997865e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2681.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.00751094426959753.\n",
            "The relative quantization error of layer 3 is 1.3312585906533059e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2273.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.010368836112320423.\n",
            "The relative quantization error of layer 4 is 4.9573111027712e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1655.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.05934187397360802.\n",
            "The relative quantization error of layer 5 is 7.137924694688991e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3022.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.012956040911376476.\n",
            "The relative quantization error of layer 6 is 7.720431312918663e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 335.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 0.053271062672138214.\n",
            "The relative quantization error of layer 7 is 6.180103082442656e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3014.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 0.028736354783177376.\n",
            "The relative quantization error of layer 8 is 0.0001043242882587947.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3015.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 0.01760047674179077.\n",
            "The relative quantization error of layer 9 is 0.0001779414596967399.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2272.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 0.05553148686885834.\n",
            "The relative quantization error of layer 10 is 0.00013485600356943905.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2944.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 0.012543623335659504.\n",
            "The relative quantization error of layer 11 is 0.0001003699580905959.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 842.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 0.05475609377026558.\n",
            "The relative quantization error of layer 12 is 0.00021484452008735389.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3225.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 0.017629677429795265.\n",
            "The relative quantization error of layer 13 is 8.484136196784675e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3032.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.008382296189665794.\n",
            "The relative quantization error of layer 14 is 0.00013557561032939702.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2751.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 0.5445865988731384.\n",
            "The relative quantization error of layer 15 is 0.002150686690583825.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3003.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.06601599603891373.\n",
            "The relative quantization error of layer 16 is 0.0010595270432531834.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1184.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 1.8943402767181396.\n",
            "The relative quantization error of layer 17 is 0.011672270484268665.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3252.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 1.4373588562011719.\n",
            "The relative quantization error of layer 18 is 0.008058312349021435.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3131.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 1.7550082206726074.\n",
            "The relative quantization error of layer 19 is 0.04771282523870468.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2949.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 18.28910255432129.\n",
            "The relative quantization error of layer 20 is 0.07383731752634048.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 32, Effective Quantized Bit Size: 21.121295382962643\n",
            "Bits 32, Quantized Test Accuracy: 0.9284\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 555.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 2.6659834475140087e-05.\n",
            "The relative quantization error of layer 0 is 7.118794087546121e-08.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1397.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 3.328434468130581e-05.\n",
            "The relative quantization error of layer 1 is 5.7662390418045106e-08.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2648.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.0020617914851754904.\n",
            "The relative quantization error of layer 2 is 7.136368822102668e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2474.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.008497330360114574.\n",
            "The relative quantization error of layer 3 is 1.5012510630185716e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2188.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.012941616587340832.\n",
            "The relative quantization error of layer 4 is 6.242183735594153e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1708.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.07049694657325745.\n",
            "The relative quantization error of layer 5 is 8.602760499343276e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2889.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.014315229840576649.\n",
            "The relative quantization error of layer 6 is 8.665808127261698e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 330.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 0.060763485729694366.\n",
            "The relative quantization error of layer 7 is 7.037355680949986e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3021.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 0.030177898705005646.\n",
            "The relative quantization error of layer 8 is 0.00010796781134558842.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3056.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 0.019035078585147858.\n",
            "The relative quantization error of layer 9 is 0.0001939007343025878.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2292.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 0.06069120392203331.\n",
            "The relative quantization error of layer 10 is 0.0001472004660172388.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2962.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 0.0134701794013381.\n",
            "The relative quantization error of layer 11 is 0.00010667976312106475.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 803.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 0.05861179158091545.\n",
            "The relative quantization error of layer 12 is 0.00023126254382077605.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3041.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 0.01869336888194084.\n",
            "The relative quantization error of layer 13 is 9.092335676541552e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2925.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.008326838724315166.\n",
            "The relative quantization error of layer 14 is 0.00013434317952487618.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2841.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 0.2680113613605499.\n",
            "The relative quantization error of layer 15 is 0.0010937226470559835.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2974.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.032255619764328.\n",
            "The relative quantization error of layer 16 is 0.0005202938336879015.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1219.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 2.0628886222839355.\n",
            "The relative quantization error of layer 17 is 0.012651896104216576.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3115.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 0.6944388747215271.\n",
            "The relative quantization error of layer 18 is 0.003939356189221144.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2939.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 1.1837997436523438.\n",
            "The relative quantization error of layer 19 is 0.03289519622921944.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3344.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 13.18617057800293.\n",
            "The relative quantization error of layer 20 is 0.052665725350379944.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 26, Effective Quantized Bit Size: 20.487868492840768\n",
            "Bits 26, Quantized Test Accuracy: 0.9292\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 483.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.0004959653015248477.\n",
            "The relative quantization error of layer 0 is 1.3155222404748201e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1110.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.0006507626967504621.\n",
            "The relative quantization error of layer 1 is 1.1286144854238955e-06.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2676.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.006651402451097965.\n",
            "The relative quantization error of layer 2 is 2.334870441700332e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2572.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.027963267639279366.\n",
            "The relative quantization error of layer 3 is 4.9435522669227794e-05.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2224.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.027793636545538902.\n",
            "The relative quantization error of layer 4 is 0.00013385209604166448.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1688.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 0.12710325419902802.\n",
            "The relative quantization error of layer 5 is 0.00015311023162212223.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2730.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.02062736451625824.\n",
            "The relative quantization error of layer 6 is 0.00012570114631671458.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 346.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 18.488977432250977.\n",
            "The relative quantization error of layer 7 is 0.021366752684116364.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3166.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 2.3163695335388184.\n",
            "The relative quantization error of layer 8 is 0.008251507766544819.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3252.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 0.7095233798027039.\n",
            "The relative quantization error of layer 9 is 0.00715220533311367.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2304.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 3.499669075012207.\n",
            "The relative quantization error of layer 10 is 0.00852525420486927.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2933.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 0.5072000622749329.\n",
            "The relative quantization error of layer 11 is 0.004061990417540073.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 842.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 3.7747409343719482.\n",
            "The relative quantization error of layer 12 is 0.014981954358518124.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2953.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 0.6214805841445923.\n",
            "The relative quantization error of layer 13 is 0.0030056198593229055.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2752.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.2721419632434845.\n",
            "The relative quantization error of layer 14 is 0.00440977094694972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2592.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 1.1385554075241089.\n",
            "The relative quantization error of layer 15 is 0.004515879787504673.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2414.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.15675018727779388.\n",
            "The relative quantization error of layer 16 is 0.002531781792640686.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1596.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 3.56687068939209.\n",
            "The relative quantization error of layer 17 is 0.021952686831355095.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3282.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 1.6639398336410522.\n",
            "The relative quantization error of layer 18 is 0.00930609367787838.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2836.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.285001277923584.\n",
            "The relative quantization error of layer 19 is 0.0620943084359169.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3191.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 20.655994415283203.\n",
            "The relative quantization error of layer 20 is 0.08343135565519333.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 20, Effective Quantized Bit Size: 18.056432982320864\n",
            "Bits 20, Quantized Test Accuracy: 0.9304\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 442.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.44438937306404114.\n",
            "The relative quantization error of layer 0 is 0.0011545568704605103.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2634.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.1983085423707962.\n",
            "The relative quantization error of layer 1 is 0.00034427695209160447.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2713.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.3042297661304474.\n",
            "The relative quantization error of layer 2 is 0.0010584065457805991.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2790.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.9123740196228027.\n",
            "The relative quantization error of layer 3 is 0.0016207387670874596.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2414.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.49927759170532227.\n",
            "The relative quantization error of layer 4 is 0.002418471034616232.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1972.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 1.1328685283660889.\n",
            "The relative quantization error of layer 5 is 0.0013627228327095509.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2923.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.17393355071544647.\n",
            "The relative quantization error of layer 6 is 0.0010337292915210128.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 349.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 38.47970199584961.\n",
            "The relative quantization error of layer 7 is 0.044518984854221344.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3151.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 5.011014461517334.\n",
            "The relative quantization error of layer 8 is 0.018183425068855286.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3149.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 2.9691739082336426.\n",
            "The relative quantization error of layer 9 is 0.03011303022503853.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2277.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 9.725991249084473.\n",
            "The relative quantization error of layer 10 is 0.023685293272137642.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3162.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 1.6812002658843994.\n",
            "The relative quantization error of layer 11 is 0.013411195017397404.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 790.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 10.407402038574219."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The relative quantization error of layer 12 is 0.040958479046821594.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3154.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 2.0395023822784424.\n",
            "The relative quantization error of layer 13 is 0.009578447788953781.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2989.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.7869080305099487.\n",
            "The relative quantization error of layer 14 is 0.012604775838553905.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2915.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 3.2933554649353027.\n",
            "The relative quantization error of layer 15 is 0.013012844137847424.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3082.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.4605238735675812.\n",
            "The relative quantization error of layer 16 is 0.007358701433986425.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1465.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 7.825771808624268.\n",
            "The relative quantization error of layer 17 is 0.04843312129378319.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3014.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 2.9001388549804688.\n",
            "The relative quantization error of layer 18 is 0.01619771681725979.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2785.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.9652934074401855.\n",
            "The relative quantization error of layer 19 is 0.08027269691228867.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2969.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 29.254106521606445.\n",
            "The relative quantization error of layer 20 is 0.11983039230108261.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 16, Effective Quantized Bit Size: 15.364368699302897\n",
            "Bits 16, Quantized Test Accuracy: 0.9252\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 714.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 0.4464960992336273.\n",
            "The relative quantization error of layer 0 is 0.0012087615905329585.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2825.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 0.2548283636569977.\n",
            "The relative quantization error of layer 1 is 0.0004414221039041877.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2758.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 0.34373995661735535.\n",
            "The relative quantization error of layer 2 is 0.0011980797862634063.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2676.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 0.9317211508750916.\n",
            "The relative quantization error of layer 3 is 0.0016665165312588215.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2424.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 0.5086522102355957.\n",
            "The relative quantization error of layer 4 is 0.0024578378070145845.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1922.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 1.2875802516937256.\n",
            "The relative quantization error of layer 5 is 0.0015565167414024472.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2997.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 0.19578532874584198.\n",
            "The relative quantization error of layer 6 is 0.0011802191147580743.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 359.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 38.37436294555664.\n",
            "The relative quantization error of layer 7 is 0.04442625865340233.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3178.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 5.064080238342285.\n",
            "The relative quantization error of layer 8 is 0.018276188522577286.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3312.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 1.954179048538208.\n",
            "The relative quantization error of layer 9 is 0.01982155814766884.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2420.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 8.204779624938965.\n",
            "The relative quantization error of layer 10 is 0.01991882734000683.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3233.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 1.2752972841262817.\n",
            "The relative quantization error of layer 11 is 0.010461105033755302.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 918.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 8.658368110656738.\n",
            "The relative quantization error of layer 12 is 0.03423430398106575.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3449.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 1.5775655508041382.\n",
            "The relative quantization error of layer 13 is 0.007576454430818558.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3214.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 0.6410874128341675.\n",
            "The relative quantization error of layer 14 is 0.010389902628958225.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2822.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 2.616032838821411.\n",
            "The relative quantization error of layer 15 is 0.010612045414745808.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3134.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.38216689229011536.\n",
            "The relative quantization error of layer 16 is 0.006039055995643139.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1244.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 6.627705097198486.\n",
            "The relative quantization error of layer 17 is 0.04123320430517197.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3201.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 2.588073253631592.\n",
            "The relative quantization error of layer 18 is 0.014488507993519306.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2799.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 2.8512885570526123.\n",
            "The relative quantization error of layer 19 is 0.07588191330432892.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3306.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 27.2978458404541.\n",
            "The relative quantization error of layer 20 is 0.11223923414945602.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 12, Effective Quantized Bit Size: 11.933123094565742\n",
            "Bits 12, Quantized Test Accuracy: 0.9267\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 463.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 3.686344623565674.\n",
            "The relative quantization error of layer 0 is 0.010044405236840248.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2605.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 3.9838180541992188.\n",
            "The relative quantization error of layer 1 is 0.006907482631504536.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2652.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 3.8411705493927.\n",
            "The relative quantization error of layer 2 is 0.013419639319181442.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2757.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 13.668428421020508.\n",
            "The relative quantization error of layer 3 is 0.024524301290512085.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2622.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 6.826650619506836.\n",
            "The relative quantization error of layer 4 is 0.03271850198507309.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1912.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 17.038469314575195.\n",
            "The relative quantization error of layer 5 is 0.020529335364699364.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2963.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 2.69581937789917.\n",
            "The relative quantization error of layer 6 is 0.016365839168429375.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 349.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 68.29747009277344.\n",
            "The relative quantization error of layer 7 is 0.07927010953426361.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3174.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 8.914325714111328.\n",
            "The relative quantization error of layer 8 is 0.03233432024717331.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2747.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 3.652799606323242.\n",
            "The relative quantization error of layer 9 is 0.03722376003861427.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2178.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 14.518305778503418.\n",
            "The relative quantization error of layer 10 is 0.035141754895448685.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2811.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 2.5052549839019775.\n",
            "The relative quantization error of layer 11 is 0.020086267963051796.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 622.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 16.091453552246094.\n",
            "The relative quantization error of layer 12 is 0.06315295398235321.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3114.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 3.1316890716552734.\n",
            "The relative quantization error of layer 13 is 0.015102933160960674.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2310.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 1.2123547792434692.\n",
            "The relative quantization error of layer 14 is 0.01968461461365223.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2272.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 5.555966854095459.\n",
            "The relative quantization error of layer 15 is 0.022279120981693268.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2854.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 0.8072737455368042.\n",
            "The relative quantization error of layer 16 is 0.012962320819497108.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1020.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 12.868639945983887.\n",
            "The relative quantization error of layer 17 is 0.07895798981189728.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2528.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 3.4861841201782227.\n",
            "The relative quantization error of layer 18 is 0.01959722302854061.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2789.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.020310163497925.\n",
            "The relative quantization error of layer 19 is 0.08398544788360596.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 2656.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 30.226964950561523.\n",
            "The relative quantization error of layer 20 is 0.12202753126621246.\n",
            "\n",
            "Bits 8, Effective Quantized Bit Size: 8.686437988602432\n",
            "Bits 8, Quantized Test Accuracy: 0.9254\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 476.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 5.897257328033447.\n",
            "The relative quantization error of layer 0 is 0.016232309862971306.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1411.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 7.35365629196167.\n",
            "The relative quantization error of layer 1 is 0.012760957702994347.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2776.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 6.5312347412109375.\n",
            "The relative quantization error of layer 2 is 0.022928349673748016.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2312.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 16.977375030517578.\n",
            "The relative quantization error of layer 3 is 0.030248355120420456.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1886.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 8.609811782836914.\n",
            "The relative quantization error of layer 4 is 0.04110286757349968.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1586.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 26.65410041809082.\n",
            "The relative quantization error of layer 5 is 0.032596997916698456.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2210.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 4.997616291046143.\n",
            "The relative quantization error of layer 6 is 0.030476108193397522.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 264.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 74.24287414550781.\n",
            "The relative quantization error of layer 7 is 0.08617378026247025.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2552.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 11.533541679382324.\n",
            "The relative quantization error of layer 8 is 0.04202381893992424.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2958.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 5.0489654541015625.\n",
            "The relative quantization error of layer 9 is 0.0506051667034626.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2086.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 18.943655014038086.\n",
            "The relative quantization error of layer 10 is 0.04601754993200302.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2683.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 3.6435699462890625.\n",
            "The relative quantization error of layer 11 is 0.029488559812307358.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 709.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 20.235395431518555.\n",
            "The relative quantization error of layer 12 is 0.07974746078252792.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:01<00:00, 2236.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 4.698964595794678.\n",
            "The relative quantization error of layer 13 is 0.022401079535484314.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2634.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 1.8206071853637695.\n",
            "The relative quantization error of layer 14 is 0.02932620421051979.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2787.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 7.207253456115723.\n",
            "The relative quantization error of layer 15 is 0.029126876965165138.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2711.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 1.1371257305145264.\n",
            "The relative quantization error of layer 16 is 0.01816282793879509.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 797.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 16.268747329711914.\n",
            "The relative quantization error of layer 17 is 0.10076847672462463.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2768.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 4.3302226066589355.\n",
            "The relative quantization error of layer 18 is 0.023991750553250313.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2802.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 3.3714447021484375.\n",
            "The relative quantization error of layer 19 is 0.08994480967521667.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3050.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 31.21817398071289.\n",
            "The relative quantization error of layer 20 is 0.12740379571914673.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 6, Effective Quantized Bit Size: 6.967481722239614\n",
            "Bits 6, Quantized Test Accuracy: 0.9248\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 382.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 18.47545051574707.\n",
            "The relative quantization error of layer 0 is 0.048838842660188675.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2995.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 23.026023864746094.\n",
            "The relative quantization error of layer 1 is 0.04006272926926613.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2627.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 19.42939567565918.\n",
            "The relative quantization error of layer 2 is 0.06824056059122086.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2741.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 45.05657196044922.\n",
            "The relative quantization error of layer 3 is 0.08019042015075684.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2185.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 22.701129913330078.\n",
            "The relative quantization error of layer 4 is 0.10890142619609833.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1756.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 76.75072479248047.\n",
            "The relative quantization error of layer 5 is 0.0935564935207367.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3186.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 14.892617225646973.\n",
            "The relative quantization error of layer 6 is 0.09121297299861908.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 350.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 141.18319702148438.\n",
            "The relative quantization error of layer 7 is 0.16339965164661407.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2915.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 27.955625534057617.\n",
            "The relative quantization error of layer 8 is 0.10149335861206055.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3074.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 12.631895065307617.\n",
            "The relative quantization error of layer 9 is 0.12962336838245392.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2368.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 43.04023361206055.\n",
            "The relative quantization error of layer 10 is 0.10469922423362732.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3234.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 9.325861930847168.\n",
            "The relative quantization error of layer 11 is 0.0729619711637497.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 900.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 45.222755432128906.\n",
            "The relative quantization error of layer 12 is 0.17832018435001373.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3514.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 12.260607719421387.\n",
            "The relative quantization error of layer 13 is 0.057465117424726486.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3260.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 4.610085487365723.\n",
            "The relative quantization error of layer 14 is 0.07480430603027344.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3011.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 17.841325759887695.\n",
            "The relative quantization error of layer 15 is 0.0715019479393959.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2945.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 2.849418878555298.\n",
            "The relative quantization error of layer 16 is 0.04637613147497177.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1384.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 40.1536750793457.\n",
            "The relative quantization error of layer 17 is 0.250205934047699.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3270.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 7.71934700012207.\n",
            "The relative quantization error of layer 18 is 0.04404381290078163.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2995.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 4.773775100708008.\n",
            "The relative quantization error of layer 19 is 0.1306423395872116.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3445.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 55.74491500854492.\n",
            "The relative quantization error of layer 20 is 0.2254711538553238.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 4, Effective Quantized Bit Size: 5.002805629730976\n",
            "Bits 4, Quantized Test Accuracy: 0.9049\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 349.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 82.71757507324219.\n",
            "The relative quantization error of layer 0 is 0.2227785587310791.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2636.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 60.755035400390625.\n",
            "The relative quantization error of layer 1 is 0.10579866170883179.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2520.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 47.91820526123047.\n",
            "The relative quantization error of layer 2 is 0.16822214424610138.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2611.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 95.45404815673828.\n",
            "The relative quantization error of layer 3 is 0.1699160784482956.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2351.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 51.10428237915039.\n",
            "The relative quantization error of layer 4 is 0.24550610780715942.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1893.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 177.019287109375.\n",
            "The relative quantization error of layer 5 is 0.212926983833313.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2913.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 26.365646362304688.\n",
            "The relative quantization error of layer 6 is 0.15808965265750885.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 337.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 289.0783996582031.\n",
            "The relative quantization error of layer 7 is 0.33593320846557617.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3230.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 47.456600189208984.\n",
            "The relative quantization error of layer 8 is 0.17267747223377228.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3389.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 20.552412033081055.\n",
            "The relative quantization error of layer 9 is 0.20605748891830444.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2589.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 77.8936538696289.\n",
            "The relative quantization error of layer 10 is 0.1891334056854248.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3484.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 15.106338500976562.\n",
            "The relative quantization error of layer 11 is 0.1197718158364296.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 1004.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 77.7275619506836.\n",
            "The relative quantization error of layer 12 is 0.30638477206230164.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3401.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 20.1449031829834.\n",
            "The relative quantization error of layer 13 is 0.09636538475751877.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3277.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 7.502277851104736.\n",
            "The relative quantization error of layer 14 is 0.12187064439058304.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 2942.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 28.236675262451172.\n",
            "The relative quantization error of layer 15 is 0.11454498022794724.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3025.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 4.242550849914551.\n",
            "The relative quantization error of layer 16 is 0.06858718395233154.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1093.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 61.31575393676758.\n",
            "The relative quantization error of layer 17 is 0.3766123950481415.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 3241.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 10.340404510498047.\n",
            "The relative quantization error of layer 18 is 0.05858737975358963.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2780.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 5.994527816772461.\n",
            "The relative quantization error of layer 19 is 0.1609760820865631.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3239.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 94.85945892333984.\n",
            "The relative quantization error of layer 20 is 0.38892054557800293.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 3, Effective Quantized Bit Size: 4.003665664873391\n",
            "Bits 3, Quantized Test Accuracy: 0.8736\n",
            "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Total number of layers to quantize 21\n",
            "\n",
            "Quantizing layer with index: 0\n",
            "Quantization progress: 0 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 3, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 27])\n",
            "shape of quantized_layer_input: torch.Size([3968, 27])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 452.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 0 is 86.72093200683594.\n",
            "The relative quantization error of layer 0 is 0.23548245429992676.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 1\n",
            "Quantization progress: 1 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2782.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 1 is 66.54373168945312.\n",
            "The relative quantization error of layer 1 is 0.115626260638237.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 2\n",
            "Quantization progress: 2 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2671.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 2 is 54.20298767089844.\n",
            "The relative quantization error of layer 2 is 0.1885504424571991.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 3\n",
            "Quantization progress: 3 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2759.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 3 is 106.88013458251953.\n",
            "The relative quantization error of layer 3 is 0.19117246568202972.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 4\n",
            "Quantization progress: 4 out of 20\n",
            "\n",
            "shape of W: torch.Size([64, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 2396.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 4 is 56.30119323730469.\n",
            "The relative quantization error of layer 4 is 0.26778972148895264.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 5\n",
            "Quantization progress: 5 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([3968, 576])\n",
            "shape of quantized_layer_input: torch.Size([3968, 576])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 576/576 [00:00<00:00, 1910.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 5 is 197.4095001220703.\n",
            "The relative quantization error of layer 5 is 0.23839519917964935.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 6\n",
            "Quantization progress: 6 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2690.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 6 is 33.29951858520508.\n",
            "The relative quantization error of layer 6 is 0.19835327565670013.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 7\n",
            "Quantization progress: 7 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 64, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([32896, 64])\n",
            "shape of quantized_layer_input: torch.Size([32896, 64])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:00<00:00, 351.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 7 is 317.9324035644531.\n",
            "The relative quantization error of layer 7 is 0.36717110872268677.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 8\n",
            "Quantization progress: 8 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3278.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 8 is 59.943153381347656.\n",
            "The relative quantization error of layer 8 is 0.21676860749721527.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 9\n",
            "Quantization progress: 9 out of 20\n",
            "\n",
            "shape of W: torch.Size([128, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 3271.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 9 is 25.34235954284668.\n",
            "The relative quantization error of layer 9 is 0.2568444311618805.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 10\n",
            "Quantization progress: 10 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([1280, 1152])\n",
            "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1152/1152 [00:00<00:00, 2473.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 10 is 91.8590316772461.\n",
            "The relative quantization error of layer 10 is 0.22527597844600677.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 11\n",
            "Quantization progress: 11 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3346.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 11 is 18.679807662963867.\n",
            "The relative quantization error of layer 11 is 0.15038543939590454.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 12\n",
            "Quantization progress: 12 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 128, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([8320, 128])\n",
            "shape of quantized_layer_input: torch.Size([8320, 128])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:00<00:00, 943.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 12 is 92.08834838867188.\n",
            "The relative quantization error of layer 12 is 0.36416691541671753.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantizing layer with index: 13\n",
            "Quantization progress: 13 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3504.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 13 is 24.43253517150879.\n",
            "The relative quantization error of layer 13 is 0.11758832633495331.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 14\n",
            "Quantization progress: 14 out of 20\n",
            "\n",
            "shape of W: torch.Size([256, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3269.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 14 is 9.191985130310059.\n",
            "The relative quantization error of layer 14 is 0.14828574657440186.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 15\n",
            "Quantization progress: 15 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([384, 2304])\n",
            "shape of quantized_layer_input: torch.Size([384, 2304])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2304/2304 [00:00<00:00, 3034.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 15 is 34.69237518310547.\n",
            "The relative quantization error of layer 15 is 0.13934902846813202.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 16\n",
            "Quantization progress: 16 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2854.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 16 is 5.289008617401123.\n",
            "The relative quantization error of layer 16 is 0.08563324809074402.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 17\n",
            "Quantization progress: 17 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 256, 1, 1])\n",
            "shape of analog_layer_input: torch.Size([2176, 256])\n",
            "shape of quantized_layer_input: torch.Size([2176, 256])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:00<00:00, 1419.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 17 is 75.35169219970703.\n",
            "The relative quantization error of layer 17 is 0.4637473225593567.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 18\n",
            "Quantization progress: 18 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2526.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 18 is 12.73023509979248.\n",
            "The relative quantization error of layer 18 is 0.07170610874891281.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 19\n",
            "Quantization progress: 19 out of 20\n",
            "\n",
            "shape of W: torch.Size([512, 512, 3, 3])\n",
            "shape of analog_layer_input: torch.Size([256, 4608])\n",
            "shape of quantized_layer_input: torch.Size([256, 4608])\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4608/4608 [00:01<00:00, 2813.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 19 is 6.626831531524658.\n",
            "The relative quantization error of layer 19 is 0.18418580293655396.\n",
            "\n",
            "\n",
            "Quantizing layer with index: 20\n",
            "Quantization progress: 20 out of 20\n",
            "\n",
            "The number of groups: 1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 512/512 [00:00<00:00, 3246.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The quantization error of layer 20 is 129.2133331298828.\n",
            "The relative quantization error of layer 20 is 0.525170624256134.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bits 2, Effective Quantized Bit Size: 3.0045257000158045\n",
            "Bits 2, Quantized Test Accuracy: 0.8176\n",
            "Results saved to checkpoints_student/checkpoints_student_DML/results_student_quantization_dml.csv\n"
          ]
        }
      ],
      "source": [
        "range1 = range(32, 20, -6)\n",
        "range2= range(20, 8, -4) \n",
        "range3= range(8, 4, -2)\n",
        "range4= range(4, 1, -1)\n",
        "bits_list = list(range1) + list(range2) + list(range3) + list(range4)\n",
        "\n",
        "for bits in bits_list:\n",
        "    # Quantization process\n",
        "    quantizer = QuantizeNeuralNet(\n",
        "        student_net.model,\n",
        "        'resnet18',\n",
        "        batch_size=128,\n",
        "        data_loader=train_loader,\n",
        "        mlp_bits=bits,\n",
        "        cnn_bits=bits,\n",
        "        ignore_layers=[],\n",
        "        mlp_alphabet_scalar=scalar(bits),#3\n",
        "        cnn_alphabet_scalar=scalar(bits),\n",
        "        mlp_percentile=1,\n",
        "        cnn_percentile=1,\n",
        "        reg=None,\n",
        "        lamb=0.1,\n",
        "        retain_rate=0.25,\n",
        "        stochastic_quantization=False,\n",
        "        device=fast_device\n",
        "    )\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    quantized_model = quantizer.quantize_network()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Check quantized model bit size\n",
        "    effective_bit_size = calculate_bit_size(quantized_model)\n",
        "    print(f\"Bits {bits}, Effective Quantized Bit Size: {effective_bit_size}\")\n",
        "\n",
        "    _, quantized_test_accuracy = utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
        "    print(f\"Bits {bits}, Quantized Test Accuracy: {quantized_test_accuracy}\")\n",
        "\n",
        "    parameter = count_parameters(quantized_model) \n",
        "\n",
        "    # Write results to CSV\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            bits, 0.932, quantized_test_accuracy, training_time  # Include effective bit size\n",
        "        ])\n",
        "\n",
        "print(f\"Results saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHWCAYAAACbsXOkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAmPNJREFUeJzs3Xl8E3X+x/FXkqYXbTlbKPcNIggIgiCXioIiiAcIHggoru6y6uJ9cHmx6k9kWQ92XQ5BUBQRUVeURVEUBAUBkUPum1KO3vRK5vfHtKGhpW0gZZL2/Xw88mgy+WbmkyEt8873O9+xGYZhICIiIiIiIufFbnUBIiIiIiIi5YHClYiIiIiIiB8oXImIiIiIiPiBwpWIiIiIiIgfKFyJiIiIiIj4gcKViIiIiIiIHyhciYiIiIiI+IHClYiIiIiIiB8oXImIiIiIiPiBwpWIXDB79uzBZrMxa9Ysz7IJEyZgs9lK9XqbzcaECRP8WlOvXr3o1auXX9cpF8by5cux2WwsWLDA6lIslf87dOzYsXNex5w5c2jZsiVOp5MqVar4r7gAYrPZGD16tNVlnBf9vRIJfApXIlKkAQMGEBkZSWpq6lnb3HHHHYSGhnL8+PELWJnvNm/ezIQJE9izZ4/VpRTpv//9Lzabjdq1a+N2u60uR86QH17Odjty5IjVJZ6XrVu3Mnz4cJo0acI777zDv//97zLdXrDuz8TERB566CFatmxJREQEcXFxdOrUiSeeeIK0tDRPu3nz5jFlyhTrCj1PK1euZMKECSQlJVldikhQCrG6ABEJTHfccQefffYZn3zyCcOGDSv0fEZGBp9++il9+/alevXq57ydZ599lieffPJ8Si3R5s2bmThxIr169aJhw4Zez3399ddluu3SmDt3Lg0bNmTPnj1888039O7d2+qSpAhvv/02UVFRhZYHe0/P8uXLcbvd/OMf/6Bp06YXbLvBtD9PnDhBx44dSUlJYeTIkbRs2ZLjx4+zceNG3n77bR544AHPe5k3bx6bNm3i4Ycftrboc7Ry5UomTpzI8OHDA/LfQiTQKVyJSJEGDBhAdHQ08+bNKzJcffrpp6Snp3PHHXec13ZCQkIICbHuT1FoaKhl2wZIT0/n008/ZdKkScycOZO5c+cGbLhKT0+nUqVKVpdhmVtvvZUaNWpYXYbfHT16FPBvqMnIyCAyMrLYNsG0P6dPn86+ffv48ccf6dq1q9dzKSkplv8dEZHAoWGBIlKkiIgIbr75ZpYtW+Y5+Cpo3rx5REdHM2DAAE6cOMGjjz5KmzZtiIqKIiYmhuuuu44NGzaUuJ2izrnKysrib3/7G7GxsZ5tHDhwoNBr9+7dy5///GdatGhBREQE1atXZ9CgQV7D/2bNmsWgQYMAuPLKKz1Dj5YvXw4UfQ7D0aNHueeee6hZsybh4eG0bduWd99916tN/vlj//d//8e///1vmjRpQlhYGJdddhk///xzie873yeffMKpU6cYNGgQQ4YMYeHChWRmZhZql5mZyYQJE2jevDnh4eHEx8dz8803s3PnTk+b/N6HNm3aEB4eTmxsLH379uWXX37xqrngOW/5zjyfLf/fZfPmzdx+++1UrVqVbt26AbBx40aGDx9O48aNCQ8Pp1atWowcObLI4aEHDx7knnvuoXbt2oSFhdGoUSMeeOABsrOz2bVrFzabjddff73Q61auXInNZuP9998vcR+6XC6efvppatWqRaVKlRgwYAD79+/3PD9+/HicTieJiYmFXnvfffdRpUqVIve5r/LPAZs/f36x9eT76KOP6NChAxEREdSoUYM777yTgwcPFmq3detWBg8eTGxsLBEREbRo0YJnnnmmULukpCRPb0PlypUZMWIEGRkZxdbcsGFDxo8fD0BsbGyhz8Fbb73FxRdfTFhYGLVr1+Yvf/lLoeFivXr1onXr1qxdu5YePXoQGRnJ008/XYo9Vrzs7GzGjRtHhw4dqFy5MpUqVaJ79+58++23hdqW9NkvaNGiRbRu3ZqwsDAuvvhilixZUmItO3fuxOFwcPnllxd6LiYmhvDwcMDcF1988QV79+71/K3J7y2fNWsWNput0PDk/M9N/t+kfPl/VyIiIujUqRMrVqwosrasrCzGjx9P06ZNCQsLo169ejz++ONkZWV5tcs/56y49z9hwgQee+wxABo1auR5D4E6pFokEKnnSkTO6o477uDdd9/lww8/9DoR/MSJE3z11VcMHTqUiIgIfv/9dxYtWsSgQYNo1KgRCQkJ/Otf/6Jnz55s3ryZ2rVr+7Tde++9l/fee4/bb7+drl278s0339CvX79C7X7++WdWrlzJkCFDqFu3Lnv27OHtt9+mV69ebN68mcjISHr06MGDDz7I1KlTefrpp7nooosAPD/PdOrUKXr16sWOHTsYPXo0jRo14qOPPmL48OEkJSXx0EMPebWfN28eqamp/OlPf8Jms/HKK69w8803s2vXLpxOZ4nvde7cuVx55ZXUqlWLIUOG8OSTT/LZZ595AiGY4eGGG25g2bJlDBkyhIceeojU1FSWLl3Kpk2baNKkCQD33HMPs2bN4rrrruPee+8lNzeXFStW8NNPP9GxY8dS7/+CBg0aRLNmzXjppZcwDAOApUuXsmvXLkaMGEGtWrX4/fff+fe//83vv//OTz/95AnLhw4dolOnTiQlJXHffffRsmVLDh48yIIFC8jIyKBx48ZcccUVzJ07l7/97W+F9kt0dDQ33nhjiTW++OKL2Gw2nnjiCY4ePcqUKVPo3bs369evJyIigrvuuovnnnuO+fPne32Os7OzWbBgAbfccovn4Lg4J06cKLQsJCSkUI9PSfWAeaA9YsQILrvsMiZNmkRCQgL/+Mc/+PHHH/n1118969y4cSPdu3fH6XRy33330bBhQ3bu3Mlnn33Giy++6LXdwYMH06hRIyZNmsS6dev4z3/+Q1xcHC+//PJZ39OUKVOYPXs2n3zyiWeY3iWXXAKYB9oTJ06kd+/ePPDAA2zbto23336bn3/+mR9//NHr8338+HGuu+46hgwZwp133knNmjXPe3+mpKTwn//8h6FDhzJq1ChSU1OZPn06ffr0Yc2aNbRr187zutJ+9n/44QcWLlzIn//8Z6Kjo5k6dSq33HIL+/btK3Z4c4MGDXC5XMyZM4e77777rO2eeeYZkpOTOXDggOdLg6KGPpZk+vTp/OlPf6Jr1648/PDD7Nq1iwEDBlCtWjXq1avnaed2uxkwYAA//PAD9913HxdddBG//fYbr7/+On/88QeLFi3yWm9J7//mm2/mjz/+4P333+f111/39CzGxsb6/B5EKixDROQscnNzjfj4eKNLly5ey6dNm2YAxldffWUYhmFkZmYaLpfLq83u3buNsLAw47nnnvNaBhgzZ870LBs/frxR8E/R+vXrDcD485//7LW+22+/3QCM8ePHe5ZlZGQUqnnVqlUGYMyePduz7KOPPjIA49tvvy3UvmfPnkbPnj09j6dMmWIAxnvvvedZlp2dbXTp0sWIiooyUlJSvN5L9erVjRMnTnjafvrppwZgfPbZZ4W2daaEhAQjJCTEeOeddzzLunbtatx4441e7WbMmGEAxuTJkwutw+12G4ZhGN98840BGA8++OBZ2xS1//OduW/z/12GDh1aqG1R+/399983AOP777/3LBs2bJhht9uNn3/++aw1/etf/zIAY8uWLZ7nsrOzjRo1ahh33313odcV9O233xqAUadOHc+/i2EYxocffmgAxj/+8Q/Psi5duhidO3f2ev3ChQvP+rkoKH9fFHVr0aKFz/VkZ2cbcXFxRuvWrY1Tp0552n3++ecGYIwbN86zrEePHkZ0dLSxd+9er5ry91/B+kaOHOnV5qabbjKqV69e7Hsr+PrExETPsqNHjxqhoaHGtdde6/W7/cYbbxiAMWPGDM+ynj17GoAxbdq0ErdVcHsl7c/c3FwjKyvL67UnT540atas6fVeS/PZNwzzMx4aGmrs2LHDs2zDhg0GYPzzn/8stuYjR44YsbGxBmC0bNnSuP/++4158+YZSUlJhdr269fPaNCgQaHlM2fONABj9+7dXsvzPzf5n8P8z0e7du283v+///1vA/D6ezVnzhzDbrcbK1as8Fpn/t/oH3/80ef3/+qrrxZZp4iUjoYFishZORwOhgwZwqpVq7yGhcybN4+aNWty9dVXAxAWFobdbv45cblcHD9+nKioKFq0aMG6det82uZ///tfAB588EGv5UWdHJ7fCwCQk5PD8ePHadq0KVWqVPF5uwW3X6tWLYYOHepZ5nQ6efDBB0lLS+O7777zan/bbbdRtWpVz+Pu3bsDsGvXrhK39cEHH2C327nllls8y4YOHcqXX37JyZMnPcs+/vhjatSowV//+tdC68jvJfr444+x2WyeIV5FtTkX999/f6FlBfd7ZmYmx44d8wyXyt/vbrebRYsW0b9//yJ7zfJrGjx4MOHh4cydO9fz3FdffcWxY8e48847S1XjsGHDiI6O9jy+9dZbiY+P93yW8tusXr3aaxjl3LlzqVevHj179izVdj7++GOWLl3qdZs5c6bP9fzyyy8cPXqUP//5z149Zv369aNly5Z88cUXgDk73ffff8/IkSOpX7++1zaK+jc989+qe/fuHD9+nJSUlFK9v4L+97//kZ2dzcMPP+z53QYYNWoUMTExnhrzhYWFMWLECJ+2UdL+dDgcnnOZ3G43J06cIDc3l44dO3r9fvvy2e/du7enpxfgkksuISYmpsTf15o1a7Jhwwbuv/9+Tp48ybRp07j99tuJi4vj+eef9/Tq+kP+5+P+++/3Opdr+PDhVK5c2avtRx99xEUXXUTLli05duyY53bVVVcBFBpCea7vX0RKT+FKRIqVP2HFvHnzADhw4AArVqxgyJAhOBwOwDzwef3112nWrBlhYWHUqFGD2NhYNm7cSHJysk/b27t3L3a73esAAKBFixaF2p46dYpx48ZRr149r+0mJSX5vN2C22/WrJnXASWcHka4d+9er+VnHvTmB62C4ehs3nvvPTp16sTx48fZsWMHO3bsoH379mRnZ/PRRx952u3cuZMWLVoUO/HHzp07qV27NtWqVStxu75o1KhRoWUnTpzgoYceombNmkRERBAbG+tpl7/fExMTSUlJoXXr1sWuv0qVKvTv39/z+QIz9NSpU8dzgFiSZs2aeT222Ww0bdrU6wuB2267jbCwME+IS05O5vPPP+eOO+4odfjs0aMHvXv39rp16dLF53ryP0NFfaZbtmzpeT7/gLekfZjvfD6LZzpbjaGhoTRu3LjQ70GdOnV8ntShNPvz3Xff5ZJLLiE8PJzq1asTGxvLF1984fX77ctn/8x9BOZ+Ks0+io+P5+233+bw4cNs27aNqVOnEhsby7hx45g+fXop3nHp5O/bMz9HTqeTxo0bey3bvn07v//+O7GxsV635s2bAxQ6X/Z83r+IlI7OuRKRYnXo0IGWLVvy/vvv8/TTT/P+++9jGIbXLIEvvfQSY8eOZeTIkTz//PNUq1YNu93Oww8/XKbXbfrrX//KzJkzefjhh+nSpQuVK1fGZrMxZMiQC3a9qPyAeaaSvsnevn27Z+KLMw+iwAwY99133/kXWMDZQoTL5Trrawr2UuUbPHgwK1eu5LHHHqNdu3ZERUXhdrvp27fvOe33YcOG8dFHH7Fy5UratGnD4sWL+fOf/1wo4J6PqlWrcsMNNzB37lzGjRvHggULyMrKKnXvWDA418+iPxT1OTlf7733HsOHD2fgwIE89thjxMXF4XA4mDRpklcPpC/8sY9sNhvNmzenefPm9OvXj2bNmjF37lzuvffeEl9XlOJ+/0ridrtp06YNkydPLvL5gudngbWfEZGKQuFKREp0xx13MHbsWDZu3Mi8efNo1qwZl112mef5BQsWcOWVVxb69jYpKcnnqZYbNGiA2+329Nbk27ZtW6G2CxYs4O677+a1117zLMvMzCw0m5kvw+IaNGjAxo0bcbvdXgf3W7du9TzvD3PnzsXpdDJnzpxCBzw//PADU6dOZd++fdSvX58mTZqwevVqcnJyzjpJRpMmTfjqq684ceLEWb/Bz+/JOHP/nNkLUZyTJ0+ybNkyJk6cyLhx4zzLt2/f7tUuNjaWmJgYNm3aVOI6+/btS2xsLHPnzqVz585kZGRw1113lbqmM7dtGAY7duzwTMyQb9iwYdx44438/PPPzJ07l/bt23PxxReXejv+qif/M7Rt27ZCvXPbtm3zPJ/fS1GafehvBWss2FuSnZ3N7t27L8jlAhYsWEDjxo1ZuHCh1+/wmcP/SvPZLyuNGzematWqHD582LPsbH9vSvv7l7/vt2/f7vX5yMnJYffu3bRt29azrEmTJmzYsIGrr776vIb/FuSv9YhUVBoWKCIlyu+lGjduHOvXry90bSuHw1Hom8+PPvqoyGmlS3LdddcBMHXqVK/lU6ZMKdS2qO3+85//LPRNcP61mc48qCnK9ddfz5EjR5g/f75nWW5uLv/85z+Jiooq9fk5JZk7dy7du3fntttu49Zbb/W65U+FnD8N+S233MKxY8d44403Cq0n//3fcsstGIbBxIkTz9omJiaGGjVq8P3333s9/9Zbb5W67vwgeOZ+P/Pfx263M3DgQD777LMip8Mu+PqQkBCGDh3Khx9+yKxZs2jTpk2hYFSc2bNnk5qa6nm8YMECDh8+7Pks5bvuuuuoUaMGL7/8Mt99912Z9VqVVE/Hjh2Ji4tj2rRpXtNlf/nll2zZssUzM2ZsbCw9evRgxowZ7Nu3z2sbZd3T0Lt3b0JDQ5k6darXtqZPn05ycnKRs3f6W1GftdWrV7Nq1SqvdqX57J+v1atXk56eXmj5mjVrOH78uNcXQZUqVSpyWHL+UOeCv38ul4t///vfXu06duxIbGws06ZNIzs727N81qxZhf6GDR48mIMHD/LOO+8U2t6pU6eKrLkkvvy9FJHC1HMlIiVq1KgRXbt25dNPPwUoFK5uuOEGnnvuOUaMGEHXrl357bffmDt3bqHzA0qjXbt2DB06lLfeeovk5GS6du3KsmXL2LFjR6G2N9xwA3PmzKFy5cq0atWKVatW8b///a/QlMrt2rXD4XDw8ssvk5ycTFhYGFdddRVxcXGF1nnffffxr3/9i+HDh7N27VoaNmzIggUL+PHHH5kyZYrXRAXnavXq1Z6p3otSp04dLr30UubOncsTTzzBsGHDmD17NmPGjGHNmjV0796d9PR0/ve///HnP/+ZG2+8kSuvvJK77rqLqVOnsn37ds8QvRUrVnDllVd6tnXvvffy97//nXvvvZeOHTvy/fff88cff5S69piYGHr06MErr7xCTk4OderU4euvv2b37t2F2r700kt8/fXX9OzZ0zNN9OHDh/noo4/44YcfvKYwHzZsGFOnTuXbb78tdurwolSrVo1u3boxYsQIEhISmDJlCk2bNmXUqFFe7ZxOJ0OGDOGNN97A4XB4TVpSGgsWLChyWu1rrrnGa+rxkupxOp28/PLLjBgxgp49ezJ06FDPVOwNGzb0mpZ+6tSpdOvWjUsvvZT77ruPRo0asWfPHr744gvWr1/vU/2+iI2N5amnnmLixIn07duXAQMGsG3bNt566y0uu+wyvwTTkvbnDTfcwMKFC7npppvo168fu3fvZtq0abRq1Yq0tDRP+9J+9s/HnDlzmDt3LjfddBMdOnQgNDSULVu2MGPGDMLDw72u69WhQwfmz5/PmDFjuOyyy4iKiqJ///5cfPHFXH755Tz11FOeXrYPPviA3Nxcr205nU5eeOEF/vSnP3HVVVdx2223sXv3bmbOnFnob+pdd93Fhx9+yP3338+3337LFVdcgcvlYuvWrXz44Yd89dVXPl+GoUOHDoA5rfyQIUNwOp3079+/Ql9AXMQnF3ZyQhEJVm+++aYBGJ06dSr0XGZmpvHII48Y8fHxRkREhHHFFVcYq1atKjTNeWmmYjcMwzh16pTx4IMPGtWrVzcqVapk9O/f39i/f3+h6cJPnjxpjBgxwqhRo4YRFRVl9OnTx9i6davRoEGDQtN4v/POO0bjxo0Nh8PhNe3xmTUahjlFev56Q0NDjTZt2hSavjz/vbz66quF9seZdZ7pr3/9qwEYO3fuPGubCRMmGICxYcMGwzDM6c+feeYZo1GjRobT6TRq1apl3HrrrV7ryM3NNV599VWjZcuWRmhoqBEbG2tcd911xtq1az1tMjIyjHvuuceoXLmyER0dbQwePNg4evToWadiLzg9d74DBw4YN910k1GlShWjcuXKxqBBg4xDhw4V+b737t1rDBs2zIiNjTXCwsKMxo0bG3/5y18KTbFtGIZx8cUXG3a73Thw4MBZ90tB+VNYv//++8ZTTz1lxMXFGREREUa/fv0KTV2eb82aNQZgXHvttaXahmEUP3V4wc+Sr/XMnz/faN++vREWFmZUq1bNuOOOO4p875s2bfLs7/DwcKNFixbG2LFjC9V35r/V2ab+Ptv7K+rf+o033jBatmxpOJ1Oo2bNmsYDDzxgnDx50qtNz549jYsvvrjYbRS1vZL2p9vtNl566SWjQYMGRlhYmNG+fXvj888/N+6+++5CU52X5rMPGH/5y18K1VPU34szbdy40XjssceMSy+91KhWrZoREhJixMfHG4MGDTLWrVvn1TYtLc24/fbbjSpVqhiAV607d+40evfubYSFhRk1a9Y0nn76aWPp0qVFXhLgrbfeMho1amSEhYUZHTt2NL7//vsi/15lZ2cbL7/8snHxxRcbYWFhRtWqVY0OHToYEydONJKTk8/p/T///PNGnTp1DLvdrmnZRXxkMwydxSgiItZr37491apVY9myZWW2jQ0bNtCuXTtmz57t03ldpbF8+XKuvPJKPvroI2699Va/rltERIKDzrkSERHL/fLLL6xfv55hw4aV6XbeeecdoqKiuPnmm8t0OyIiUjHpnCsREbHMpk2bWLt2La+99hrx8fHcdtttZbKdzz77jM2bN/Pvf/+b0aNH6/wREREpEwpXIiJimQULFvDcc8/RokUL3n//fcLDw8tkO3/9619JSEjg+uuvL3JWOREREX/QOVciIiIiIiJ+oHOuRERERERE/EDhSkRERERExA90zlUR3G43hw4dIjo6GpvNZnU5IiIiIiJiEcMwSE1NpXbt2tjtxfdNKVwV4dChQ9SrV8/qMkREREREJEDs37+funXrFttG4aoI0dHRgLkDY2JiLK0lJyeHr7/+mmuvvRan02lpLb5S7dZQ7dZQ7dZQ7dZQ7dZQ7dZQ7dYIpNpTUlKoV6+eJyMUR+GqCPlDAWNiYgIiXEVGRhITE2P5B8tXqt0aqt0aqt0aqt0aqt0aqt0aqt0agVh7aU4X0oQWIiIiIiIifqBwJSIiIiIi4gcKVyIiIiIiIn6gc67OkWEY5Obm4nK5ynQ7OTk5hISEkJmZWebb8rdgqd3hcBASEqJp90VERETkvChcnYPs7GwOHz5MRkZGmW/LMAxq1arF/v37g+7gP5hqj4yMJD4+ntDQUKtLEREREZEgpXDlI7fbze7du3E4HNSuXZvQ0NAyDQ5ut5u0tDSioqJKvGhZoAmG2g3DIDs7m8TERHbv3k2zZs0CtlYRERERCWwKVz7Kzs7G7XZTr149IiMjy3x7breb7OxswsPDg+6gP1hqj4iIwOl0snfvXk+9IiIiIiK+Ctwj3gAXyGFBfKd/TxERERE5XzqiFBERERER8QOFKxERERGRIrjcBqt3n2DtMRurd5/A5TasLqlCCOb9rnOuLOJyG6zZfYKjqZnERYfTqVE1HPbAnlHPF7169aJt27ZMnDjR6lJERETEQgUPlKvvPkGXpnFBccyzZNNhJn62mcPJmYCD2dt/Ib5yOOP7t6Jv63iryyu3gn2/q+fKAks2Habby98w9J2feOiD9Qx95ye6vfwNSzYdLrNtJiYm8sADD1C/fn3CwsKoVasWffr04ccff/S0sdlsLFq0qMxqOF/Dhw9n4MCBpWr75ptv0rBhQ8LDw+ncuTNr1qwp2+JERESkkPxjnjtn/MLs7Q7unPFLmR/z+MOSTYd54L11eQf4px1JzuSB99YFfP3Bqjzsd4WrC8yqD80tt9zCr7/+yrvvvssff/zB4sWL6dWrF8ePHy+T7Vlp/vz5jBkzhvHjx7Nu3Tratm1Lnz59OHr0qNWliYiIVBjBeqDschtM/GwzRQ1Ey1828bPNAT9ULdiG1pWX/a5hgX5gGAanclwltnO5DcYv/v2sHxobMGHxZq5oWsPTXe52uzmV7SIkO7fQjHYRTkeprrGVlJTEihUrWL58OT179gSgQYMGdOrUydOmYcOGANx0002e5/fs2cPw4cNJSkry6tF6+OGHWb9+PcuXLwcgPT2dBx54gIULFxIdHc2jjz5aqIasrCyeeeYZ3n//fZKSkmjdujUvv/wyvXr1AmDWrFk8/PDDzJ8/n4cffpj9+/fTrVs3Zs6cSXx8PBMmTODdd98F8Lznb7/91vP6giZPnsyoUaMYMWIEANOmTeOLL75gxowZPPnkkyXuLxERETk/JR0o2zAPlK9pVavIIYJut0GO202uyyDH5Sbb5SbHZZCT6/Z+7HKTk3vGY5eb7Fw3uW7Dc9/rOZebnNwzHhdY99HUzEKB8Mz6Dydn8viCDVwUH0NMuJPo8BCiPT9DiAoPISbcSViIvUyvh3o2gTS0zu02SM/OJTXTvKVl5ZCSmf84x/Nze0Jaqfb7mt0n6NKk+oV7Az5SuPKDUzkuWo376rzXYwBHUjJpM+HrUrXf/FwfIkNL/ieMiooiKiqKRYsWcfnllxMWFlaozc8//0xcXBwzZ86kb9++OByOUtf92GOP8d133/Hpp58SFxfH008/7ekxyjd69Gg2b97MBx98QO3atfnkk0/o27cvv/32G82aNQMgIyOD//u//2POnDnY7XbuvPNOHn30UebOncujjz7Kli1bSElJYebMmQBUq1atUC3Z2dmsXbuWp556yrPMbrfTu3dvVq1aVer3JCIiIuduxfbEUh0od5m0DIfdVigE5QZ47wTAx+sOAgeLbeN02LxCV3SYk6i8+zEFl4c7iQo7fT+mQFiLDC3dl+n58nsMz9yD+T2Gb995aakDVq7LTXqWi5QCISg1M5fUrBxPWDozJJ0OUbmkZOaQlpWL4cd/zqOpZ/9cBQKFqwogJCSEWbNmMWrUKKZNm8all15Kz549GTJkCJdccgkAsbGxAFSpUoVatWqVet1paWlMnz6d9957j6uvvhqAd999l7p163ra7Nu3j5kzZ7Jv3z5q164NwKOPPsqSJUuYOXMmL730EgA5OTlMmzaNJk2aAGYge+655wAzIEZERJCVlVVsfceOHcPlclGzZk2v5TVr1mTr1q2lfl8iIiJSsuSMHHYkprLjaBrbE9LYkWj+PJh0qlSvP5qaVap2Nhs4HXZCHXacDhtOh918HHLGY4cdZ4j34xCv5/Puh5zxOG9ZqMPG3uMZvLV8Z4k1XX1RHJGhIaRm5pB2RshIyzYDRY7L4ER6NifSs0v1Potit5EXvJyFQlmUV4+Zk6hQB899XvzQuic//o2DSadIz3J5haHUrMIhKSO75JFZpRVitxXu4QvLD5IhJJ/KYdH6QyWuJy463G81lQWFKz+IcDrY/FyfEtut2X2C4TN/LrHdrBGX0amR2SvjdrtJTUklOia6yGGBpXXLLbfQr18/VqxYwU8//cSXX37JK6+8wn/+8x+GDx9e6vWcaefOnWRnZ9O5c2fPsmrVqtGiRQvP499++w2Xy0Xz5s29XpuVlUX16qe7dSMjIz3BCiA+Pl7nSYmIiFjMMAyOpWWz42gaO46msv1omhmmjqaRWMpwdDYTB1zMpfWregJRaH7Qcdjywo75+ELOLuhyG3zy60GOJGcWGVJsQK3K4fz7ro5nrcvtNkjLzi0UuvJ7cs7s5fEOOafvu9wGbgNSMnNJycz1y/tLOpXD859v8ek1YSH2Aj1qhXvaogv0xkWFF728pCGS+eeIlbTf84+RA5XClR/YbLZSDc/r3iyW+MrhJX5oujeL9TrnKjfUQWRoSKFw5avw8HCuueYarrnmGsaOHcu9997L+PHjiw1Xdrsd44y+3JycHJ+2m5aWhsPhYO3atYWGG0ZFRXnuO51Or+dsNluhbZekRo0aOBwOEhISvJYnJCT41CMnIiJS0RiGwaHkzLxeqFR2Jp7ujUrKOPv//bViwmlWM4omsVE0qxlF09goGtWoxI1v/ljiMc+dlzcIuGnZHXYb4/u34oH31mEDr/rzKx3fv1WxddvtNmLCncSEO8/apiT55/Sn5QWrM8OYOezOu7dpV2I624+mlbjudvWqcFF8tBmAwvJ7wbzDUMEQFRpS9nPg+WO/BwKFqwso0D40rVq18pqowul04nJ5d//GxsayadMmr2Xr16/3BKEmTZrgdDpZvXo19evXB+DkyZP88ccf9OjRA4D27dvjcrk4evQo3bt3P+d6Q0NDC9VXVJsOHTqwbNkyz7TtbrebZcuWMXr06HPetoiIiJX8ea0ol9tg/4kMth9NY/vR1LweqTR2Hk0j/SzDwGw2qFc1kmZxUTQtcGsSF3XWABFIxzy+6ts6nrfvvLTApBCmWhdwUoj8L+8jQ0OIiynda1btPM7Qd34qsd0TfVsG5KQQgbDfz5fC1QVmxYfm+PHjDBo0iJEjR3LJJZcQHR3NL7/8wiuvvMKNN97oadewYUOWLVvGFVdcQVhYGFWrVuWqq67i1VdfZfbs2XTp0oX33nuPTZs20b59e8Dsebrnnnt47LHHqF69OnFxcTzzzDNevWzNmzfnjjvuYNiwYbz22mu0b9+exMREli1bxiWXXEK/fv1K9T4aNmzIV199xbZt26hevTqVK1cu1NsFMGbMGO6++246duxIp06dmDJlCunp6Z7ZA0VERILJuc78lp3rZs/xdLP3qUCQ2nUsnexcd5GvCbHbaFijUuEQFRtFuA+nI0DwHyj3bR3PNa1qsWrHUb5esZpru3cO+Asgd2pUrVSjpAJ5aF0w7veCFK4skP+hWbP7BEdTM4mLNj/kZfWhiYqKonPnzrz++uvs3LmTnJwc6tWrx6hRo3j66ac97V577TXGjBnDO++8Q506ddizZw99+vRh7NixPP7442RmZjJy5EiGDRvGb7/95nndq6++SlpaGv379yc6OppHHnmE5ORkrxpmzpzJCy+8wCOPPMLBgwepUaMGl19+OTfccEOp38eoUaNYvnw5HTt2JC0t7axTsd92220kJiYybtw4jhw5Qrt27ViyZEmhSS5EREQCXWlmfuvZPM4cwnfUe2KJvcczznpNoLAQO01izeDULC5vOF9cFA2qV8Lp8N8QsGA/UHbYbXRuVI3jWww6l+Gxmr8E2iipcxVs+70ghSuLOOy2C9YdGxYWxqRJk5g0aVKx7fr370///v0LLZ84cSITJ0486+uioqKYM2cOc+bM8Sx77LHHcLvdpKSkAOaQw+LWM3z48ELnfg0cONDrnKvY2Fi+/rp009SPHj1awwBFRCSoleaiqn+Zuw5XMacnR4WFeHqfmnl+RlOnasQFO2AN5gPlYBTsPYbBTuFKREREJACt2X2i2GtFAZ5gVa1SaJEhqmZMmCUXsRVrBXuPYTBTuBIREREJQKW9WOqLA1tzx+UNyrgaCTbqMbRG2c+rKCIiIiI+i4sOK1W7xrFRJTcSCSZuF7a9P1DnxCpse38At/8uZlzW1HMlIiIiEmBcboMvNx0ptk0wzPwm4rPNi2HJE4SkHKIjwN63IaY29H0ZWg2wuroSqedKREREJIBk5rj489y1zF6117PszAFdwTTzm0ipbV4MHw6DlEPey1MOm8s3L7amLh8oXImIiIgEiBPp2dz+zk989XsCoQ47/xzanml3XkqtyuFe7WpVDuftOy8NjpnfgniIV1DXHmzcLljyBBQ3P+aSJwP+30DDAkVEREQCwL7jGdw9cw27j6UTEx7CO8M60rmxedmWoJ35LZiHeAVz7cHA7YKUg3BiF5zYDbu/L9xj5cUw2+9dCY26X7AyfaVwJSIiImKxDfuTuOfdnzmWlk2dKhHMGnEZzWpGe54Pypnf8od4ndkTkT/Ea/DswA0pwVx7IMnNhqR9ZoA6uft0kDqxC5L2givb93WmJfi/Tj9SuBIRERGx0LItCYye9yunclxcXDuGmcMvIy4mvOQXBjK3C758nGKHeH32ILiywO4EuwNsjgI/7QUen3G/UNtzWV5MOC1xeJrNHJ7Wsp+5rkDlNaQxBhr3KJt6s9Ph5B7v4JQfpJIPgOE++2vtTqjaAKo1BkcYbP2s5O1F1fRb6WVB4coqbpfZrZmWYH5IGnQN7F9QH/Xq1Yu2bdsyceJEq0sREREJWHNX72Xsok24DejRPJa37riUqLAAPzxz5UDqEUg9bN5SDkPqIXNZyiFzWfIByC3hOl2nTsLH916YmguxnT3QGS7ITC7mtXnD0z7/G9RuDxFVIaJK3s+8W2hU8QGurPl7SOOppCJ6n/LupxU/qyUhEWZ4qtYo79YYqub9rFz39PGv2wVTWpufpyKDrc18Dw26+l7/BRTgv73lVN4H3mtcaRmP4U1MTGTcuHF88cUXJCQkULVqVdq2bcu4ceO44oorALDZbHzyyScMHDiwTGo4X8OHDycpKYlFixYV2+7777/n1VdfZe3atRw+fDig35OIiFRMhmHw6lfbeGv5TgAGd6zLize1wek4y1xjF6IXwjDMwJOSF5RSD+UFp/wQlRec0o9R9MHvOajRAiKrm4HG7Srw033GYxe43UW0O8vyEuszwJ0L5MK5zo+w7l3zVhR7CIRX8Q5cZwawiKqF24RXBsd5Hp6fy5BGw4D0xKJ7n07sMj8XxQmv7B2aPGGqsdmJUJqgaXeYx8IfDsOcD7Ng/Xmv7/v3gO+MULi60Cwaw3vLLbeQnZ3Nu+++S+PGjUlISGDZsmUcP37c79uyWnp6Om3btmXkyJHcfPPNVpcjIiLiJTvXzRMfb+STXw8C8HDvZjx0dTNsZzsA9UcvRM6pvJBUoHepUHA6Yg7TKw27E6LjIboWxMRDdO28n3m3lEPwyX0lr6ffa2UzOYFhFBHC8kJbkcGtQKA78DMsHl3yNpr0hpAwM3gUvLmyzOCWccy8+SosxjuIFQppZwlqzojSDWn8/G9mXSf3nO6BOrkbstOKr6tSnHdo8gSpRhDpp2uttRpgHgsX2Qnx96A4z03hyh8MA3IySm5X4vhjm/lhatyrQBep21x3dl53dUHOyFJ9E5CUlMSKFStYvnw5PXv2BKBBgwZ06tTJ06Zhw4YA3HTTTZ7n9+zZU2Rv0cMPP8z69etZvnw5YIaZBx54gIULFxIdHc2jjz5aqIasrCyeeeYZ3n//fZKSkmjdujUvv/wyvXr1AmDWrFk8/PDDzJ8/n4cffpj9+/fTrVs3Zs6cSXx8PBMmTODdd81vh/L/8/n22289ry/ouuuu47rrritxv4iIiFxoKZk5PPDeWn7ccRyH3cakm9ow+LJ6Z39BSV/KDnoX6l9euHfpzPBUUs9DQZHVzbBUMDhF1zIPcPPDU2T1wsclBbldsGyCdUO8bLa8HqBzONSt0QyWv1Ry7Xd8WHQvSs6pwoHrVFLhZZlJ3s9npZivz0oxb0n7fKvbEWYeG2YW929tmMHq878V/b4q14WqDQv3PlVtCGHRRbymDLQaAC37kbvre9av+Ip23fsQUlbni5UBhSt/yMmAl2r7YUWG+Ufx76f/yNqBKmdr/vQhCK1U4lqjoqKIiopi0aJFXH755YSFhRVq8/PPPxMXF8fMmTPp27cvDkfpP8CPPfYY3333HZ9++ilxcXE8/fTTrFu3jrZt23rajB49ms2bN/PBBx9Qu3ZtPvnkE/r27ctvv/1Gs2bNAMjIyOD//u//mDNnDna7nTvvvJNHH32UuXPn8uijj7JlyxZSUlKYOXMmANWq6Yr0IiISPA4nn2LEzJ/ZeiSVSqEO3rqzAz2bx579BaW57s9Hw0pfQEiEd++S1/3ap3uiQgofJ/gsmId4nW/tzgjzFuPjsaEr1zzX66wBrJigZrjMHrPS9jzWbG0G24LD+KrUB2eATKRid2A06MbB31No26BbYH5OzkLhqgIICQlh1qxZjBo1imnTpnHppZfSs2dPhgwZwiWXXAJAbKz5x71KlSrUqlWr1OtOS0tj+vTpvPfee1x99dUAvPvuu9StW9fTZt++fcycOZN9+/ZRu7b5h+bRRx9lyZIlzJw5k5deegmAnJwcpk2bRpMmTQAzkD333HOAGRAjIiLIysryqT4REZFAsPVICsNn/MyRlExio8OYOfwyWtepXPyL9q4s4bo/BUTVKty7FFMwONUyh5ddyEkWgnmIlxW1O0KgUnXz5gvDMIf0nToJO7+Bzx4q+TV9/x7Q14oKZgpX/uCMNHuRSrJ3Jcy9teR2dyzwdJO73W5SUlOJiY7GXtSwwFK65ZZb6NevHytWrOCnn37iyy+/5JVXXuE///kPw4cPL/V6zrRz506ys7Pp3LmzZ1m1atVo0aKF5/Fvv/2Gy+WiefPmXq/NysqievXTf0AiIyM9wQogPj6eo0ePnnNtIiIigeDHHce4f85aUrNyaRoXxawRl1G3ain+Dy/t9Xxu+je0ve38iiwrwTzEK1hqt9nMIXth0dD+Lvju5aCfcS+YKVz5g81WquF5NLnK/ECX9IFvcpX3OVdOl7n+4sY2l0J4eDjXXHMN11xzDWPHjuXee+9l/PjxxYYru92OYXjXmpOT49N209LScDgcrF27ttBww6ioKM99p9Pp9ZzNZiu0bRERkWCycN0Bnvh4Izkug06NqvHOXR2pHOks+YVQ+uv5+Dr87EIL4iFeQVd7MA/HLCfO72hdfJP/gQc8H3CPC/+Bb9WqFenp6Z7HTqcTl8t7PtLY2FgOHz7stWz9+vWe+02aNMHpdLJ69WrPspMnT/LHH394Hrdv3x6Xy8XRo0dp2rSp182XIX6hoaGF6hMREQlEhmHw5rc7GPPhBnJcBjdcEs+cezqVPliB2bsQGlVMAxvE1FEvhHjLH9IYE++9PKZ2mc1KLacpXF1oFnzgjx8/zlVXXcV7773Hxo0b2b17Nx999BGvvPIKN954o6ddw4YNWbZsGUeOHOHkSXOmmauuuopffvmF2bNns337dsaPH8+mTZs8r4mKiuKee+7hscce45tvvmHTpk0MHz7cawhj8+bNueOOOxg2bBgLFy5k9+7drFmzhkmTJvHFF1+U+n00bNiQjRs3sm3bNo4dO3bWHrS0tDTWr1/vCYG7d+9m/fr17Nvn46w7IiIi5yDX5eaZRZt49attANzXozFTh7QnLMTHL093LS9memz1QkgxWg2AhzeRe+cifmnwALl3LoKHf1OwugA0LNAKeWN42bvSHE8dVdP81qmM/jhGRUXRuXNnXn/9dXbu3ElOTg716tVj1KhRPP300552r732GmPGjOGdd96hTp067Nmzhz59+jB27Fgef/xxMjMzGTlyJMOGDeO3337zvO7VV18lLS2N/v37Ex0dzSOPPEJysveVzWfOnMkLL7zAI488wsGDB6lRowaXX345N9xwQ6nfx6hRo1i+fDkdO3YkLS3trFOx//LLL1x55ZWex2PGjAHg7rvvZtasWaXenoiIiK8ysnP567xfWbb1KDYbjL+hFcOvaOT7ilIT4JM/mfebXA2JW4JvUgixVrANaSwnFK6sYndcsFlawsLCmDRpEpMmTSq2Xf/+/enfv3+h5RMnTmTixIlnfV1UVBRz5sxhzpw5nmWPPfaYORlHinnNBqfTWex6hg8fXujcr4EDB3qdcxUbG8vXX39d7HsA6NWrl87VEhGRCy4xNYt73v2ZjQeSCQux848h7enb+hxmuHW7zWCVnghxF8OQueAIDfyJFURE4UpERETkfO1KTOPumWvYf+IUVSOd/Ofuy+jQoOq5rWzlVNj1rXldqkEzzWsmgXohRIKAwpWIiIjIeVi79wT3vvsLJzNyqF8tklkjLqNxbHETURTjwC/wzfPm/etehtgWxbcXkYCicCUiIiJyjpZsOsxDH6wnK9dN27qVmT78MmpEhZ3byjKTYcFIcOfCxTfDpcP8W6yIlDmFKxEREZFzMPPH3Tz3+WYMA3pfFMfUoe2JDD3HQyvDgM8ehqS9UKUB9J9iXkdTRIKKwtU50oQJ5Yv+PUVEpLTcboOX/ruF//ywG4A7Otdn4oCLCXGcxxVufp0Dvy8EewjcOgPCK/upWhG5kBSufOR0mhf/y8jIICIiwuJqxF8yMjKA0/++IiIiRcnMcfHIhxv44rfDADzetwUP9GyC7Xx6mRK3wX8fN+9f9SzU7eiHSkXECgpXPnI4HFSpUoWjR48CEBkZeX5/UEvgdrvJzs4mMzPT68K8wSAYajcMg4yMDI4ePUqVKlVwODT7koiIFC0pI5tRs3/h5z0ncTpsvHprWwa2r3N+K805ZZ5nlXsKGl8JXR/yT7EiYgmFq3NQq5Z5zYr8gFWWDMPg1KlTRERElGmIKwvBVHuVKlU8/64iIiJn2n8ig+Ez17AzMZ3osBD+dVcHujatcf4r/vpZSNgElWLhpn9BgH4ZKSKlo3B1Dmw2G/Hx8cTFxZGTk1Om28rJyeH777+nR48eQTdkLVhqdzqd6rESEZGz2nQwmRGzfiYxNYv4yuHMHHEZLWvFnP+Kt3wGP//HvH/TvyC65vmvU0QspXB1HhwOR5kflDscDnJzcwkPDw/ogFKUYK5dREQE4NttR/nL3HVkZLtoWSuamSMuI76yH865TtoPn44273d9EJpeff7rFBHLWd73/Oabb9KwYUPCw8Pp3Lkza9asOWvbnJwcnnvuOZo0aUJ4eDht27ZlyZIl57VOkfLE5TZYvfsEa4/ZWL37BC63ZkEUETlX83/ex73v/kJGtosrmlbnw/u7+CdYuXJh4SjITILal8JVY89/nSISECwNV/Pnz2fMmDGMHz+edevW0bZtW/r06XPWc5meffZZ/vWvf/HPf/6TzZs3c//993PTTTfx66+/nvM6RcqLJZsO0+3lb7hzxi/M3u7gzhm/0O3lb1iy6bDVpYnIGYL5i5Bgrr20DMNg8tI/eOLj33C5DW5uX4eZwzsRE+6nURjfvwL7VkFotDntekiof9YrIpazNFxNnjyZUaNGMWLECFq1asW0adOIjIxkxowZRbafM2cOTz/9NNdffz2NGzfmgQce4Prrr+e1114753WKlAdLNh3mgffWcTg502v5keRMHnhvnQJWGasIB5viP8H8RUgw115aOS43jy3YyNRl2wEYfWVTXhvcltAQPx0y7V4B371i3u8/Bao18s96RSQgWHbOVXZ2NmvXruWpp57yLLPb7fTu3ZtVq1YV+ZqsrCzCw8O9lkVERPDDDz+c8zrz15uVleV5nJKSApjDEMt6woqS5G/f6jrOhWq/MFxugwmLf6eow3kDsAETP/udXs2q47AH9qyNwbTf8331ewIv/HcrR1KyAAezt/9CrZgwnr2+JX0uDo6T04Nxv+cLttq/+j2Bv36wodDva/4XIf8c0jZgPzfBXHtBxX1mUjNzeXD+Bn7YcRy7DSb2b8WQy+qSm5vrn41nHCfk43uxYeBueweuljeCD5/dYPu8F6TaraHa/cOXGmyGYVjyFeuhQ4eoU6cOK1eupEuXLp7ljz/+ON999x2rV68u9Jrbb7+dDRs2sGjRIpo0acKyZcu48cYbcblcZGVlndM6ASZMmMDEiRMLLZ83bx6RkZF+eLcSTNwG7EyxkZIDMU5oEmMQSJkk2wVpuZCeA2m5NnYkw/8OlTyxyl8uctG8inpU/GnDcRsz/sj/Nrvgh8TczyObu2lbXftcTG4DJq5zkJQN3p+XfAYxTnjwYhchdrDbzFZ2W94NsBVxP1BqrxIK4y91BdTfS18kZ8O/tjg4mGEj1G4wvLmbi6v68ffXMOi0awrxKb+SGhbPdy2ew+UI89/6RaTMZGRkcPvtt5OcnExMTPEzhQbVbIH/+Mc/GDVqFC1btsRms9GkSRNGjBhx3kP+nnrqKcaMGeN5nJKSQr169bj22mtL3IFlLScnh6VLl3LNNdcE3Yx7wVj7V78nMMnTC2Eqy14IwzBIzczlZEYOJ9KzzVtGNifScziZkfc4PYcTGdmcTM/mREYOGdmuc9rWf7Y7aVEziobVK9GoRiSNapg/G1aPJDI0MP4UBNNnxuU2mPTa90BWEc/asAFfJkTy+B09gqLHMFj2+5kCtXaX2+BoahYHTp4yb0mn+HVfEknZx4t5lfmlzgvrfft9dNht2G3mT4fNhj3vp63QMjzPef20U3jZGW1TTuWQlJ1cbO1J2RDeuANXt4wL6GsbFvWZ2Z6Qxj1z1nE4I5PqlUJ55672tKlT2a/btf/8bxzrf8VwhBF+1/v0qdnaL7UHC9VuDdXuH/mj2krDsiOqGjVq4HA4SEhI8FqekJBw1ou5xsbGsmjRIjIzMzl+/Di1a9fmySefpHHjxue8ToCwsDDCwgp/e+R0Oi3/x8wXSLX4KlhqX7LpcJFDXhJSsvjrBxt4+85L6ds6vth15LrcnMwwg9HxtPxwlGUGpPQsjucHqLzbyYxscly+fzPqdNioGhlKtUqhhNhtbDpU8i99Vq6bjQdT2HiwcNv4yuE0jq1EoxqVaFwjikaxlWhSI4o6VSMsCQaB/pkxDINvfj/iFcILtQEOJ2fx64FUujSpfuGKOw+Bvt+Lc6FrNwyDY2nZ7D+Zwf4TGXkhKoP9J8yfB5NOndPvNpi/3zZsuAyjVOfvudwGLjjn7fnTA/M2EBpip2ZMGLViwomLCadW3q1m5XBqRodRq3I4NWPCCXde+OsLutwG6/LOj6x+IJUuTeNYs/sE9835hdTMXBrXqMSsEZ2oX93Po1YOb4BlEwCwXfsCzrrtz2t1+l21hmq3RiDU7sv2LQtXoaGhdOjQgWXLljFw4EAA3G43y5YtY/To0cW+Njw8nDp16pCTk8PHH3/M4MGDz3udUrG53AYTP9t81vOWAJ7+ZBPpWbkkncrNC0xmgDqZke0JTcmncjiXgbaVQh1UrRRK9UpmYKpWKYxqlZxUqxTmWeZ5PiqU6LAQzzfDLrdBt5e/4UhyZpH124CalcOZOfwy9h5PZ9exdHYlprP7WDq7EtM4mZHD4eRMDidn8uMO72/VQx12GlSPzAteUTSOrUSTvPvVKvl3dquCk0JU332CLk3jLAl2p7JdJKRkciQl0/yZnElCSpbXsqMpWWS73KVa37OLfqNTo2pmaK1RicaxlahXLRKnw/IrYQS9svzMGIZBUkYOB06eYv/JDE9wMu+bASozp/jPQIjdRu0qEdSrFkHdKpEYGHz4y4EStz17ZGevQO52G56g5c7/6abQMq/nDQO3QZHLXW68X2cY5jYKPl9gmcsw2J6Qyjsrdpdq32Xnus19deJUse0qRziLDF21YsyfNSuHUaNSGHY//Zsu2XSYiZ9tzpv4xzw/skqEk7SsXHLdBh0aVOU/wzpS1c9/28hKg49GgCsbWvSDTqP8u34RCSiWjgUaM2YMd999Nx07dqRTp05MmTKF9PR0RowYAcCwYcOoU6cOkyZNAmD16tUcPHiQdu3acfDgQSZMmIDb7ebxxx8v9TpFzpSV62LRrwcLzbR3phPp2Tzy0cZSrbNKpJNqXmHpdGiqXjAo5d3O5xtch93G+P6teOC9ddjAK2DlH5JM6N+Ki+JjuCi+8DDXk+nZeYErLS9wmcFr9/F0snPdbD+axvajaYB3j3CVSKenp6txbCUa16hE49goGlSP9Pn9FHXQE185nPH9W5XYW1haLrfB8bQsjuQHptQsEpJPB6b8IJWS6acT1/PsTExnZ2K617IQu4361SI9YSs/uDaOrURsVFhAD6kKFP74zKRm5oWnvJ6n/QV6ng6cPEVaVvGfBZsN4mPCqVstkrpVI6hXNe9ntUjqVYukZnQYIQVCtMttsGL7sWK/CKlVOZxOjap5LbfbbdixYUFHj4fLbfD5xsMl1r7skZ4cT8v2fBlxJDmTo6lZHMn7XTuatzwzx03yqRyST+WwLSH1rNsNsduIjQ4rELrCqFn5dG9YXEw4tSqHExVW/OFM/oyqZ9aedMo8Sb19vSrMvbdz2fSm/fcxOLETYurAjW+YHxwRKbcsDVe33XYbiYmJjBs3jiNHjtCuXTuWLFlCzZrmuS379u3Dbj/9H1NmZibPPvssu3btIioqiuuvv545c+ZQpUqVUq9TKq70rFx2JqaxIy8s7Mi77T2eTmlnzm5eM4rmNaPzglEY1aLMkFQ1MpTqUWZQqhLh9DqguhD6to7n7TsvLXCwaapVioPNqpVC6VAplA4Nqnotd7kNDiWdKjJ4HUw6RVJGDr/uS+LXfUler7PZoE6VCBrVqEST2KjTww1jo4iPCS/0LfTZDnryZyAraTimYRikZeXmhaOswr1OeSEqMS2r1FOkRzgded+ih53+Fj3vIK5mjHmgV71SGFe9trzYg83qUaE8fd1F7Dmjx/BUjst8fCydZVu9XxcdFkKjM4ZoNq5hPq5UwgFkRVHaz8ypbBcHk7x7nAoGqaSMkmd/io0O8wSnetUiqFs10nM/vnKET9Nzl+aLkPH9WwXkOXqlrT0yNITIaiHUq3b2YXWGYZByKvf072lKJgnJmSSkev8OH0vLItdteHrWixMVFkJc3u/r6eGIZm9Yjagwxn1a9Iyq+Y6kZJZNb/LGD2HDPLDZ4Zb/QGS1kl8jIkHN8v+pR48efdYhe8uXL/d63LNnTzZv3nxe65TyLzkjhx2JqWxP8A5RB5POPkQlwmnnVAlDfAAmDmgdsOfP9G0dzzWtarFqx1G+XrGaa7t3Pq9hUg67zfMNfM/msV7Pncp2mYEhMZ3dx9LYlZjOzrwQlpqZ6zmJf8X2Y16vC3faaVi9Ul5PVxQNq0cy6cutxU4jP+7T36lWKex0r1PesDxzuJ75uLSTfNht5sFy4cBUIEhVDvcadlmckg42XxjYulAwNAyDIymZ7EpMLxRcD5zMIDUrl40Hktl4oPDkAbViwr3CauO8nq86VSLOOdAHynDM0jIvPVD8EN6/vv8rMeGbOJ6eXeL6qkY6zcBU7XTPU91qkdSragYpf/dknM8XIVbzV+02m43KkU4qRzppUSv6rO1yXW4S07KKHJpbcMhuWlaueUvMZdcZvcSldTg5kzW7T/j37/vxnfD538z7PZ+ABl39t24RCViWhyuRc2EYBolpWZ7gtONoGtsT0tiRmEZi6tknGagRFUrTuCiaxkXRLC4676d5/lD3V771ebhOoHHYbXRuVI3jWww6N6pWZgfJEaGOIocZGobB8fRsz/lcBQPEvhPmOSpbj6Sy9cjZhwF5rQ84mprF4H+d/Tp1+aLDQ84ITWecUF85nOqVQv3aq3guB5s2m434ymavxxVNa3g9l5XrYt/xDHYWOCdud14P14n0bE+4XLmz8Llx9atHmj1ceZOR5Pd4VasUetageCGGY54p1+UmLSuX1MxcUjJzSM3MzbvlnH15gfsnM7JL/CIkx2V4glVUWIhnqN7pHqi8EFU1gujwC3+StL+/CLmQLmTtIQ6753elOPk914V6v/Ie705M9wz/K87R1OJ7x3ySmw0LRkJ2GjS4Ano85r91i0hAU7iSMuGvb8MNw+BQcibbE1JPh6i8n8nF/GdZu3I4TQoGqJpRNI2NKvZE5WAdrhNIbDYbNaLCqBEVxmUNvYNorsvNgZOn2H0snZ2Jaew6ls7Pu0/knc9VvKp553ed7mU6fdJ7/lA9q6aT9+fBZliIg2Y1o2lWs/C3+UkZ2QWGFqadPjfuWDpZuW7P78eZYsJDvHq5GseaE2tsT0jloQ/W+zQcMyvX5RV6irufllUwJJ1+/lTOuV1KwFePXtuCOy+vT+UIZ0Cew3ahvggpC4FWe1RYCFGxUTSJjSry+VU7jzP0nZ9KXE9cdLj/ilo2EQ6vh4iqcPM7YLfwhDkRuaAUrgJYsA3XyXcu34bnutzsP3nKDFGJaezI64XacTTtrEO+7DaoXy0yryfqdC9Uk7ioEk9uLkowD9cJBiEOOw1rVKJhjUpc2TIOKP1Bz1t3dAjY4ZhwYQ42q0SGcmn9UC6t731unNttcCj5lNlLWKCna1diOoeST5GSmcv6/Ums359Uqu3kh60H319P85o7PEOuUjJzyc4t3QyJpRHutBMd7iQ6LITo8BDzfrh5Pyrs9P0Yz3InUeEh7ExM45EPN5S4/g4NqlIl0s+zvklQ6tSoGvGVwy/cyITtS2HVG+b9G9+CynX8s14RCQoKVwHKiuE6/lDSieZTh7ajec2YvB6oVLYfTWPnUfNb+LNNbe102GhYvZKn96lpzWiaxZnfvpfF+RDBOlwnGF3wg55yyG63UbdqJHWrRtLjjHPjMnNcnt6tXXm9hbsS0/njSAoZJQyty3a5z3r9tKiwEKI8oahgMMr7WSgwOb3aRoWF+DQRREFt6lTm/77aps+MlNoFnUgk5TB88ifzfqc/Qcvrz3+dIhJUFK4C0PnOnlZW3G6DHLebHJdBTq6bHJebbFfeY5ebU9kunvlkUwknmq8/6/rDnXaaxJq9TwV7oxpUv7DXBAq0IS/lWTDPnhYMwp1Fnxv36a8HeWj++hJff1+PRvS+qFahYGTlv4c+M3IuLsjIBLcLPrkPMo5DzTZwzXPnv04RCToKVwGmNBezfWrhb+Tkmhd2NMONOy/sFHhcIPSYzxsFwtDp57Jzz3hcTPvSTmNdkginnZbxMZ4QlX9eVJ0qEX67WKQEDw3HvPDiYkp3bsmVLWoGZA+QPjNyLsp8ZMIPr8Pu78FZCQbNBKcfz+ESkaChcBVg1uw+UeL1PE5m5PDXD369QBWdncNuI8RuI9RhxxliJ9ftJuVUyRdg/fvNl3Bje41Bl9M0HPPCKg/DMfWZkXNRZiMT9q2Gb18y71//KtRo5p/1ikjQUbgKMKWdCrZJbCVqV4nA6bATYrfhDLGbIcdhw+mw43TYCQ0543H+8yGnH4fkPR+a1yb/ea/HnnV5r+/M/5RKPSNTKb81l4pFwzEvnPIytE6fGQkIp5Lg43vBcEGbQdDudqsrEhELKVwFmNJOBfvCwDYBN3taefg2XKSi0NA6ET8wDFj8V0jeB1UbQb/JEIBT/4vIhaNwFWCCOaCUl2/DRSoKDa0TOU9rZ8KWxWAPgVunQ3hMya8RkXLtwk3BJqWSH1DgdCDJFwwBJf/b8FqVvXvgalUOt2yWQxE5u/yhdR1qaGidiE8SNsOSp8z7vSdAnQ6WliMigUE9VwEo2Ifr6NtwEREp17IzYMFIyM2Epr3h8r9YXZGIBAiFqwAV7AFFJ5qLiEi59dXTkLgFomrCwGlg10AgETEpXAUwBRQREZEA8/sn5rlW2OCmf0FUrNUViUgA0VctIiIiIqVxci8sfsi83+1haHKlpeWISOBRuBIREREpiSvHvJ5VVjLUvQyufMbqikQkAClciYiIiJRk+SQ4sAbCKsMt08HhtLoiEQlAClciIiIixdm1HFZMNu8P+AdUbWBpOSISuBSuRERERM4mLREW3gcYcOndcPFNVlckIgFM4UpERESkKG43LHoA0hIgtiX0/bvVFYlIgFO4EhERESnKT2/BjqUQEg63zoDQSKsrEpEAp3AlIiIicqaD6+B/E8z7fV6CmhdbWo6IBAeFKxEREZGCMlNgwUhw58BFA6DjSKsrEpEgoXAlIiIiks8w4ItH4ORuqFwPBkwFm83qqkQkSChciYiIiOTb8D789iHYHHDLfyCiqtUViUgQUbgSERERATi2A7541Lx/5VNQ/3Jr6xGRoKNwJSIiIpKbBQuGQ046NOwO3cZYXZGIBCGFKxEREZGl4+DIbxBZHW5+B+wOqysSkSCkcCUiIiIV27YvYfU08/7AtyEm3tp6RCRoKVyJiIhIxZVyCBb92bx/+Z+heR9r6xGRoKZwJSIiIhWT2wUfj4JTJyC+LfSeYHVFIhLkFK5ERESkYvr+/2DvDxAaBbfOhJAwqysSkSAXYnUBIiIiEkTcLmx7f6DOiVXY9sZA4x7BM/lDgdrtaw7A8knm8n6vQfUm1tYmIuWCwpWIiIiUzubFsOQJQlIO0RFg79sQUxv6vgytBlhdXfEK1Z63vMEV0HaIhYWJSHmiYYEiIiJSss2L4cNh5gQQBaUcNpdvXmxNXaVxttoB9q4M7NpFJKio50pERESK53bBkicAo4gn85Z9/jCEhAfeEEG3y6ytyNrzLHkSWvYLvNpFJOgoXImIiMhpbjekHYETu+HELvN2YE3RvT4FZRyHeYMuTI1+ZUDKQbMHq1F3q4sRkSCncCUiIlLRuHIheT+czA9Qu0+HqZN7IPfUua03ph5EVPFnpefvVBKk7C+5XVpCmZciIuWfwpWIiMiFdiFm3MvNgpN7T/c+FQxSSXvBnXv219ocUKUeVGts3gwDfple8jZvejvwen92r4B3byi5XVTNsq9FRMo9hSsREZELyZ8z7mWlndH7tOt071PyAYo9z8gRBlUb5gWoRqd/Vm0EVeqDw3m6rdsFf3xpTl5R5Dpt5nto0NW3+i+EBl3N2oKxdhEJOgpXIiIVWTBfsygY5c9ad+ZBfv6Me4NnFw5YGScKDNk7I0ilHy1+e6HRUK2hGZyqNjrdE1WtEUTXBnspJw22O8zw9+EwwHZG/TbzR9+/B+ZnJ5hrF5Ggo3AlIlJRBfM1i4JRaWbc++xBOPSr2fOUH6Qyk4tfb0Q179BUMEhVqgE2m3/qbzXADH9LnvCe3CKmthlOAvkzE8y1i0hQUbgSEamIzqUHRc7P3pUlz7h36iT8MLnw8uj4AqHpjCF8F3ICiVYDoGU/cnd9z/oVX9Guex9CgqW3M5hrF5GgoXAlIlLRlNiDYtN1f/wpMxn2/AA//6d07Rv1hGbXnA5TVRtCaGSZlugTuwOjQTcO/p5C2wbdguszEsy1i0hQULgSEaloSuxB0XV/zktuNhz4GXYtN28H14LhKv3rezym/S4iEqQUrkREKoqME7B/NaydVbr2v30IkdUgtqW+4S+OYcDRzafD1J4fISfdu031ptCoB/y+yBz6p1nrRETKJYUrEZHyyDDMyRD2/QT7fzJ/HvvDt3Wsm23eQqOhzqVQ9zKo1wnqdIRK1cum7mCRfDAvTH0Lu74rPGtfZA1o3AuaXGkO86tSz1ze+ErNWiciUo4pXImIlAe52XBkI+xblReoVkN6YuF2NZqbAWnL53mz0J3lOkhh0RDfzpy5LjsVdn9n3vJVawx1O0HdjmboqtkaHOX4v5T886Z2fmuGquPbvZ93Rpo9To2vNENVXKuipznXrHUiIuVaOf6fUESkHDt1Evb/fLpX6uBayM30buMIhdqXQv3OUL+LGYbye5ya9Sm+B+XGt8wDfbcLjm6BA2vgwC/muUTH/jh9sdqNH5jtnZFQu70ZtPJv0TXLeCeUIc95U98WOG/Kffp5mx3qdDCDVONe5vsNCSvdujVrnYhIuaVwJSIS6AzDvO7R/tWne6WObi7cLqIa1L8c6nU2f8a3A2d40essbQ+K3QG1Wpu3jiPNZRkn4OA6M3wcWAMH1kJWMuz90bzlq1K/QNjqBLXaQEioP/aI/xkGJPx++rypvT9CToZ3m+rNToepht3Obwp0zVonIlIuKVyJiAQaVw4c+a3A+VKrIe1I4XbVmhQIU12gRjPfLhh7rj0okdWgWW/zBuB2m71ZB34+fTu6BZL2mbdNH5vtHGFQu11e2OpoBq7KdUpfr78lHzgdpnYtLzyMslLs6TBV8LwpERGRs1C4EhE5X24Xtr0/UOfEKmx7Y8DXIV6ZyWYg2bfaPGfq4NrCvSZ2J8S3NcNUfqCKijv/2v3Rg2K3Q1xL83bpXXnvKQUOrTOHLuYHrlN5sxXuX336tdG1oV6BoYTF9badydf9firJPG8qP0wVed7UFacDVc2LfQurIiJS4SlciYicj82LYckThKQcoiPA3rfzhta9fPbJCZL2e/dKJWyi0MQS4ZXNAJXfK1XnUnBGlPGb8aPwmNMhBU7PXnjgZ9i/xvyZ8DukHoLNn5o3MENkrTanZyas2xGqNCgcckqz33OzTl9vaue3Ztgr9rypToE7bFFERIKCwpWIyLnavDhvUogzglHKYXP54NnQsp8ZnvJ7pfavNi/Qe6YqDcwQVb8z1Ls879pSRcw2F6xsNqjexLy1HWIuy043ZyM88HNeD9cac2jeoXXmbc2/zHaV4k4PJazXydy/C0dR9H6/C9rebk6Nvndl2Z43JSIicgaFKxGRc+F2mZNBFDmVed6yj+8Fe0jhC8raHBB/iRmi8of5Rdcq64oDT2glM+A07GY+NgzzHK2C524d3mgGpW1fmLdi5e33DfNOL/KcN3UlNO4JleuWxTsREREBFK5ERM7N3pXes+wVxZVl3kKjzR6X/HOl6nSAsKgLU2cwsdmgagPz1uZWc1nOKTNg5c9MuOdHyDhW8ro63gOX3WNeb0rnTYmIyAWicCUi4ousVPN8qTXvlK791ePhioc01fa5ckbkXaers/n4twXw8T0lv65BV3NCChERkQvI8gH9b775Jg0bNiQ8PJzOnTuzZs2aYttPmTKFFi1aEBERQb169fjb3/5GZubpC2dOmDABm83mdWvZsmVZvw0RKa+yM8zJEJY9B//pDX9vAHNvhe1fle71dS9TsPKnqFJemLi07URERPzI556rXbt20bhxY79sfP78+YwZM4Zp06bRuXNnpkyZQp8+fdi2bRtxcYWnGJ43bx5PPvkkM2bMoGvXrvzxxx8MHz4cm83G5MmTPe0uvvhi/ve//3keh4Sog05ESil/hrndK2D393DwF3Ble7epUt88T2jrl5CZRNHnXdnM2esadL0ARVcgDbqa+zXlMNrvIiISaHxOHU2bNqVnz57cc8893HrrrYSHl/J6JEWYPHkyo0aNYsSIEQBMmzaNL774ghkzZvDkk08War9y5UquuOIKbr/9dgAaNmzI0KFDWb16tVe7kJAQatWqgCeHi4jvXDlwcB3s+d4MU/vXQG6md5vo2tCoBzTqDg27m+cEQYHZAm14H+jnnePT9+/qtfI3u8Ocbl37XUREApDP4WrdunXMnDmTMWPGMHr0aG677TbuueceOnXq5NN6srOzWbt2LU899ZRnmd1up3fv3qxatarI13Tt2pX33nuPNWvW0KlTJ3bt2sV///tf7rrrLq9227dvp3bt2oSHh9OlSxcmTZpE/fr1z1pLVlYWWVlZnscpKSkA5OTkkJOT49P78rf87Vtdx7lQ7dZQ7SVwu7Ad2YBt7w/Y9vyIbf9P2M6Yzc+oFIfR4ArcDbphNOwGVRt7T4qQX1+z67DdMhPH109jSz09uYURUxvXNS9iNLvudNsAFnSfGe13y6l2a6h2a6h2awRS7b7UYDMMo6hxFSXKzc1l8eLFzJo1iyVLltC8eXNGjhzJXXfdRWxsbImvP3ToEHXq1GHlypV06dLFs/zxxx/nu+++K9QblW/q1Kk8+uijGIZBbm4u999/P2+//bbn+S+//JK0tDRatGjB4cOHmThxIgcPHmTTpk1ER0cXuc4JEyYwceLEQsvnzZtHZGRkie9FRAKY4Sbm1H5qpG2hRuoWaqRtxek+5dUk21GJY9GtOBZ1EceiLiI1vLZvM8wZbqqnbSM8J4lMZxWOR7UwL1ArZUv7XURELoCMjAxuv/12kpOTiYmJKbbtOYerfFlZWbz11ls89dRTZGdnExoayuDBg3n55ZeJj48/6+vOJVwtX76cIUOG8MILL9C5c2d27NjBQw89xKhRoxg7dmyR20lKSqJBgwZMnjyZe+4peoaponqu6tWrx7Fjx0rcgWUtJyeHpUuXcs011+B0Oi2txVeq3RoVvnbDgGPbsO/5weyd2vcjtlMnvZuExWDU74rRsBvuBt3ypus+v4PyCr/fLaLaraHaraHaraHarRFItaekpFCjRo1Shatznunhl19+YcaMGXzwwQdUqlSJRx99lHvuuYcDBw4wceJEbrzxxmJn/qtRowYOh4OEhASv5QkJCWc9X2rs2LHcdddd3HvvvQC0adOG9PR07rvvPp555hns9sIHR1WqVKF58+bs2LHjrLWEhYURFhZWaLnT6bT8HzNfINXiK9VujaCr3e3Ctnc1dU6sIvRQDCGNe5TuvBnDgOM7886ZWgF7fjAvOltQaBTU7+I5Z8oW3xZb3rr9fWZO0O33AlS7NVS7NVS7NVS7NVT7+ddQWj6Hq8mTJzNz5ky2bdvG9ddfz+zZs7n++us9waZRo0bMmjWLhg0bFrue0NBQOnTowLJlyxg4cCAAbrebZcuWMXr06CJfk5GRUShAORzmodHZOuDS0tLYuXNnofOyRCSAbF4MS54gJOUQHQH2vm3O+Nb3ZWg1oHD7k3vNySf2rDADVeoZF/MNCTcv2NuwuzkRRe324AjO/1REREQkePgcrt5++21GjhzJ8OHDzzrsLy4ujunTp5e4rjFjxnD33XfTsWNHOnXqxJQpU0hPT/fMHjhs2DDq1KnDpEmTAOjfvz+TJ0+mffv2nmGBY8eOpX///p6Q9eijj9K/f38aNGjAoUOHGD9+PA6Hg6FDh/r6VkXkQvDMuHfGFyQph83lg2dD3Y6np0bf8z0k7fNu6wiFup1Oz+ZXtyOEFO6NFhERESlLPoer7du3l9gmNDSUu+++u8R2t912G4mJiYwbN44jR47Qrl07lixZQs2a5sUf9+3b59VT9eyzz2Kz2Xj22Wc5ePAgsbGx9O/fnxdffNHT5sCBAwwdOpTjx48TGxtLt27d+Omnn0o1yYaIXGBuFyx5gqKvV5S37KPhYLi8n7KHQJ0OeT1T3aFeZ3BGlHGxIiIiIsXzOVzNnDmTqKgoBg0a5LX8o48+IiMjo1ShqqDRo0efdRjg8uXLvR6HhIQwfvx4xo8ff9b1ffDBBz5tX0QstHclpBwqvo3hAmzm0L5G3aFhD3PIX1jUBSlRREREpLR8nh5r0qRJ1KhRo9DyuLg4XnrpJb8UJSIVxNHNpWs3YCrc9y1c8xw0661gJSIiIgHJ556rffv20ahRo0LLGzRowL59+4p4hYhIAaeSYMti2PihOSFFaVQt/DdHREREJND4HK7i4uLYuHFjodkAN2zYQPXq1f1Vl4iUJ7nZsGMpbJwP25aA6/R15XCEgiv7LC+0mbMGNuh6QcoUEREROR8+h6uhQ4fy4IMPEh0dTY8ePQD47rvveOihhxgyZIjfCxSRIGUYsH+1Gah+/wQKXsg3tiVcchu0GQSHfs2bLRC8J7awmT/6/r1017sSERERsZjP4er5559nz549XH311YSEmC93u90MGzZM51yJCCT+Ab99aA77S9p7enl0PLS+xQxVtdqALS88ValnTre+5AnvyS1iapvBqqjrXImIiIgEIJ/DVWhoKPPnz+f5559nw4YNRERE0KZNGxo0aFAW9YlIMEg7Cps+NnupDv16enloFFw0ANreZk6bfrYeqFYDoGU/cnd9z/oVX9Guex9CGvdQj5WIiIgEFZ/DVb7mzZvTvHlzf9YiIsEkOx22fmEGqp3fnr4WlT0EmvY2h/y1uB5CI0u3PrsDo0E3Dv6eQtsG3RSsREREJOicU7g6cOAAixcvZt++fWRne5+IPnnyZL8UJiIByJULu5ebQ/62fA456aefq3uZOeTv4pugUuHLNYiIiIiUdz6Hq2XLljFgwAAaN27M1q1bad26NXv27MEwDC699NKyqFFErGQY5lC/3z6C3xZA+tHTz1VtZAaqSwZD9SbW1SgiIiISAHwOV0899RSPPvooEydOJDo6mo8//pi4uDjuuOMO+vbtWxY1iogVTu4xA9XGD+HYH6eXR1Y3J6ZoMxjqdjw9MYWIiIhIBedzuNqyZQvvv/+++eKQEE6dOkVUVBTPPfccN954Iw888IDfixSRCyTjhDlt+sYPYf9Pp5eHhEPLfmYvVZOrwOG0rkYRERGRAOVzuKpUqZLnPKv4+Hh27tzJxRdfDMCxY8f8W52IlL2cTPhjiRmotn8N7py8J2zQqIcZqC7qD+ExlpYpIiIiEuh8DleXX345P/zwAxdddBHXX389jzzyCL/99hsLFy7k8ssvL4saRaS03C5se3+gzolV2PbGwNmmM3e7Ye+P5kx/mxdDVvLp52q1MYf8tbnVvNaUiIiIiJSKz+Fq8uTJpKWlATBx4kTS0tKYP38+zZo100yBIlbavBiWPEFIyiE6Aux9O+9CvC+fvhBvwmYzUP22AFIOnH5tTF24ZJAZqmq2sqJ6ERERkaDnU7hyuVwcOHCASy65BDCHCE6bNq1MChMRH2xeDB8OAwzv5SmHzeWX3AYJv0PCb6efC6sMF99oPle/K9jtF7RkERERkfLGp3DlcDi49tpr2bJlC1WqVCmjkkTEJ24XLHmCQsEKTi/b+IH50+6E5n3MqdOb9QFn+IWqUkRERKTc83lYYOvWrdm1axeNGjUqi3pExFd7V0LKoZLbXf4X6PEoRFYr+5pEREREKiCfxwG98MILPProo3z++eccPnyYlJQUr5uIXGBpCaVrV+dSBSsRERGRMuRzz9X1118PwIABA7AVuHioYRjYbDZcLpf/qhOR4rldcHhD6dpG1SzbWkREREQqOJ/D1bffflsWdYiIr3Ysg6/HwtHfS2hoM2cNbND1gpQlIiIiUlH5HK569uxZFnWISGklbIavn4Wdy8zH4ZWhRT/Y8H5eg4ITW+T1Lvf9e9HXuxIRERERv/E5XH3//ffFPt+jR49zLkZEipF6BL59EX59Dwy3OfNfp1HQ4zHzXKoW15mzBhac3CKmthms8q9zJSIiIiJlxudw1atXr0LLCp57pXOuRPwsOx1WvgE//gNy0s1lFw2A3hOgepPT7VoNgJb9yN31PetXfEW77n0IadxDPVYiIiIiF4jP4erkyZNej3Nycvj1118ZO3YsL774ot8KE6nw3C5YPw++eQHSjpjL6nSEPi9C/cuLfo3dgdGgGwd/T6Ftg24KViIiIiIXkM/hqnLlyoWWXXPNNYSGhjJmzBjWrl3rl8JEKrSd35iTVSRsMh9XqW/2VF18MxToKRYRERGRwOFzuDqbmjVrsm3bNn+tTqRiOrrFDFU7lpqPwypDz8eg030QEmZtbSIiIiJSLJ/D1caNG70eG4bB4cOH+fvf/067du38VZdIxZKaAMtfgnWz8yarCIHLRkHPx3XhXxEREZEg4XO4ateuHTabDcMwvJZffvnlzJgxw2+FiVQI2Rmw6k34cQpkp5nLLuoPvSd6T1YhIiIiIgHP53C1e/dur8d2u53Y2FjCw8P9VpRIued2wYYPzMkqUvOmTq/TAa59ERp0sbY2ERERETknPoerBg0alEUdIhXHruXmRYCP/GY+rlwfeo83J6uw2y0tTURERETOnc/h6sEHH6Rp06Y8+OCDXsvfeOMNduzYwZQpU/xVm0j5cnQrLB0H278yH4dVhh6PQKc/gVM9vyIiIiLBzuevyT/++GOuuOKKQsu7du3KggUL/FKUSLmSdhQ+exje7mIGK3uIGage/BWueEjBSkRERKSc8Lnn6vjx40Ve6yomJoZjx475pSiRciE7A356E36YcnqyipY3mJNV1GhqaWkiIiIi4n8+91w1bdqUJUuWFFr+5Zdf0rhxY78UJRLU3G5Y/z680dGcsCI7DWq3h+H/hSFzFaxEREREyimfe67GjBnD6NGjSUxM5KqrrgJg2bJlvPbaazrfSmT39/DVM3Ak73pwlevB1eOh9S2arEJERESknPM5XI0cOZKsrCxefPFFnn/+eQAaNmzI22+/zbBhw/xeoEhQSNxmTlbxR16vblgMdB8DnR/QOVUiIiIiFYTP4QrggQce4IEHHiAxMZGIiAiioqL8XZdIcEhLhOWTYO0sMFxgc8Bl90DPJ6BSDaurExEREZEL6JwuIpybm0uzZs2IjY31LN++fTtOp5OGDRv6sz6RwJRzCn56C1a8Dtmp5rIW/eCaiVCjmbW1iYiIiIglfD4JZPjw4axcubLQ8tWrVzN8+HB/1CRiLbcL294fqHNiFba9P4DbVeA5N2yYD//sCMueM4NVfDu4+3MYOk/BSkRERKQC87nn6tdffy3yOleXX345o0eP9ktRIpbZvBiWPEFIyiE6Aux9G2JqQ9+XIaIqfP0sHF5vto2pC1ePgzaDNFmFiIiIiPgermw2G6mpqYWWJycn43K5iniFSJDYvBg+HAYY3stTDsGHd51+HBptTlZx+QPgjLigJYqIiIhI4PL56/YePXowadIkryDlcrmYNGkS3bp182txIheM2wVLnqBQsDpTx5Hw4K9muFKwEhEREZECfO65evnll+nRowctWrSge/fuAKxYsYKUlBS++eYbvxcockHsXWn2UJXk4pshKrbkdiIiIiJS4fjcc9WqVSs2btzI4MGDOXr0KKmpqQwbNoytW7fSunXrsqhRpOylJfi3nYiIiIhUOOd0navatWvz0ksveS1LSkrijTfe0KQWEpyiavq3nYiIiIhUOOc9xdmyZcu4/fbbiY+PZ/z48f6oSeTCq98FQisV08AGMXWgQdcLVpKIiIiIBJdzClf79+/nueeeo1GjRlx77bUAfPLJJxw5csSvxYlcEG43fPkYZKefpYHN/NH372B3XLCyRERERCS4lDpc5eTk8NFHH9GnTx9atGjB+vXrefXVV7Hb7Tz77LP07dsXp9NZlrWK+J/bBZ/+BX6ZAdig4z3mda0KiqkNg2dDqwGWlCgiIiIiwaHU51zVqVOHli1bcuedd/LBBx9QtWpVAIYOHVpmxYmUKVcOLLwPfl8INgfc9C+4ZBC4XyV31/esX/EV7br3IaRxD/VYiYiIiEiJSt1zlZubi81mw2az4XDoQFOCXG4WfHi3GazsThg0ywxWAHYHRoNuHKzWBaNBNwUrERERESmVUoerQ4cOcd999/H+++9Tq1YtbrnlFj755BNsNltZ1ifif9kZ8P4Q2PYFOMJgyDwN+RMRERGR81bqcBUeHs4dd9zBN998w2+//cZFF13Egw8+SG5uLi+++CJLly7F5XKVZa0i5y8rFeYNhp3fgDMS7vgQml9rdVUiIiIiUg6c02yBTZo04YUXXmDv3r188cUXZGVlccMNN1Czpq4BJAHsVBLMuRn2rIDQaLhzITTuZXVVIiIiIlJOnNNFhPPZ7Xauu+46rrvuOhITE5kzZ46/6hLxr4wTMGcgHN4A4VXgroVQp4PVVYmIiIhIOXJe4aqg2NhYxowZ46/VifhP2lGYfSMc3QyRNWDYIqjVxuqqRERERKSc8Vu4EglIyQdh9gA4vgOiasHdiyG2hdVViYiIiEg5pHAl5dfJPfDuAEjaC5XrwbBPoXoTq6sSERERkXLqnCa08Kc333yThg0bEh4eTufOnVmzZk2x7adMmUKLFi2IiIigXr16/O1vfyMzM/O81inl0LEdMPN6M1hVbQQj/qtgJSIiIiJlytJwNX/+fMaMGcP48eNZt24dbdu2pU+fPhw9erTI9vPmzePJJ59k/PjxbNmyhenTpzN//nyefvrpc16nlEMJm2HmdZByEGo0hxFfQpX6VlclIiIiIuWcz8MCXS4Xs2bNYtmyZRw9ehS32+31/DfffFPqdU2ePJlRo0YxYsQIAKZNm8YXX3zBjBkzePLJJwu1X7lyJVdccQW33347AA0bNmTo0KGsXr36nNcp5czhDTB7IJw6ATVbw12LICrW6qpEREREpALwOVw99NBDzJo1i379+tG6dWtsNts5bTg7O5u1a9fy1FNPeZbZ7XZ69+7NqlWrinxN165dee+991izZg2dOnVi165d/Pe//+Wuu+4653UCZGVlkZWV5XmckpICQE5ODjk5Oef0/vwlf/tW13EuLnTttoO/4Hh/MLasFNzx7XEN/RDCqsA5bF/73Rqq3Rqq3Rqq3Rqq3Rqq3Rqq3T98qcFmGIbhy8pr1KjB7Nmzuf76630urKBDhw5Rp04dVq5cSZcuXTzLH3/8cb777juv3qiCpk6dyqOPPophGOTm5nL//ffz9ttvn9c6J0yYwMSJEwstnzdvHpGRkefzNuUCqZ62lct3TibEncnxSs35qckj5DoirC5LRERERIJcRkYGt99+O8nJycTExBTb1ueeq9DQUJo2bXrOxZ2P5cuX89JLL/HWW2/RuXNnduzYwUMPPcTzzz/P2LFjz3m9Tz31lNc1ulJSUqhXrx7XXnttiTuwrOXk5LB06VKuueYanE6npbX46kLVbtu1HMdHr2NzZ+Ju2J2YQe9xbWil81qn9rs1VLs1VLs1VLs1VLs1VLs1VLt/5I9qKw2fw9UjjzzCP/7xD954441zHhIIZg+Yw+EgISHBa3lCQgK1atUq8jVjx47lrrvu4t577wWgTZs2pKenc9999/HMM8+c0zoBwsLCCAsLK7Tc6XRa/o+ZL5Bq8VWZ1r7tS/hwGLiyodm12AfPxu70X4+V9rs1VLs1VLs1VLs1VLs1VLs1VPv511BaPoerH374gW+//ZYvv/ySiy++uNDGFi5cWKr1hIaG0qFDB5YtW8bAgQMBcLvdLFu2jNGjRxf5moyMDOx27wkOHQ4HAIZhnNM6JYj9/gl8fC+4c+Gi/nDLDAgJtboqEREREamgfA5XVapU4aabbvLLxseMGcPdd99Nx44d6dSpE1OmTCE9Pd0z09+wYcOoU6cOkyZNAqB///5MnjyZ9u3be4YFjh07lv79+3tCVknrlHJiwwew6AEw3NBmEAycBg5dE1tERERErOPz0ejMmTP9tvHbbruNxMRExo0bx5EjR2jXrh1LliyhZs2aAOzbt8+rp+rZZ5/FZrPx7LPPcvDgQWJjY+nfvz8vvvhiqdcp5cAvM+HzvwEGtL8L+v8D7A6rqxIRERGRCu6cv+pPTExk27ZtALRo0YLY2HO7ltDo0aPPOmRv+fLlXo9DQkIYP34848ePP+d1SpD76W1Ykne9sk73Qd+XwW7ptbBFRERERADw+ag0PT2dkSNHEh8fT48ePejRowe1a9fmnnvuISMjoyxqFDGtmHw6WHV9EK57RcFKRERERAKGz0emY8aM4bvvvuOzzz4jKSmJpKQkPv30U7777jseeeSRsqhRKjrDgG9ehGV51yLr+SRc8xycx2yVIiIiIiL+5vOwwI8//pgFCxbQq1cvz7Lrr7+eiIgIBg8e7Lmgr4hfGAZ8/SysesN83HsCdPubpSWJiIiIiBTF53CVkZFR5OQQcXFxGhYo/uV2w5ePwc//MR9f9wp0/pO1NYmIiIiInIXPwwK7dOnC+PHjyczM9Cw7deoUEydOpEuXLn4tTiowtwsW/zUvWNmg/1QFKxEREREJaD73XP3jH/+gT58+1K1bl7Zt2wKwYcMGwsPD+eqrr/xeoFRArhz45E+w6WOwOeCmaXDJYKurEhEREREpls/hqnXr1mzfvp25c+eydetWAIYOHcodd9xBRESE3wuUCiY3CxaMhK2fgz0Ebp0BrW60uioRERERkRKd03WuIiMjGTVqlL9rkYou5xTMvwt2LAVHGNw2B5r3sboqEREREZFSKVW4Wrx4Mddddx1Op5PFixcX23bAgAF+KUwqmKw0eH8I7FkBIREw9H1ocqXVVYmIiIiIlFqpwtXAgQM5cuQIcXFxDBw48KztbDYbLpfLX7VJRZGZDHMHw/6fIDQa7vgQGnS1uioREREREZ+UKly53e4i74uct4wT8N7NcOhXCK8Md34CdTtYXZWIiIiIiM98nop99uzZZGVlFVqenZ3N7Nmz/VKUVBBpiTDrBjNYRVaHuz9XsBIRERGRoOVzuBoxYgTJycmFlqempjJixAi/FCUVQMohmHU9HP0domrC8P9C/CVWVyUiIiIics58ni3QMAxsNluh5QcOHKBy5cp+KUrKuaR98G5/OLkHYurC3YuhehOrqxIREREROS+lDlft27fHZrNhs9m4+uqrCQk5/VKXy8Xu3bvp27dvmRQp5cjxnfDuAEg5AFUbwt2fQZX6VlclIiIiInLeSh2u8mcJXL9+PX369CEqKsrzXGhoKA0bNuSWW27xe4FSjhzdCrNvhLQjUKM5DPsUYmpbXZWIiIiIiF+UOlyNHz8egIYNG3LbbbcRHh5eZkVJOeB2Ydv7A3VOrMK2NwYiqsDcWyDjONRsDXctgqhYq6sUEREREfEbn8+5uvvuu8uiDilPNi+GJU8QknKIjgB73wZsgAG128OdCyGymrU1ioiIiIj4mc/hyuVy8frrr/Phhx+yb98+srOzvZ4/ceKE34qTILR5MXw4DDDOeCLvcef7FaxEREREpFzyeSr2iRMnMnnyZG677TaSk5MZM2YMN998M3a7nQkTJpRBiRI03C5Y8gSFg1U+Gyx7zmwnIiIiIlLO+Byu5s6dyzvvvMMjjzxCSEgIQ4cO5T//+Q/jxo3jp59+KosaJVjsXWlev+qsDEg5aLYTERERESlnfA5XR44coU2bNgBERUV5Lih8ww038MUXX/i3OgkuaQn+bSciIiIiEkR8Dld169bl8OHDADRp0oSvv/4agJ9//pmwsDD/VifBJaqmf9uJiIiIiAQRn8PVTTfdxLJlywD461//ytixY2nWrBnDhg1j5MiRfi9QgkiDrnnXrbKdpYENYuqY7UREREREyhmfZwv8+9//7rl/2223Ub9+fVatWkWzZs3o37+/X4uTIGN3QN+X4cO7ingyL3D1/bvZTkRERESknPE5XJ2pS5cudOnSxR+1SHnQagC0GgibF3kvj6ltBqtWA6yoSkRERESkzJUqXC1evLjUKxwwQAfPFV7iNgBcXR/m14NZtOveh5DGPdRjJSIiIiLlWqnC1cCBA70e22w2DMMotAzMiwxLBZa4DRK3gN2Ju8tfOfjNj7Rt0E3BSkRERETKvVJNaOF2uz23r7/+mnbt2vHll1+SlJREUlISX375JZdeeilLliwp63ol0G3O6+Vs3AvCK1taioiIiIjIheTzOVcPP/ww06ZNo1u3bp5lffr0ITIykvvuu48tW7b4tUAJMls+NX+2utHaOkRERERELjCfp2LfuXMnVapUKbS8cuXK7Nmzxw8lSdA6vhOO/AY2B7TsZ3U1IiIiIiIXlM/h6rLLLmPMmDEkJCR4liUkJPDYY4/RqVMnvxYnQWZL3pDARt0hspq1tYiIiIiIXGA+h6sZM2Zw+PBh6tevT9OmTWnatCn169fn4MGDTJ8+vSxqlGCRf76VhgSKiIiISAXk8zlXTZs2ZePGjSxdupStW7cCcNFFF9G7d2/PjIFSASXtg0PrwGaHljdYXY2IiIiIyAV3ThcRttlsXHvttVx77bX+rkeCVX6vVf2uEBVnbS0iIiIiIhYoVbiaOnUq9913H+Hh4UydOrXYtg8++KBfCpMgs0VDAkVERESkYitVuHr99de54447CA8P5/XXXz9rO5vNpnBVEaUcgv2rzfsX9be2FhERERERi5QqXO3evbvI+yIAbPnM/FmvM8TEW1uLiIiIiIhFfJ4tUKQQzRIoIiIiIlK6nqsxY8aUeoWTJ08+52IkCKUdhb0/mvcvGmBtLSIiIiIiFipVuPr1119LtTJNxV4BbfkMMKD2pVClntXViIiIiIhYplTh6ttvvy3rOiRYaZZAERERERFA51zJ+Ug/DrtXmPdbaUigiIiIiFRs53QR4V9++YUPP/yQffv2kZ2d7fXcwoUL/VKYBIFtX4DhglptoFpjq6sREREREbGUzz1XH3zwAV27dmXLli188skn5OTk8Pvvv/PNN99QuXLlsqhRApVmCRQRERER8fA5XL300ku8/vrrfPbZZ4SGhvKPf/yDrVu3MnjwYOrXr18WNUogOnUSdi0377caaGUlIiIiIiIBwedwtXPnTvr16wdAaGgo6enp2Gw2/va3v/Hvf//b7wVKgNq2BNw5EHsR1GhmdTUiIiIiIpbzOVxVrVqV1NRUAOrUqcOmTZsASEpKIiMjw7/VSeDSLIEiIiIiIl58ntCiR48eLF26lDZt2jBo0CAeeughvvnmG5YuXcrVV19dFjVKoMlMgR3LzPsKVyIiIiIigA/hatOmTbRu3Zo33niDzMxMAJ555hmcTicrV67klltu4dlnny2zQiWAbP8aXFlQvSnEXWR1NSIiIiIiAaHU4eqSSy7hsssu495772XIkCEA2O12nnzyyTIrTgLU5k/Nn61uBJvN2lpERERERAJEqc+5+u6777j44ot55JFHiI+P5+6772bFihVlWZsEoux02L7UvK8hgSIiIiIiHqUOV927d2fGjBkcPnyYf/7zn+zZs4eePXvSvHlzXn75ZY4cOVKWdUqg2L4Uck9BlQZQ6xKrqxERERERCRg+zxZYqVIlRowYwXfffccff/zBoEGDePPNN6lfvz4DBgwoixolkBScJVBDAkVEREREPHwOVwU1bdqUp59+mmeffZbo6Gi++OILf9UlgSjnFPzxlXlfFw4WEREREfHi81Ts+b7//ntmzJjBxx9/jN1uZ/Dgwdxzzz3+rE0Czc5vIDsNYupCnUutrkZEREREJKD4FK4OHTrErFmzmDVrFjt27KBr165MnTqVwYMHU6lSpbKqUQLF5vwhgQM0JFBERERE5AylHhZ43XXX0aBBA/75z39y0003sWXLFn744QdGjBhx3sHqzTffpGHDhoSHh9O5c2fWrFlz1ra9evXCZrMVuvXr18/TZvjw4YWe79u373nVWOHlZsG2L837miVQRERERKSQUvdcOZ1OFixYwA033IDD4fBbAfPnz2fMmDFMmzaNzp07M2XKFPr06cO2bduIi4sr1H7hwoVkZ2d7Hh8/fpy2bdsyaNAgr3Z9+/Zl5syZnsdhYWF+q7lC2vUdZCVDVC2o28nqakREREREAk6pw9XixYvLpIDJkyczatQoRowYAcC0adP44osvmDFjRpEXKK5WrZrX4w8++IDIyMhC4SosLIxatWqVSc0V0pa8Cwdf1B/s5zUPioiIiIhIuXTOE1r4Q3Z2NmvXruWpp57yLLPb7fTu3ZtVq1aVah3Tp09nyJAhhYYmLl++nLi4OKpWrcpVV13FCy+8QPXq1YtcR1ZWFllZWZ7HKSkpAOTk5JCTk+Pr2/Kr/O1bWocrh5CtX2ADclv0wyhlLQFR+zlS7dZQ7dZQ7dZQ7dZQ7dZQ7dZQ7f7hSw02wzCMMqylWIcOHaJOnTqsXLmSLl26eJY//vjjfPfdd6xevbrY169Zs4bOnTuzevVqOnU6PVQtvzerUaNG7Ny5k6effpqoqChWrVpV5JDGCRMmMHHixELL582bR2Rk5Hm8w/IhNmUTXXe+QlZINEta/xNs6rkSERERkYohIyOD22+/neTkZGJiYopta2nP1fmaPn06bdq08QpWAEOGDPHcb9OmDZdccglNmjRh+fLlXH311YXW89RTTzFmzBjP45SUFOrVq8e1115b4g4sazk5OSxdupRrrrkGp9NpSQ32/y4DIKTNTVx//Q2lfl0g1H6uVLs1VLs1VLs1VLs1VLs1VLs1VLt/5I9qKw1Lw1WNGjVwOBwkJCR4LU9ISCjxfKn09HQ++OADnnvuuRK307hxY2rUqMGOHTuKDFdhYWFFTnjhdDot/8fMZ1ktbhdsMy8O7Wh9E45zqCGQ9qOvVLs1VLs1VLs1VLs1VLs1VLs1VPv511Balo7vCg0NpUOHDixbtsyzzO12s2zZMq9hgkX56KOPyMrK4s477yxxOwcOHOD48ePEx8efd80Vzt6VkHEMIqpCw+5WVyMiIiIiErAsP3lmzJgxvPPOO7z77rts2bKFBx54gPT0dM/sgcOGDfOa8CLf9OnTGThwYKFJKtLS0njsscf46aef2LNnD8uWLePGG2+kadOm9OnT54K8p3JlS94skS36gSM4v/EQEREREbkQLD/n6rbbbiMxMZFx48Zx5MgR2rVrx5IlS6hZsyYA+/btw37G1N/btm3jhx9+4Ouvvy60PofDwcaNG3n33XdJSkqidu3aXHvttTz//PO61pWv3G7YnBeudOFgEREREZFiWR6uAEaPHs3o0aOLfG758uWFlrVo0YKzTXIYERHBV1995c/yKq4DayDtCIRVhsY9ra5GRERERCSgWT4sUAJYfq9Vi74Qol4/EREREZHiKFxJ0QwDNn9q3teQQBERERGREilcSdEOroOUAxAaBU2usroaEREREZGAp3AlRduS12vV7FpwRlhbi4iIiIhIEFC4ksI0JFBERERExGcKV1LYkY1wcg+ERECza6yuRkREREQkKChcSWH5swQ26w2hlaytRUREREQkSChciTfDgM2LzPutBlpZiYiIiIhIUFG4Em9Ht8DxHeAIMyezEBERERGRUlG4Em9b8oYENrkKwmOsrUVEREREJIgoXIk3zRIoIiIiInJOFK7ktMQ/4OhmsDuhRV+rqxERERERCSoKV3Ja/oWDG/eEiKrW1iIiIiIiEmQUruS0/CnYNSRQRERERMRnCldiOrHLvHiwzQEt+lldjYiIiIhI0FG4ElN+r1XDblCpurW1iIiIiIgEIYUrMW3RkEARERERkfOhcCWQtA8OrgVscFF/q6sREREREQlKClcCWz4zfzboClFx1tYiIiIiIhKkFK5EswSKiIiIiPiBwlVFl3II9v9k3teQQBERERGRc6ZwVdFt+dz8WbcTxNS2thYRERERkSCmcFXRaZZAERERERG/ULiqyNKOwt4fzfutBlhbi4iIiIhIkFO4qsi2fg6GG2q3hyr1ra5GRERERCSoKVxVZJolUERERETEbxSuKqqME7D7e/P+RRoSKCIiIiJyvhSuKqqtX4DhgpptoHoTq6sREREREQl6ClcVlWYJFBERERHxK4WriuhUEuz81ryvcCUiIiIi4hcKVxXRH0vAnQOxLSG2udXViIiIiIiUCwpXFZFmCRQRERER8TuFq4omKxV2/M+8r3AlIiIiIuI3ClcVzR9fgSsLqjWBuFZWVyMiIiIiUm4oXFU0BWcJtNmsrUVEREREpBxRuKpIstNh+1LzvoYEioiIiIj4lcJVRbLjf5CTAVXqQ3xbq6sRERERESlXFK4qks0aEigiIiIiUlYUriqKnEzz+lYArQZaWoqIiIiISHmkcFVR7PwGstMgpg7UvtTqakREREREyh2Fq4oif5bAiwaAXf/sIiIiIiL+pqPsiiA3G7b+17yvWQJFRERERMqEwlVFsPs7yEqGqJpQr7PV1YiIiIiIlEsKVxXB5k/Nnxf115BAEREREZEyoiPt8s6VA1s/N+9rSKCIiIiISJlRuCrv9vwAp05CZHWo39XqakREREREyi2Fq/Iuf5bAljeAI8TaWkREREREyjGFq/LM7YItn5n3NSRQRERERKRMKVyVZ/tWQXoihFeBRj2srkZEREREpFxTuCrPNucPCewHDqe1tYiIiIiIlHMKV+WV2336fCsNCRQRERERKXMKV+XVgZ8h9TCExUDjXlZXIyIiIiJS7ilclVf5vVbN+0JImLW1iIiIiIhUAApX5ZFhwOZPzfsaEigiIiIickEoXJVHh9ZB8n5wVoKmV1tdjYiIiIhIhaBwVR7lzxLY/FpwRlhbi4iIiIhIBaFwVd5oSKCIiIiIiCUCIly9+eabNGzYkPDwcDp37syaNWvO2rZXr17YbLZCt379+nnaGIbBuHHjiI+PJyIigt69e7N9+/YL8Vasd+Q3OLkbQiKg6TVWVyMiIiIiUmFYHq7mz5/PmDFjGD9+POvWraNt27b06dOHo0ePFtl+4cKFHD582HPbtGkTDoeDQYMGedq88sorTJ06lWnTprF69WoqVapEnz59yMzMvFBvyzr5swQ2vRrCoqytRURERESkArE8XE2ePJlRo0YxYsQIWrVqxbRp04iMjGTGjBlFtq9WrRq1atXy3JYuXUpkZKQnXBmGwZQpU3j22We58cYbueSSS5g9ezaHDh1i0aJFF/CdWcAw4PdF5v1WA62sRERERESkwgmxcuPZ2dmsXbuWp556yrPMbrfTu3dvVq1aVap1TJ8+nSFDhlCpUiUAdu/ezZEjR+jdu7enTeXKlencuTOrVq1iyJAhhdaRlZVFVlaW53FKSgoAOTk55OTknNN785f87ZeqjsStOI9vx3CEktv4agim2gOMareGareGareGareGareGareGavcPX2qwGYZhlGEtxTp06BB16tRh5cqVdOnSxbP88ccf57vvvmP16tXFvn7NmjV07tyZ1atX06lTJwBWrlzJFVdcwaFDh4iPj/e0HTx4MDabjfnz5xdaz4QJE5g4cWKh5fPmzSMyMvJc394F1/zwIi46spAjMe1Y3WSM1eWIiIiIiAS9jIwMbr/9dpKTk4mJiSm2raU9V+dr+vTptGnTxhOsztVTTz3FmDGnw0hKSgr16tXj2muvLXEHlrWcnByWLl3KNddcg9PpLLZtyDt/B6BGz3u5/pLrL0R5xfKl9kCj2q2h2q2h2q2h2q2h2q2h2q2h2v0jf1RbaVgarmrUqIHD4SAhIcFreUJCArVq1Sr2tenp6XzwwQc899xzXsvzX5eQkODVc5WQkEC7du2KXFdYWBhhYWGFljudTsv/MfOVWMuxHXB0M9hDCGl1AwRI3RBY+9FXqt0aqt0aqt0aqt0aqt0aqt0aqv38aygtSye0CA0NpUOHDixbtsyzzO12s2zZMq9hgkX56KOPyMrK4s477/Ra3qhRI2rVquW1zpSUFFavXl3iOoPalrxrWzXqCRFVra1FRERERKQCsnxY4JgxY7j77rvp2LEjnTp1YsqUKaSnpzNixAgAhg0bRp06dZg0aZLX66ZPn87AgQOpXr2613KbzcbDDz/MCy+8QLNmzWjUqBFjx46ldu3aDBw48EK9rQtPFw4WEREREbGU5eHqtttuIzExkXHjxnHkyBHatWvHkiVLqFmzJgD79u3DbvfuYNu2bRs//PADX3/9dZHrfPzxx0lPT+e+++4jKSmJbt26sWTJEsLDw8v8/VjixG44vAFsDmh5g9XViIiIiIhUSJaHK4DRo0czevToIp9bvnx5oWUtWrSguEkObTYbzz33XKHzscqtLZ+ZPxteAZWqF99WRERERETKhOUXERY/0JBAERERERHLKVwFu+QDcPAXwAYt+1tdjYiIiIhIhaVwFezyhwTW7wLRNa2tRURERESkAlO4CnYaEigiIiIiEhAUroJZymHY95N5/yINCRQRERERsZLCVTDb+jlgQN3LoHIdq6sREREREanQFK6CmYYEioiIiIgEDIWrYJWWCHt/NO9fNMDaWkREREREROEqaG39HAw3xLeDqg2srkZEREREpMJTuApWWxabPzUkUEREREQkIChcBaOME7DrO/O+wpWIiIiISEBQuApG2/4LhgtqtobqTayuRkREREREULgKTps1JFBEREREJNAoXAWbzGTY+Y15X+FKRERERCRgKFwFm21LwJ0DNVpAbAurqxERERERkTwKV8FGswSKiIiIiAQkhatgkpUK25ea9xWuREREREQCisJVMNn+NbiyoFpjqHmx1dWIiIiIiEgBClfBpOAsgTabtbWIiIiIiIgXhatgkZNh9lyBhgSKiIiIiAQghasgYdv5jRmwqtSH+HZWlyMiIiIiImdQuAoS9q2fmXcuGqAhgSIiIiIiAUjhKgjY3dnYtn9lPmg10NJaRERERESkaApXgcztwrb3B1oe/hhbdhpExUOdDlZXJSIiIiIiRQixugA5i82LYckThKQcoln+suwU2Po5tBpgZWUiIiIiIlIE9VwFos2L4cNhkHLIe3l2urk8f0p2EREREREJGApXgcbtgiVPAMbZ2yx50mwnIiIiIiIBQ+Eq0OxdWbjHyosBKQfNdiIiIiIiEjAUrgJNWoJ/24mIiIiIyAWhcBVoomr6t52IiIiIiFwQCleBpkFXiKkNnO1CwTaIqWO2ExERERGRgKFwFWjsDuj7ct6DMwNW3uO+fzfbiYiIiIhIwFC4CkStBsDg2RAT7708pra5XNe5EhEREREJOLqIcKBqNQBa9iN31/esX/EV7br3IaRxD/VYiYiIiIgEKPVcBTK7A6NBNw5W64LRoJuClYiIiIhIAFO4EhERERER8QOFKxERERERET9QuBIREREREfEDhSsRERERERE/ULgSERERERHxA4UrERERERERP1C4EhERERER8QOFKxERERERET9QuBIREREREfEDhSsRERERERE/CLG6gEBkGAYAKSkpFlcCOTk5ZGRkkJKSgtPptLocn6h2a6h2a6h2a6h2a6h2a6h2a6h2awRS7fmZID8jFEfhqgipqakA1KtXz+JKREREREQkEKSmplK5cuVi29iM0kSwCsbtdnPo0CGio6Ox2WyW1pKSkkK9evXYv38/MTExltbiK9VuDdVuDdVuDdVuDdVuDdVuDdVujUCq3TAMUlNTqV27NnZ78WdVqeeqCHa7nbp161pdhpeYmBjLP1jnSrVbQ7VbQ7VbQ7VbQ7VbQ7VbQ7VbI1BqL6nHKp8mtBAREREREfEDhSsRERERERE/ULgKcGFhYYwfP56wsDCrS/GZareGareGareGareGareGareGardGsNauCS1ERERERET8QD1XIiIiIvL/7d17TFP3/8fxVwULtaJyEWg13BUUgah4QV2+UQiXGe/3MAcyZ9yqgk6H0zE0XnGZd4fTMZZ4v0ScI3MMnLJpVBCs4uZ9xrviXYR5Gf38/thP8u3Qtvjt+BR9PZImcAr6bEP66bvnnJaIrIDDFRERERERkRVwuCIiIiIiIrICDldERERERERWwOHKxq1atQo+Pj5wdHREt27dUFRUJDvJrF9++QX9+vWDVquFQqHAzp07ZSdZbMGCBejSpQucnJzg7u6OgQMH4vTp07KzLJKZmYnQ0NCaD9uLiIjA7t27ZWfV2cKFC6FQKJCSkiI7xSKzZs2CQqEwugQFBcnOstjVq1fxzjvvwNXVFSqVCiEhIThy5IjsLLN8fHxq3e8KhQI6nU52mlnV1dVIS0uDr68vVCoV/P39MWfOHDSE95eqqKhASkoKvL29oVKp0KNHDxQXF8vOeiFza5EQAp999hk0Gg1UKhWioqJw9uxZObH/YK59x44diI6OhqurKxQKBfR6vZTOFzHV/uzZM6SmpiIkJARqtRparRbvvvsurl27Ji/4v5i732fNmoWgoCCo1Wo4OzsjKioKhw8flhP7D3V57jV+/HgoFAosXbq03vpMMdeemJhY67E+NjZWTqwFOFzZsC1btmDKlClIT09HaWkpwsLCEBMTg/LyctlpJlVWViIsLAyrVq2SnVJnhYWF0Ol0OHToEPLz8/Hs2TNER0ejsrJSdppZrVu3xsKFC1FSUoIjR46gT58+GDBgAH777TfZaRYrLi7GV199hdDQUNkpdRIcHIzr16/XXPbv3y87ySL37t1Dz5490bhxY+zevRu///47vvjiCzg7O8tOM6u4uNjoPs/PzwcADBs2THKZeRkZGcjMzMTKlStx8uRJZGRkYNGiRVixYoXsNLPGjh2L/Px8rFu3DmVlZYiOjkZUVBSuXr0qO60Wc2vRokWLsHz5cqxevRqHDx+GWq1GTEwMHj9+XM+ltZlrr6ysRK9evZCRkVHPZeaZaq+qqkJpaSnS0tJQWlqKHTt24PTp0+jfv7+E0trM3e9t27bFypUrUVZWhv3798PHxwfR0dG4detWPZfWZulzr5ycHBw6dAharbaeysyzpD02NtboMX/Tpk31WFhHgmxW165dhU6nq/m+urpaaLVasWDBAolVdQNA5OTkyM54ZeXl5QKAKCwslJ3ySpydncXXX38tO8MiFRUVok2bNiI/P1/85z//EcnJybKTLJKeni7CwsJkZ7yS1NRU0atXL9kZVpGcnCz8/f2FwWCQnWJW3759RVJSktG2wYMHi/j4eElFlqmqqhJ2dnYiNzfXaHunTp3EzJkzJVVZ5p9rkcFgEJ6enuLzzz+v2Xb//n3h4OAgNm3aJKHw5UytoxcuXBAAxNGjR+u1yVKWPAcoKioSAMTFixfrJ8pClrQ/ePBAABAFBQX1E2Whl7VfuXJFtGrVSpw4cUJ4e3uLJUuW1HubOS9qT0hIEAMGDJDS8yq458pGPX36FCUlJYiKiqrZ1qhRI0RFReHgwYMSy94sDx48AAC4uLhILqmb6upqbN68GZWVlYiIiJCdYxGdToe+ffsa/c03FGfPnoVWq4Wfnx/i4+Nx6dIl2UkW2bVrF8LDwzFs2DC4u7ujY8eOWLt2reysOnv69CnWr1+PpKQkKBQK2Tlm9ejRA3v27MGZM2cAAMeOHcP+/fsRFxcnucy0v/76C9XV1XB0dDTarlKpGsze2ucuXLiAGzduGD3eNG/eHN26deMaW88ePHgAhUKBFi1ayE6pk6dPn2LNmjVo3rw5wsLCZOeYZTAYMHr0aEybNg3BwcGyc+ps3759cHd3R2BgID744APcuXNHdtJL2csOoBe7ffs2qqur4eHhYbTdw8MDp06dklT1ZjEYDEhJSUHPnj3RoUMH2TkWKSsrQ0REBB4/foymTZsiJycH7du3l51l1ubNm1FaWmqz526Y0q1bN3z77bcIDAzE9evXMXv2bLz11ls4ceIEnJycZOeZ9McffyAzMxNTpkzBjBkzUFxcjEmTJkGpVCIhIUF2nsV27tyJ+/fvIzExUXaKRaZPn46HDx8iKCgIdnZ2qK6uxrx58xAfHy87zSQnJydERERgzpw5aNeuHTw8PLBp0yYcPHgQAQEBsvPq5MaNGwDwwjX2+XX073v8+DFSU1MxatQoNGvWTHaORXJzczFy5EhUVVVBo9EgPz8fbm5usrPMysjIgL29PSZNmiQ7pc5iY2MxePBg+Pr64vz585gxYwbi4uJw8OBB2NnZyc6rhcMV0UvodDqcOHGiQb0iGxgYCL1ejwcPHmD79u1ISEhAYWGhTQ9Yly9fRnJyMvLz82u9It4Q/PfehtDQUHTr1g3e3t7YunUr3nvvPYll5hkMBoSHh2P+/PkAgI4dO+LEiRNYvXp1gxqusrKyEBcXZ1PnEJiydetWbNiwARs3bkRwcDD0ej1SUlKg1Wpt/n5ft24dkpKS0KpVK9jZ2aFTp04YNWoUSkpKZKdRA/Ps2TMMHz4cQghkZmbKzrFY7969odfrcfv2baxduxbDhw/H4cOH4e7uLjvtpUpKSrBs2TKUlpY2iL37/zRy5Miar0NCQhAaGgp/f3/s27cPkZGREstejIcF2ig3NzfY2dnh5s2bRttv3rwJT09PSVVvjgkTJiA3Nxd79+5F69atZedYTKlUIiAgAJ07d8aCBQsQFhaGZcuWyc4yqaSkBOXl5ejUqRPs7e1hb2+PwsJCLF++HPb29qiurpadWCctWrRA27Ztce7cOdkpZmk0mlqDd7t27RrMYY0AcPHiRRQUFGDs2LGyUyw2bdo0TJ8+HSNHjkRISAhGjx6NyZMnY8GCBbLTzPL390dhYSEePXqEy5cvo6ioCM+ePYOfn5/stDp5vo5yjZXj+WB18eJF5OfnN5i9VgCgVqsREBCA7t27IysrC/b29sjKypKdZdKvv/6K8vJyeHl51ayzFy9exEcffQQfHx/ZeXXm5+cHNzc3m11nOVzZKKVSic6dO2PPnj012wwGA/bs2dNgzqFpiIQQmDBhAnJycvDzzz/D19dXdtL/xGAw4MmTJ7IzTIqMjERZWRn0en3NJTw8HPHx8dDr9Ta5y9+UR48e4fz589BoNLJTzOrZs2etjxo4c+YMvL29JRXVXXZ2Ntzd3dG3b1/ZKRarqqpCo0bGy6+dnR0MBoOkorpTq9XQaDS4d+8e8vLyMGDAANlJdeLr6wtPT0+jNfbhw4c4fPgw19h/2fPB6uzZsygoKICrq6vspP9JQ1hnR48ejePHjxuts1qtFtOmTUNeXp7svDq7cuUK7ty5Y7PrLA8LtGFTpkxBQkICwsPD0bVrVyxduhSVlZUYM2aM7DSTHj16ZPRqwoULF6DX6+Hi4gIvLy+JZebpdDps3LgR3333HZycnGqOvW/evDlUKpXkOtM++eQTxMXFwcvLCxUVFdi4cSP27dtn8w+cTk5Otc5pU6vVcHV1bRDnuk2dOhX9+vWDt7c3rl27hvT0dNjZ2WHUqFGy08yaPHkyevTogfnz52P48OEoKirCmjVrsGbNGtlpFjEYDMjOzkZCQgLs7RvOctavXz/MmzcPXl5eCA4OxtGjR7F48WIkJSXJTjMrLy8PQggEBgbi3LlzmDZtGoKCgmxyXTK3FqWkpGDu3Llo06YNfH19kZaWBq1Wi4EDB8qL/n/m2u/evYtLly7VfD7U8xdJPD09pe95M9Wu0WgwdOhQlJaWIjc3F9XV1TXrrIuLC5RKpaxsAKbbXV1dMW/ePPTv3x8ajQa3b9/GqlWrcPXqVZv4CAhzfzP/HGIbN24MT09PBAYG1ndqLabaXVxcMHv2bAwZMgSenp44f/48Pv74YwQEBCAmJkZitQmS362QzFixYoXw8vISSqVSdO3aVRw6dEh2kll79+4VAGpdEhISZKeZ9aJuACI7O1t2mllJSUnC29tbKJVK0bJlSxEZGSl++ukn2VmvpCG9FfuIESOERqMRSqVStGrVSowYMUKcO3dOdpbFvv/+e9GhQwfh4OAggoKCxJo1a2QnWSwvL08AEKdPn5adUicPHz4UycnJwsvLSzg6Ogo/Pz8xc+ZM8eTJE9lpZm3ZskX4+fkJpVIpPD09hU6nE/fv35ed9ULm1iKDwSDS0tKEh4eHcHBwEJGRkTbzt2SuPTs7+4XXp6enS+0WwnT787eOf9Fl7969stNNtv/5559i0KBBQqvVCqVSKTQajejfv78oKiqSnS2EqPtzL1t6K3ZT7VVVVSI6Olq0bNlSNG7cWHh7e4v3339f3LhxQ3b2SymEaAAfCU9ERERERGTjeM4VERERERGRFXC4IiIiIiIisgIOV0RERERERFbA4YqIiIiIiMgKOFwRERERERFZAYcrIiIiIiIiK+BwRUREREREZAUcroiIiIiIiKyAwxUREZGVKRQK7Ny5U3YGERHVMw5XRET0WklMTIRCoah1iY2NlZ1GRESvOXvZAURERNYWGxuL7Oxso20ODg6SaoiI6E3BPVdERPTacXBwgKenp9HF2dkZwN+H7GVmZiIuLg4qlQp+fn7Yvn270e+XlZWhT58+UKlUcHV1xbhx4/Do0SOjn/nmm28QHBwMBwcHaDQaTJgwwej627dvY9CgQWjSpAnatGmDXbt2/bs3moiIpONwRUREb5y0tDQMGTIEx44dQ3x8PEaOHImTJ08CACorKxETEwNnZ2cUFxdj27ZtKCgoMBqeMjMzodPpMG7cOJSVlWHXrl0ICAgw+j9mz56N4cOH4/jx43j77bcRHx+Pu3fv1uvtJCKi+qUQQgjZEURERNaSmJiI9evXw9HR0Wj7jBkzMGPGDCgUCowfPx6ZmZk113Xv3h2dOnXCl19+ibVr1yI1NRWXL1+GWq0GAPzwww/o168frl27Bg8PD7Rq1QpjxozB3LlzX9igUCjw6aefYs6cOQD+HtiaNm2K3bt389wvIqLXGM+5IiKi107v3r2NhicAcHFxqfk6IiLC6LqIiAjo9XoAwMmTJxEWFlYzWAFAz549YTAYcPr0aSgUCly7dg2RkZEmG0JDQ2u+VqvVaNasGcrLy1/1JhERUQPA4YqIiF47arW61mF61qJSqSz6ucaNGxt9r1AoYDAY/o0kIiKyETznioiI3jiHDh2q9X27du0AAO3atcOxY8dQWVlZc/2BAwfQqFEjBAYGwsnJCT4+PtizZ0+9NhMRke3jnisiInrtPHnyBDdu3DDaZm9vDzc3NwDAtm3bEB4ejl69emHDhg0oKipCVlYWACA+Ph7p6elISEjArFmzcOvWLUycOBGjR4+Gh4cHAGDWrFkYP3483N3dERcXh4qKChw4cAATJ06s3xtKREQ2hcMVERG9dn788UdoNBqjbYGBgTh16hSAv9/Jb/Pmzfjwww+h0WiwadMmtG/fHgDQpEkT5OXlITk5GV26dEGTJk0wZMgQLF68uObfSkhIwOPHj7FkyRJMnToVbm5uGDp0aP3dQCIiskl8t0AiInqjKBQK5OTkYODAgbJTiIjoNcNzroiIiIiIiKyAwxUREREREZEV8JwrIiJ6o/BoeCIi+rdwzxUREREREZEVcLgiIiIiIiKyAg5XREREREREVsDhioiIiIiIyAo4XBEREREREVkBhysiIiIiIiIr4HBFRERERERkBRyuiIiIiIiIrOD/APYUVZG5m+ZfAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('checkpoints_student/checkpoints_student_DML/results_student.csv')\n",
        "\n",
        "# Filter data for each student\n",
        "student_0 = df[df['Student ID'] == 0]\n",
        "student_1 = df[df['Student ID'] == 1]\n",
        "\n",
        "# Convert 'Epoch' column to integers\n",
        "df['Epoch'] = df['Epoch'].astype(int)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(student_0['Epoch'], student_0['Valid Accuracy'], label='Student 0', marker='o')\n",
        "plt.plot(student_1['Epoch'], student_1['Valid Accuracy'], label='Student 1', marker='o')\n",
        "plt.title('Validation Accuracy by Epoch for Each Student')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.xticks(df['Epoch'].unique())  # Ensure all epochs are included in x-axis\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV files\n",
        "quant_teacher = pd.read_csv(\"checkpoints_teacher/results_teacher_quantization.csv\")\n",
        "quant_student_dml = pd.read_csv(\"checkpoints_student/checkpoints_student_DML/results_student_quantization_dml.csv\")\n",
        "quant_student_van = pd.read_csv(\"checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\")\n",
        "\n",
        "# Plot both lines sharing the same axes\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(quant_teacher[\"Bits\"], quant_teacher[\"Quantized Test Accuracy\"], marker='o', label=\"Teacher Model\")\n",
        "plt.plot(quant_student_dml[\"Bits\"], quant_student_dml[\"Quantized Test Accuracy\"], marker='o', label=\"Student Model with DML\")\n",
        "plt.plot(quant_student_van[\"Bits\"], quant_student_van[\"Quantized Test Accuracy\"], marker='o', label=\"Student Model with VKD\")\n",
        "\n",
        "# Add horizontal lines for original accuracy\n",
        "plt.axhline(y=0.9225, color='blue', linestyle='--', alpha=0.7)\n",
        "plt.axhline(y=0.932, color='orange', linestyle='--', alpha=0.7)\n",
        "plt.axhline(y=0.9152, color='green', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Quantization Effect on Accuracy (CIFAR-10)\")\n",
        "plt.xlabel(\"Bits\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Method\", loc=\"best\")\n",
        "\n",
        "# Save the plot as PNG\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/teacher_student_quant_acc_comparison.png', dpi=500)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17598\\AppData\\Local\\Temp\\ipykernel_13896\\774814024.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth')\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\17598\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.9152)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('checkpoints_student/checkpoints_student_VAN/student_epoch_19.pth')\n",
        "van_student_net = networks.StudentNetwork(0.0, teacher_net = teacher_net)\n",
        "van_student_net = student_net.to(fast_device)\n",
        "van_student_net.load_state_dict(checkpoint)\n",
        "\n",
        "utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the CSV files\n",
        "quant_teacher = pd.read_csv(\"checkpoints_teacher/results_teacher_quantization.csv\")\n",
        "quant_student_dml = pd.read_csv(\"checkpoints_student/checkpoints_student_DML/results_student_quantization_dml.csv\")\n",
        "quant_student_van = pd.read_csv(\"checkpoints_student/checkpoints_student_VAN/results_student_quantization_van.csv\")\n",
        "\n",
        "num_parameter_teacher = count_parameters(teacher_net)\n",
        "quant_teacher[\"Bits*Num_Parameter\"] = quant_teacher['Bits'] * num_parameter_teacher\n",
        "\n",
        "num_parameter_student = count_parameters(van_student_net)\n",
        "quant_student_dml[\"Bits*Num_Parameter\"] = quant_student_dml['Bits'] * num_parameter_student\n",
        "quant_student_van[\"Bits*Num_Parameter\"] = quant_student_van['Bits'] * num_parameter_student\n",
        "\n",
        "# Define fixed colors for pre-quantization models\n",
        "pre_student_color_dml = \"red\"\n",
        "pre_student_color_van = \"green\"\n",
        "pre_teacher_color = \"blue\"\n",
        "\n",
        "# Define marker styles\n",
        "marker_mapping = {\n",
        "    \"pre_student\": \"o\",  # Circle for pre-quantization Student\n",
        "    \"post_student\": \"s\",  # Square for post-quantization Student\n",
        "    \"pre_teacher\": \"^\",  # Triangle for pre-quantization Teacher\n",
        "    \"post_teacher\": \"D\"  # Diamond for post-quantization Teacher\n",
        "}\n",
        "\n",
        "# Scatter plots for pre and post-quantization\n",
        "# Assumed that pre-quantization accuracy data is available; otherwise replace with actual data\n",
        "pre_quantization_student_van_accuracy = 0.9152\n",
        "pre_quantization_student_dml_accuracy = 0.932  # Example data\n",
        "pre_quantization_teacher_accuracy = 0.9225  # Example data\n",
        "\n",
        "pre_quantization_student_dml_bit_para = 357566784\n",
        "pre_quantization_teacher_bit_para = 752666944\n",
        "\n",
        "# Create colormap for bit precisions\n",
        "cmap_student_dml = plt.cm.Reds\n",
        "cmap_student_van = plt.cm.Greens\n",
        "cmap_teacher = plt.cm.Blues\n",
        "norm_student_dml = plt.Normalize(vmin=min(quant_student_dml['Bits*Num_Parameter']), vmax=max(quant_student_dml['Bits*Num_Parameter']))\n",
        "norm_student_van = plt.Normalize(vmin=min(quant_student_van['Bits*Num_Parameter']), vmax=max(quant_student_van['Bits*Num_Parameter']))\n",
        "norm_teacher = plt.Normalize(vmin=min(quant_teacher['Bits*Num_Parameter']), vmax=max(quant_teacher['Bits*Num_Parameter']))\n",
        "\n",
        "# Define fixed colors for pre-quantization models\n",
        "pre_student__dml_color = \"red\"\n",
        "pre_student__van_color = \"green\"\n",
        "pre_teacher_color = \"blue\"\n",
        "\n",
        "# Define marker styles\n",
        "marker_mapping = {\n",
        "    \"pre_student\": \"o\",  # Circle for pre-quantization Student\n",
        "    \"post_student\": \"s\",  # Square for post-quantization Student\n",
        "    \"pre_teacher\": \"^\",  # Triangle for pre-quantization Teacher\n",
        "    \"post_teacher\": \"D\"  # Diamond for post-quantization Teacher\n",
        "}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Plot Post-Quantization Student\n",
        "ax.plot(quant_student_dml['Bits*Num_Parameter'], quant_student_dml['Quantized Test Accuracy'], \n",
        "        color='red', alpha=0.5, linestyle='-', linewidth=1.5)\n",
        "ax.plot(quant_student_van['Bits*Num_Parameter'], quant_student_van['Quantized Test Accuracy'], \n",
        "        color='green', alpha=0.5, linestyle='-', linewidth=1.5)\n",
        "\n",
        "# Plot Post-Quantization Teacher\n",
        "ax.plot(quant_teacher['Bits*Num_Parameter'], quant_teacher['Quantized Test Accuracy'], \n",
        "        color='blue', alpha=0.5, linestyle='-', linewidth=1.5)\n",
        "\n",
        "\n",
        "# Plot Post-Quantization points\n",
        "for index, row in quant_teacher.iterrows():\n",
        "    color_teacher = cmap_teacher(norm_teacher(row['Bits*Num_Parameter']))\n",
        "    ax.scatter(row['Bits*Num_Parameter'], row['Quantized Test Accuracy'], \n",
        "               color=color_teacher, marker=marker_mapping[\"post_teacher\"], s=50, zorder = 10, label=\"Teacher (Post-Quantization)\" if index == 0 else \"\")\n",
        "ax.scatter(pre_quantization_teacher_bit_para, pre_quantization_teacher_accuracy, \n",
        "           color=pre_teacher_color, marker=marker_mapping[\"pre_teacher\"], label=\"Teacher (Pre-Quantization)\", s=40, zorder = 10)\n",
        "\n",
        "for index, row in quant_student_van.iterrows():\n",
        "    color_student = cmap_student_van(norm_student_van(row['Bits*Num_Parameter']))\n",
        "    ax.scatter(row['Bits*Num_Parameter'], row['Quantized Test Accuracy'], \n",
        "               color=color_student, marker=marker_mapping[\"post_student\"], s=50, zorder = 10, label=\"Student VKD (Post-Quantization)\" if index == 0 else \"\")\n",
        "ax.scatter(pre_quantization_student_dml_bit_para, pre_quantization_student_van_accuracy, \n",
        "           color=pre_student_color_van, marker=marker_mapping[\"pre_student\"], label=\"Student VKD (Pre-Quantization)\", s=40, zorder = 10)\n",
        "   \n",
        "   \n",
        "for index, row in quant_student_dml.iterrows():\n",
        "    color_student = cmap_student_dml(norm_student_dml(row['Bits*Num_Parameter']))\n",
        "    ax.scatter(row['Bits*Num_Parameter'], row['Quantized Test Accuracy'], \n",
        "               color=color_student, marker=marker_mapping[\"post_student\"], s=50, zorder = 10, label=\"Student DML (Post-Quantization)\" if index == 0 else \"\")\n",
        "ax.scatter(pre_quantization_student_dml_bit_para, pre_quantization_student_dml_accuracy, \n",
        "           color=pre_student_color_dml, marker=marker_mapping[\"pre_student\"], label=\"Student DML (Pre-Quantization)\", s=40, zorder = 10)  \n",
        "\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Bits * Number of Parameters\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Accuracy vs. Bits * Number of Parameters (Pre & Post Quantization)\")\n",
        "plt.xscale(\"log\")  # Using log scale for better parameter visualization\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Save the plot\n",
        "if not os.path.exists('images'):\n",
        "    os.makedirs('images')\n",
        "image_path = os.path.join('images', \"quantization_effects.png\")\n",
        "plt.savefig(image_path, dpi=500)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
