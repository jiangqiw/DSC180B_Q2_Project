{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb8caa0-1215-42e4-a182-8856fd1343a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "#sys.path.append('/content/KD')\n",
    "# Import the module\n",
    "import networks\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a72503-414f-4434-b10c-01d8a71711dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True    # set use_gpu to True if system has gpu\n",
    "gpu_id = 0        # id of gpu to be used\n",
    "cpu_device = torch.device('cpu')\n",
    "# fast_device is where computation (training, inference) happens\n",
    "fast_device = torch.device('cpu')\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
    "    fast_device = torch.device('cuda:' + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4326e98-e27e-4db6-a221-001e4bef96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducibilitySeed():\n",
    "    \"\"\"\n",
    "    Ensure reproducibility of results; Seeds to 0\n",
    "    \"\"\"\n",
    "    torch_init_seed = 0\n",
    "    torch.manual_seed(torch_init_seed)\n",
    "    numpy_init_seed = 0\n",
    "    np.random.seed(numpy_init_seed)\n",
    "    if use_gpu:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reproducibilitySeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5805699b-cf1f-4372-977c-bac43f4a33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path_teacher = 'checkpoints_teacher/'\n",
    "checkpoints_path_student = 'checkpoints_student_DKD_new/'\n",
    "if not os.path.exists(checkpoints_path_teacher):\n",
    "    os.makedirs(checkpoints_path_teacher)\n",
    "if not os.path.exists(checkpoints_path_student):\n",
    "    os.makedirs(checkpoints_path_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c4d4e-e745-4f6e-8011-dd2782353051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44188faf-2e07-429c-acad-506ddfaf98b0",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c023dc5-d571-4f2a-af01-67d5ca9329a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "\n",
    "# Set up transformations for CIFAR-10\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
    "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "    ]\n",
    ")\n",
    "\n",
    "import torchvision as tv\n",
    "preprocess_train = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((160, 160), interpolation=PIL.Image.BILINEAR),  # It's the default, just being explicit for the reader.\n",
    "    tv.transforms.RandomCrop((128, 128)),\n",
    "    tv.transforms.RandomHorizontalFlip(),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "])\n",
    "\n",
    "preprocess_eval = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((128, 128), interpolation=PIL.Image.BILINEAR),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
    "                                            download=True, transform=transform_train)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
    "                                            download=True, transform=transform_test)\n",
    "\n",
    "# Split the training dataset into training and validation\n",
    "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
    "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
    "\n",
    "# DataLoader setup\n",
    "batch_size = 128\n",
    "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df999144-90bc-4818-b8e6-df6c05ce5c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe1d9fd9-e44c-4cc1-aba9-bd5c64f1d4c9",
   "metadata": {},
   "source": [
    "## Load Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c091d88a-4261-478a-bef9-2c0988ba8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /tmp/xdg-cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 344MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "test accuracy:  0.9225\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the teacher networks\n",
    "teacher_net_1 = networks.TeacherNetwork50()\n",
    "checkpoint = torch.load('resnet50_cifar10_pretrained.bin')\n",
    "\n",
    "\n",
    "teacher_net_1.model.load_state_dict(checkpoint)\n",
    "teacher_net_2 = networks.TeacherNetworkBiT()\n",
    "\n",
    "# Create the ensemble model\n",
    "#teacher_net = networks.EnsembleModel(teacher_net_1, teacher_net_2)\n",
    "\n",
    "# Move the ensemble model to the appropriate device (e.g., GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "teacher_net = teacher_net_1.to(device)\n",
    "\n",
    "reproducibilitySeed()\n",
    "_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, device)\n",
    "print('test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048079bf-67c5-4396-b422-f16d3d2b5af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d04350-7e39-4f1d-9b4c-790a94918d61",
   "metadata": {},
   "source": [
    "## Train Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287fb4d7-20ec-4e72-b9c6-9768f4883fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7198c1-3428-4c6d-9b15-983b4d2a8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the total number of trainable parameters in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of trainable parameters.\n",
    "    \"\"\"\n",
    "    return sum((p.data != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def count_zero_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of trainable parameters that are exactly zero.\n",
    "    \"\"\"\n",
    "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3031e18-da71-40ca-a255-eb9df97d19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hparamsT=4, alpha=2, beta=4, dropout_hidden=0.0, dropout_input=0.0, lr=0.0005, lr_decay=0.95, momentum=0.9, weight_decay=0.0001_2_4 and pruning factor 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /tmp/xdg-cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 330MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11173962 23520842\n",
      "[Epoch 1, Batch 100/372] Loss: 12.036, Accuracy: 0.570\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "temperatures = [4]\n",
    "alphas = [2]\n",
    "betas = [4, 8, 10]\n",
    "learning_rates = [5e-4]\n",
    "learning_rate_decays = [0.95]\n",
    "weight_decays = [1e-4]\n",
    "momentums = [0.9]\n",
    "dropout_probabilities = [(0.0, 0.0)]\n",
    "hparams_list = []\n",
    "\n",
    "checkpoints_path_student = 'checkpoints_student_DKD_new/'\n",
    "\n",
    "for hparam_tuple in itertools.product(alphas, betas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, momentums, learning_rates):\n",
    "    hparam = {\n",
    "        'alpha': hparam_tuple[0],\n",
    "        'beta': hparam_tuple[1],\n",
    "        'T': hparam_tuple[2],\n",
    "        'dropout_input': hparam_tuple[3][0],\n",
    "        'dropout_hidden': hparam_tuple[3][1],\n",
    "        'weight_decay': hparam_tuple[4],\n",
    "        'lr_decay': hparam_tuple[5],\n",
    "        'momentum': hparam_tuple[6],\n",
    "        'lr': hparam_tuple[7]\n",
    "    }\n",
    "    hparams_list.append(hparam)\n",
    "\n",
    "results_distill = {}\n",
    "pruning_factors = [0]\n",
    "\n",
    "# CSV file setup\n",
    "csv_file = checkpoints_path_student + \"results_student.csv\"\n",
    "if not os.path.exists(csv_file):\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            \"Alpha\", \"Beta\", \"Temperature\", \"Dropout Input\", \"Dropout Hidden\",\n",
    "            \"Weight Decay\", \"LR Decay\", \"Momentum\", \"Learning Rate\",\n",
    "            \"Pruning Factor\", \"Zero Parameters\", \"Test Accuracy\", \"Training Time (s)\"\n",
    "        ])\n",
    "\n",
    "# Training and logging\n",
    "for pruning_factor in pruning_factors:\n",
    "    for hparam in hparams_list:\n",
    "        alpha = hparam['alpha']\n",
    "        beta = hparam['beta']  # Now using beta from hparams_list\n",
    "\n",
    "        print('Training with hparams' + utils.hparamToString(hparam) + f'_{alpha}_{beta}' + f' and pruning factor {pruning_factor}')\n",
    "\n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "\n",
    "        reproducibilitySeed()\n",
    "        student_net = networks.StudentNetwork()\n",
    "        student_net.to(device)\n",
    "        hparam_tuple = utils.hparamDictToTuple(hparam)\n",
    "\n",
    "        # Count parameters\n",
    "        student_params_num = count_parameters(student_net)\n",
    "\n",
    "        print(pruning_factor, student_params_num, count_parameters(teacher_net))\n",
    "        results_distill[(hparam_tuple, pruning_factor)] = utils.trainStudentWithDKD(\n",
    "            teacher_net, student_net, hparam, num_epochs,\n",
    "            train_loader, val_loader,\n",
    "            print_every=print_every,\n",
    "            fast_device=device, quant=False, checkpoint_save_path=checkpoints_path_student, a=alpha, b=beta\n",
    "        )\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Final model save\n",
    "        final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + f'_{alpha}_{beta}' + '.tar'\n",
    "        torch.save({\n",
    "            'results': results_distill[(hparam_tuple, pruning_factor)],\n",
    "            'model_state_dict': student_net.state_dict(),\n",
    "            'epoch': num_epochs\n",
    "        }, final_save_path)\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        _, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "        print('Test accuracy: ', test_accuracy)\n",
    "\n",
    "        # Write results to CSV\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                alpha, beta, hparam['T'], hparam['dropout_input'], hparam['dropout_hidden'],\n",
    "                hparam['weight_decay'], hparam['lr_decay'], hparam['momentum'], hparam['lr'],\n",
    "                pruning_factor, student_params_num, test_accuracy, training_time\n",
    "            ])\n",
    "\n",
    "print(f\"Results saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2ed80-e7ab-4336-8f30-3359a3777dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a90bb5-c2e2-4317-a028-28be51f58ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n",
    "print('Test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acb5f0-1eeb-4fb4-aefe-36eec08cf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = checkpoints_path_student + utils.hparamToString(hparam) + f'_{alpha}_{beta}' + '.tar'\n",
    "torch.save({\n",
    "    'results': results_distill[(hparam_tuple, pruning_factor)],\n",
    "    'model_state_dict': student_net.state_dict(),\n",
    "    'epoch': num_epochs\n",
    "    }, final_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdc1ad-a382-4bd9-a39d-af1cb56d7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hparams_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842945a4-1df5-4fb8-8b54-629107f618ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
