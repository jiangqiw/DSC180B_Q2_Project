{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'checkpoints_student/T=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=0.001_pruning_0.1_final.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "#sys.path.append('/content/KD')\n",
    "# Import the module\n",
    "import models\n",
    "import utilities\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True    # set use_gpu to True if system has gpu\n",
    "gpu_id = 0        # id of gpu to be used\n",
    "cpu_device = torch.device('cpu')\n",
    "# fast_device is where computation (training, inference) happens\n",
    "fast_device = torch.device('cpu')\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'    # set visible devices depending on system configuration\n",
    "    fast_device = torch.device('cuda:' + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducibilitySeed():\n",
    "    \"\"\"\n",
    "    Ensure reproducibility of results; Seeds to 0\n",
    "    \"\"\"\n",
    "    torch_init_seed = 0\n",
    "    torch.manual_seed(torch_init_seed)\n",
    "    numpy_init_seed = 0\n",
    "    np.random.seed(numpy_init_seed)\n",
    "    if use_gpu:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "reproducibilitySeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set up transformations for CIFAR-10\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),  # Augment training data by padding 4 and random cropping\n",
    "        transforms.RandomHorizontalFlip(),     # Randomly flip images horizontally\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalization for CIFAR-10\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_val_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=True,\n",
    "                                            download=True, transform=transform_train)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10_dataset/', train=False,\n",
    "                                            download=True, transform=transform_test)\n",
    "\n",
    "# Split the training dataset into training and validation\n",
    "num_train = int(0.95 * len(train_val_dataset))  # 95% of the dataset for training\n",
    "num_val = len(train_val_dataset) - num_train  # Remaining 5% for validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n",
    "\n",
    "# DataLoader setup\n",
    "batch_size = 128\n",
    "train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_23460\\1568890185.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(teacher_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.9224\n"
     ]
    }
   ],
   "source": [
    "# Path to the saved model\n",
    "import utilities.model_utils\n",
    "\n",
    "\n",
    "teacher_path = \"../models/resnet50_cifar10_pretrained.bin\"\n",
    "\n",
    "# Initialize the network\n",
    "teacher_net = models.teachers.TeacherNetworkR50()\n",
    "teacher_net = teacher_net.to(fast_device)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(teacher_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "teacher_net.model.load_state_dict(checkpoint)\n",
    "\n",
    "# pre-trained teacher accuracy\n",
    "reproducibilitySeed()\n",
    "_, test_accuracy = utilities.utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n",
    "print('test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utilities.data_utils import load_data_CIFAR100\n",
    "\n",
    "train_val_dataset, train_loader, val_loader, test_loader = load_data_CIFAR100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daniel\\dsc180b\\DSC180B_Q2_Project\\src\\models\\student.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6217\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2700.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2606.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3266.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3174.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2813.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3467.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3625.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1729.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2929.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2754.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3113.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3415.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2909.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3068.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3062.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3372.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3510.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2909.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3224.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3465.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3436.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2953\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2250.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2249.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2294.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3154.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2826.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2704.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2893.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1684.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2773.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3085.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2569.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3034.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 3121.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3035.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2850.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3073.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3120.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3311.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2840.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2818.84it/s]"
     ]
    }
   ],
   "source": [
    "from GPFQ.quantize_neural_net import QuantizeNeuralNet\n",
    "\n",
    "# Path to the saved model\n",
    "student_path = \"..\\model_checkpoints\\checkpoints_student_mixup_cifar100\\checkpoints_student_mixup_cifar100T=4, alpha=1.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.0005, lr_decay=0.95, momentum=0.9, opt=adam, weight_decay=0.0001_epoch_200.tar\"\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the network\n",
    "student_model = models.student.StudentNetwork(dataset='cifar100')\n",
    "student_model = student_model.to(fast_device)\n",
    "\n",
    "# Load the checkpoint\n",
    "student_model.load_model(student_path)\n",
    "\n",
    "# Ensure reproducibility anda evaluate pre-trained teacher accuracy\n",
    "reproducibilitySeed()\n",
    "\n",
    "\n",
    "_, test_accuracy = utilities.utils.getLossAccuracyOnDataset(student_model, test_loader, fast_device)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "pre_quantization = test_accuracy\n",
    "post_quantization = []\n",
    "bits = [2, 3, 4, 5, 6, 7, 8]\n",
    "scalars = [.3, .5, .75, 1.0, 1.16, 1.16, 1.16]\n",
    "for bit, scalar in zip(bits, scalars):\n",
    "\n",
    "    quantizer = QuantizeNeuralNet(student_model.model,\n",
    "        'resnet18',  # Default from `-model`\n",
    "        batch_size=128,  # Default from `--batch_size`\n",
    "        data_loader=train_loader,\n",
    "        mlp_bits=bit,  # Default from `--bits`\n",
    "        cnn_bits=bit,  # Default from `--bits`\n",
    "        ignore_layers=[],  # Default from `--ignore_layer`\n",
    "        mlp_alphabet_scalar=scalar,  # Default from `--scalar`\n",
    "        cnn_alphabet_scalar=scalar,  # Default from `--scalar`\n",
    "        mlp_percentile=1,  # Default from `--percentile`\n",
    "        cnn_percentile=1,  # Default from `--percentile`\n",
    "        reg=None,  # Default from `--regularizer`\n",
    "        lamb=0.1,  # Default from `--lamb`\n",
    "        retain_rate=0.25,  # Default from `--retain_rate`\n",
    "        stochastic_quantization=False,  # Default from `--stochastic_quantization`\n",
    "        device=fast_device\n",
    "    )\n",
    "\n",
    "    quantized_model = quantizer.quantize_network(verbose=False)\n",
    "\n",
    "    _, test_accuracy = utilities.utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "    post_quantization.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.521, 0.8923, 0.939, 0.9501, 0.954, 0.9554, 0.9553, 0.9555, 0.9542, 0.9568]\n",
      "[2, 3, 4, 6, 8, 12, 16, 20, 26, 32]\n",
      "0.9577\n"
     ]
    }
   ],
   "source": [
    "print(post_quantization)\n",
    "print(bits)\n",
    "print(pre_quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(bits, post_quantization, marker='o', label='Post Quantization Student')\n",
    "plt.axhline(pre_quantization, color='r', linestyle='--', label='Pre Quantization Student')\n",
    "plt.xlabel('Bits')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Quantization Effects on Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daniel\\anaconda3\\envs\\Classifier\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_23460\\4094146677.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(teacher_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9224\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2076.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 74.11003112792969.\n",
      "The relative quantization error of layer 0 is 0.2481493353843689.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 665.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 30.48805046081543.\n",
      "The relative quantization error of layer 1 is 0.27406173944473267.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 1955.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 12.592508316040039.\n",
      "The relative quantization error of layer 2 is 0.2069534808397293.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1333.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 28.077678680419922.\n",
      "The relative quantization error of layer 3 is 0.3046037554740906.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1523.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 43.353233337402344.\n",
      "The relative quantization error of layer 4 is 0.26247304677963257.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2959.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 27.53522491455078.\n",
      "The relative quantization error of layer 5 is 0.2506777346134186.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2996.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 8.97442626953125.\n",
      "The relative quantization error of layer 6 is 0.208812415599823.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1488.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 17.831024169921875.\n",
      "The relative quantization error of layer 7 is 0.28705453872680664.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2737.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 25.45488929748535.\n",
      "The relative quantization error of layer 8 is 0.25917091965675354.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3235.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 6.676239967346191.\n",
      "The relative quantization error of layer 9 is 0.21219325065612793.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1280.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 11.837770462036133.\n",
      "The relative quantization error of layer 10 is 0.26026350259780884.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2152.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 45.93547058105469.\n",
      "The relative quantization error of layer 11 is 0.28615620732307434.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3347.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 12.845423698425293.\n",
      "The relative quantization error of layer 12 is 0.1967138648033142.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2145.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 12.701203346252441.\n",
      "The relative quantization error of layer 13 is 0.2579905688762665.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 652.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 59.86075210571289.\n",
      "The relative quantization error of layer 14 is 0.255230188369751.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3494.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 14.305325508117676.\n",
      "The relative quantization error of layer 15 is 0.24823148548603058.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3382.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 4.106872081756592.\n",
      "The relative quantization error of layer 16 is 0.18767300248146057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2876.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 7.712491512298584.\n",
      "The relative quantization error of layer 17 is 0.2933909296989441.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3310.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 16.635709762573242.\n",
      "The relative quantization error of layer 18 is 0.277986079454422.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2940.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 4.786623954772949.\n",
      "The relative quantization error of layer 19 is 0.21033526957035065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2204.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 7.520784378051758.\n",
      "The relative quantization error of layer 20 is 0.3664052486419678.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2765.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 17.487836837768555.\n",
      "The relative quantization error of layer 21 is 0.2979433834552765.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2662.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 4.030618190765381.\n",
      "The relative quantization error of layer 22 is 0.2541877329349518.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1815.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 7.2668280601501465.\n",
      "The relative quantization error of layer 23 is 0.4346737265586853.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2326.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 31.078523635864258.\n",
      "The relative quantization error of layer 24 is 0.3126140832901001.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2656.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 8.450529098510742.\n",
      "The relative quantization error of layer 25 is 0.202256441116333.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2767.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 10.131390571594238.\n",
      "The relative quantization error of layer 26 is 0.2647957503795624.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1429.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 32.92232894897461.\n",
      "The relative quantization error of layer 27 is 0.30125755071640015.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2923.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 7.247596263885498.\n",
      "The relative quantization error of layer 28 is 0.20214329659938812.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2925.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 1.285961389541626.\n",
      "The relative quantization error of layer 29 is 0.11528237164020538.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3065.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 3.438997268676758.\n",
      "The relative quantization error of layer 30 is 0.2611129581928253.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3068.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 8.198534965515137.\n",
      "The relative quantization error of layer 31 is 0.2360183745622635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2958.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 1.4611023664474487.\n",
      "The relative quantization error of layer 32 is 0.11678618937730789.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3077.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 3.9854369163513184.\n",
      "The relative quantization error of layer 33 is 0.2998344898223877.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3188.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 10.038933753967285.\n",
      "The relative quantization error of layer 34 is 0.2595805823802948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3033.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 1.8183491230010986.\n",
      "The relative quantization error of layer 35 is 0.14658506214618683.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2746.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 4.941313743591309.\n",
      "The relative quantization error of layer 36 is 0.40901193022727966.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3224.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 11.64245891571045.\n",
      "The relative quantization error of layer 37 is 0.3250269591808319.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3062.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 2.141991376876831.\n",
      "The relative quantization error of layer 38 is 0.16566568613052368.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2617.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 4.741643905639648.\n",
      "The relative quantization error of layer 39 is 0.48706623911857605.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3181.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 11.43678092956543.\n",
      "The relative quantization error of layer 40 is 0.3619230389595032.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3062.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 2.014920473098755.\n",
      "The relative quantization error of layer 41 is 0.16121970117092133.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2876.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 4.434267044067383.\n",
      "The relative quantization error of layer 42 is 0.4679773449897766.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3355.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 15.021811485290527.\n",
      "The relative quantization error of layer 43 is 0.3570869565010071.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3060.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 1.7159205675125122.\n",
      "The relative quantization error of layer 44 is 0.09338973462581635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3129.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 3.67549991607666.\n",
      "The relative quantization error of layer 45 is 0.286063015460968.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2400.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 8.191115379333496.\n",
      "The relative quantization error of layer 46 is 0.38106080889701843.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3079.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 9.499711990356445.\n",
      "The relative quantization error of layer 47 is 0.239802747964859.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3132.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.46628910303115845.\n",
      "The relative quantization error of layer 48 is 0.08301526308059692.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3400.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 1.259273886680603.\n",
      "The relative quantization error of layer 49 is 0.28284287452697754.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3329.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 14.099244117736816.\n",
      "The relative quantization error of layer 50 is 0.23971286416053772.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2926.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.37070655822753906.\n",
      "The relative quantization error of layer 51 is 0.08041789382696152.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3140.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 1.8899939060211182.\n",
      "The relative quantization error of layer 52 is 0.32413315773010254.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2986.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 20.666812896728516.\n",
      "The relative quantization error of layer 53 is 0.14775396883487701.\n",
      "\n",
      "Test accuracy: 0.9056\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2454.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 53.28987121582031.\n",
      "The relative quantization error of layer 0 is 0.18378928303718567.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 794.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 22.055042266845703.\n",
      "The relative quantization error of layer 1 is 0.19803324341773987.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2503.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 9.45603084564209.\n",
      "The relative quantization error of layer 2 is 0.15577758848667145.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 649.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 19.578693389892578.\n",
      "The relative quantization error of layer 3 is 0.21241389214992523.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 852.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 32.783077239990234.\n",
      "The relative quantization error of layer 4 is 0.19932590425014496.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1907.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 19.684370040893555.\n",
      "The relative quantization error of layer 5 is 0.17894750833511353.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3280.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.9969635009765625.\n",
      "The relative quantization error of layer 6 is 0.16453392803668976.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 804.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 12.406007766723633.\n",
      "The relative quantization error of layer 7 is 0.20049768686294556.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1997.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 18.187606811523438.\n",
      "The relative quantization error of layer 8 is 0.18411001563072205.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3356.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 4.844692707061768.\n",
      "The relative quantization error of layer 9 is 0.1526748090982437.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 992.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 8.606046676635742.\n",
      "The relative quantization error of layer 10 is 0.18868523836135864.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1813.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 30.577556610107422.\n",
      "The relative quantization error of layer 11 is 0.19028034806251526.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3295.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 9.339459419250488.\n",
      "The relative quantization error of layer 12 is 0.1432972401380539.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2187.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 8.422955513000488.\n",
      "The relative quantization error of layer 13 is 0.17011809349060059.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 630.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 40.7838020324707.\n",
      "The relative quantization error of layer 14 is 0.17392753064632416.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3258.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 9.717897415161133.\n",
      "The relative quantization error of layer 15 is 0.16889286041259766.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3369.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 2.7561545372009277.\n",
      "The relative quantization error of layer 16 is 0.12561006844043732.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2875.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 4.826333522796631.\n",
      "The relative quantization error of layer 17 is 0.1818346530199051.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3249.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 10.844599723815918.\n",
      "The relative quantization error of layer 18 is 0.1819046288728714.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3040.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 3.1175103187561035.\n",
      "The relative quantization error of layer 19 is 0.1344020664691925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2327.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 4.723751544952393.\n",
      "The relative quantization error of layer 20 is 0.22916661202907562.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3268.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 11.139657020568848.\n",
      "The relative quantization error of layer 21 is 0.19080527126789093.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3089.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 2.5354604721069336.\n",
      "The relative quantization error of layer 22 is 0.15984465181827545.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2081.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 4.471603870391846.\n",
      "The relative quantization error of layer 23 is 0.26582181453704834.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2694.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 19.707849502563477.\n",
      "The relative quantization error of layer 24 is 0.1993560791015625.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3338.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 5.221998691558838.\n",
      "The relative quantization error of layer 25 is 0.12849362194538116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3179.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 6.314764499664307.\n",
      "The relative quantization error of layer 26 is 0.16625532507896423.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1499.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 20.85296058654785.\n",
      "The relative quantization error of layer 27 is 0.19132186472415924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3340.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 4.615111827850342.\n",
      "The relative quantization error of layer 28 is 0.13088878989219666.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3077.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.7739466428756714.\n",
      "The relative quantization error of layer 29 is 0.06964211165904999.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3260.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 2.1215133666992188.\n",
      "The relative quantization error of layer 30 is 0.1611001342535019.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3300.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 5.218148708343506.\n",
      "The relative quantization error of layer 31 is 0.1531953513622284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3256.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.9295324087142944.\n",
      "The relative quantization error of layer 32 is 0.07489795237779617.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2993.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 2.454820156097412.\n",
      "The relative quantization error of layer 33 is 0.18337221443653107.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3064.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 6.199997901916504.\n",
      "The relative quantization error of layer 34 is 0.1584966480731964.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2870.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 1.0501136779785156.\n",
      "The relative quantization error of layer 35 is 0.08481857925653458.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2595.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 2.9514167308807373.\n",
      "The relative quantization error of layer 36 is 0.24549752473831177.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2956.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 7.207664966583252.\n",
      "The relative quantization error of layer 37 is 0.19933173060417175.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2764.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 1.1954716444015503.\n",
      "The relative quantization error of layer 38 is 0.09412722289562225.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2797.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 2.8825438022613525.\n",
      "The relative quantization error of layer 39 is 0.30485841631889343.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3283.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 7.004290580749512.\n",
      "The relative quantization error of layer 40 is 0.21984408795833588.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2855.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 1.1732568740844727.\n",
      "The relative quantization error of layer 41 is 0.09345400333404541.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2794.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 2.6787376403808594.\n",
      "The relative quantization error of layer 42 is 0.2816206216812134.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2887.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 8.98747444152832.\n",
      "The relative quantization error of layer 43 is 0.21642276644706726.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2809.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 1.086068034172058.\n",
      "The relative quantization error of layer 44 is 0.05690750479698181.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2922.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 2.176647186279297.\n",
      "The relative quantization error of layer 45 is 0.16652342677116394.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2172.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 5.153755187988281.\n",
      "The relative quantization error of layer 46 is 0.23878569900989532.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3026.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 6.1149210929870605.\n",
      "The relative quantization error of layer 47 is 0.15015800297260284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3186.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.25343218445777893.\n",
      "The relative quantization error of layer 48 is 0.04540970176458359.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3476.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.9349060654640198.\n",
      "The relative quantization error of layer 49 is 0.20913907885551453.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3201.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 8.32650375366211.\n",
      "The relative quantization error of layer 50 is 0.1425422579050064.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3182.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.22162853181362152.\n",
      "The relative quantization error of layer 51 is 0.04713050648570061.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2510.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 1.1592273712158203.\n",
      "The relative quantization error of layer 52 is 0.19973449409008026.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2741.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 11.364396095275879.\n",
      "The relative quantization error of layer 53 is 0.0798964574933052.\n",
      "\n",
      "Test accuracy: 0.9171\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1635.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 45.213993072509766.\n",
      "The relative quantization error of layer 0 is 0.1557631939649582.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 826.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 21.101398468017578.\n",
      "The relative quantization error of layer 1 is 0.18913137912750244.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2213.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.409337997436523.\n",
      "The relative quantization error of layer 2 is 0.13858851790428162.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1579.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 16.88227653503418.\n",
      "The relative quantization error of layer 3 is 0.18188680708408356.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1346.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 29.30170249938965.\n",
      "The relative quantization error of layer 4 is 0.17848794162273407.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3139.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 17.053089141845703.\n",
      "The relative quantization error of layer 5 is 0.15427275002002716.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3128.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.235187530517578.\n",
      "The relative quantization error of layer 6 is 0.1452006995677948.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1599.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 10.355270385742188.\n",
      "The relative quantization error of layer 7 is 0.1673346608877182.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2678.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 14.337157249450684.\n",
      "The relative quantization error of layer 8 is 0.14486677944660187.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3244.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 4.001145839691162.\n",
      "The relative quantization error of layer 9 is 0.1269097775220871.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1347.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 7.387088298797607.\n",
      "The relative quantization error of layer 10 is 0.16088685393333435.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2077.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 24.12609100341797.\n",
      "The relative quantization error of layer 11 is 0.1504107415676117.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3178.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.996686935424805.\n",
      "The relative quantization error of layer 12 is 0.12264300882816315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2080.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.703009605407715.\n",
      "The relative quantization error of layer 13 is 0.13550104200839996.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 645.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 32.508792877197266.\n",
      "The relative quantization error of layer 14 is 0.13838079571723938.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3026.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.689265727996826.\n",
      "The relative quantization error of layer 15 is 0.1331324279308319.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3337.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 2.1433417797088623.\n",
      "The relative quantization error of layer 16 is 0.09887000173330307.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2842.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.6230990886688232.\n",
      "The relative quantization error of layer 17 is 0.13602715730667114.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3248.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 8.49682331085205.\n",
      "The relative quantization error of layer 18 is 0.14250463247299194.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3062.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.5052647590637207.\n",
      "The relative quantization error of layer 19 is 0.10814479738473892.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2156.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 3.484872341156006.\n",
      "The relative quantization error of layer 20 is 0.1683470457792282.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3592.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 8.493677139282227.\n",
      "The relative quantization error of layer 21 is 0.14436417818069458.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3170.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.8511509895324707.\n",
      "The relative quantization error of layer 22 is 0.11757323145866394.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2098.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 3.0816571712493896.\n",
      "The relative quantization error of layer 23 is 0.18439775705337524.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2826.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 14.63930892944336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relative quantization error of layer 24 is 0.1481909304857254.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3336.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.996453046798706.\n",
      "The relative quantization error of layer 25 is 0.09524468332529068.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2828.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 4.494654655456543.\n",
      "The relative quantization error of layer 26 is 0.11694172024726868.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1473.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 15.695101737976074.\n",
      "The relative quantization error of layer 27 is 0.14439602196216583.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3327.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.6360039710998535.\n",
      "The relative quantization error of layer 28 is 0.10292061418294907.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2882.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5666192173957825.\n",
      "The relative quantization error of layer 29 is 0.05047508701682091.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2777.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.5069223642349243.\n",
      "The relative quantization error of layer 30 is 0.11443335562944412.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3273.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.8118155002593994.\n",
      "The relative quantization error of layer 31 is 0.11084859818220139.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2805.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.6346153616905212.\n",
      "The relative quantization error of layer 32 is 0.05174653232097626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2971.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.780297040939331.\n",
      "The relative quantization error of layer 33 is 0.1331525593996048.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3169.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 4.478143215179443.\n",
      "The relative quantization error of layer 34 is 0.11328692734241486.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2993.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.6840046048164368.\n",
      "The relative quantization error of layer 35 is 0.05455232039093971.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2708.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.9400510787963867.\n",
      "The relative quantization error of layer 36 is 0.16315419971942902.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3307.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 4.814176559448242.\n",
      "The relative quantization error of layer 37 is 0.13497880101203918.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2849.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.7672834396362305.\n",
      "The relative quantization error of layer 38 is 0.059389423578977585.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2680.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.849937915802002.\n",
      "The relative quantization error of layer 39 is 0.19725745916366577.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2974.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 4.515238285064697.\n",
      "The relative quantization error of layer 40 is 0.1425986886024475.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2965.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.7359529137611389.\n",
      "The relative quantization error of layer 41 is 0.05864468216896057.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2680.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.8133134841918945.\n",
      "The relative quantization error of layer 42 is 0.19161169230937958.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3078.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 6.042203426361084.\n",
      "The relative quantization error of layer 43 is 0.14381855726242065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2983.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.7273849248886108.\n",
      "The relative quantization error of layer 44 is 0.03789850324392319.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2941.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.7392666339874268.\n",
      "The relative quantization error of layer 45 is 0.13604237139225006.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2442.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.8093273639678955.\n",
      "The relative quantization error of layer 46 is 0.17647238075733185.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3233.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.612452507019043.\n",
      "The relative quantization error of layer 47 is 0.11206362396478653.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3246.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.1848391890525818.\n",
      "The relative quantization error of layer 48 is 0.03342461213469505.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3408.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8281629085540771.\n",
      "The relative quantization error of layer 49 is 0.18263459205627441.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3165.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 6.4843831062316895.\n",
      "The relative quantization error of layer 50 is 0.10943789780139923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3070.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.17179515957832336.\n",
      "The relative quantization error of layer 51 is 0.036467816680669785.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2952.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 1.0295003652572632.\n",
      "The relative quantization error of layer 52 is 0.17444895207881927.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2886.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 8.400235176086426.\n",
      "The relative quantization error of layer 53 is 0.05999179184436798.\n",
      "\n",
      "Test accuracy: 0.9195\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2247.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 43.31279373168945.\n",
      "The relative quantization error of layer 0 is 0.14741742610931396.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 870.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 19.644968032836914.\n",
      "The relative quantization error of layer 1 is 0.1768406629562378.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2318.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.02581787109375.\n",
      "The relative quantization error of layer 2 is 0.1322920173406601.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 607.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 16.316978454589844.\n",
      "The relative quantization error of layer 3 is 0.1758018583059311.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 779.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 27.532045364379883.\n",
      "The relative quantization error of layer 4 is 0.16731852293014526.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1880.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.518325805664062.\n",
      "The relative quantization error of layer 5 is 0.14848099648952484.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3078.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.183706760406494.\n",
      "The relative quantization error of layer 6 is 0.14485344290733337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 966.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.693184852600098.\n",
      "The relative quantization error of layer 7 is 0.15628699958324432.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2325.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 13.854132652282715.\n",
      "The relative quantization error of layer 8 is 0.14188677072525024.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3432.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.926997423171997.\n",
      "The relative quantization error of layer 9 is 0.12591418623924255.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1015.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 7.038034439086914.\n",
      "The relative quantization error of layer 10 is 0.15326690673828125.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1867.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 21.90496063232422.\n",
      "The relative quantization error of layer 11 is 0.1368451714515686.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3375.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.878822326660156.\n",
      "The relative quantization error of layer 12 is 0.11997240036725998.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2245.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.289581775665283.\n",
      "The relative quantization error of layer 13 is 0.12726719677448273.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 652.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 30.57709312438965.\n",
      "The relative quantization error of layer 14 is 0.1298835724592209.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3498.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.206343650817871.\n",
      "The relative quantization error of layer 15 is 0.12451983243227005.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3419.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8670856952667236.\n",
      "The relative quantization error of layer 16 is 0.08496449142694473.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2481.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.099578380584717.\n",
      "The relative quantization error of layer 17 is 0.1159813404083252.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3475.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.880301475524902.\n",
      "The relative quantization error of layer 18 is 0.13228920102119446.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3346.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.2851996421813965.\n",
      "The relative quantization error of layer 19 is 0.09965427964925766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2285.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 2.982347249984741.\n",
      "The relative quantization error of layer 20 is 0.14543399214744568.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3225.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.812440395355225.\n",
      "The relative quantization error of layer 21 is 0.1328737437725067.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3013.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.5887110233306885.\n",
      "The relative quantization error of layer 22 is 0.09995626658201218.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2369.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.475680351257324.\n",
      "The relative quantization error of layer 23 is 0.14760246872901917.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3004.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.205183029174805.\n",
      "The relative quantization error of layer 24 is 0.1235702857375145.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3488.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.5135908126831055.\n",
      "The relative quantization error of layer 25 is 0.08585236966609955.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3212.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.789044141769409.\n",
      "The relative quantization error of layer 26 is 0.09808842837810516.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1528.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.416163444519043.\n",
      "The relative quantization error of layer 27 is 0.1225460022687912.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3228.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.2691378593444824.\n",
      "The relative quantization error of layer 28 is 0.0931825190782547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3296.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5055269002914429.\n",
      "The relative quantization error of layer 29 is 0.04559134319424629.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3140.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.2986974716186523.\n",
      "The relative quantization error of layer 30 is 0.09833866357803345.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3373.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.343327522277832.\n",
      "The relative quantization error of layer 31 is 0.09763228893280029.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3147.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.5571795105934143.\n",
      "The relative quantization error of layer 32 is 0.04407292231917381.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3236.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4559910297393799.\n",
      "The relative quantization error of layer 33 is 0.1094135269522667.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3237.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.661789894104004.\n",
      "The relative quantization error of layer 34 is 0.09455316513776779.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3140.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5136696100234985.\n",
      "The relative quantization error of layer 35 is 0.04180783033370972.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3270.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.514395833015442.\n",
      "The relative quantization error of layer 36 is 0.12377386540174484.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3458.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.9048495292663574.\n",
      "The relative quantization error of layer 37 is 0.10779532045125961.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3202.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5969430208206177.\n",
      "The relative quantization error of layer 38 is 0.045608989894390106.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3413.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.4173275232315063.\n",
      "The relative quantization error of layer 39 is 0.1496782749891281.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3358.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.562838554382324.\n",
      "The relative quantization error of layer 40 is 0.11266236752271652.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3124.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5333070158958435.\n",
      "The relative quantization error of layer 41 is 0.041117340326309204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3367.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.4437280893325806.\n",
      "The relative quantization error of layer 42 is 0.14795555174350739.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3534.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.811976909637451.\n",
      "The relative quantization error of layer 43 is 0.11600850522518158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3242.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5752173066139221.\n",
      "The relative quantization error of layer 44 is 0.031025681644678116.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3362.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.555780053138733.\n",
      "The relative quantization error of layer 45 is 0.11857389658689499.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2808.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.1685965061187744.\n",
      "The relative quantization error of layer 46 is 0.14379262924194336.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3308.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.359099864959717.\n",
      "The relative quantization error of layer 47 is 0.11059391498565674.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3250.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.15954230725765228.\n",
      "The relative quantization error of layer 48 is 0.028170889243483543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3354.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.797691822052002.\n",
      "The relative quantization error of layer 49 is 0.176924467086792.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3330.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 5.742511749267578.\n",
      "The relative quantization error of layer 50 is 0.10136009007692337.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3225.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.16601380705833435.\n",
      "The relative quantization error of layer 51 is 0.03485720977187157.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3368.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.9570215940475464.\n",
      "The relative quantization error of layer 52 is 0.16434790194034576.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3124.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.499504089355469.\n",
      "The relative quantization error of layer 53 is 0.053991708904504776.\n",
      "\n",
      "Test accuracy: 0.9197\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1928.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 42.71966552734375.\n",
      "The relative quantization error of layer 0 is 0.14805634319782257.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 589.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 19.06090545654297.\n",
      "The relative quantization error of layer 1 is 0.1706867218017578.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2522.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.16565990447998.\n",
      "The relative quantization error of layer 2 is 0.13275404274463654.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 187.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 15.793323516845703.\n",
      "The relative quantization error of layer 3 is 0.17225731909275055.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1619.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 27.507246017456055.\n",
      "The relative quantization error of layer 4 is 0.1666397899389267.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2383.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.216123580932617.\n",
      "The relative quantization error of layer 5 is 0.14688411355018616.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3046.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.043956756591797.\n",
      "The relative quantization error of layer 6 is 0.1408924013376236.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1515.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.745504379272461.\n",
      "The relative quantization error of layer 7 is 0.15632715821266174.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3157.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 14.056285858154297.\n",
      "The relative quantization error of layer 8 is 0.14164075255393982.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3233.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.9059178829193115.\n",
      "The relative quantization error of layer 9 is 0.12402620911598206.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 955.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 6.958802700042725.\n",
      "The relative quantization error of layer 10 is 0.1519087702035904.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2113.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 21.743122100830078.\n",
      "The relative quantization error of layer 11 is 0.13565579056739807.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3322.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.670063018798828.\n",
      "The relative quantization error of layer 12 is 0.11797545105218887.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2241.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 5.970808029174805.\n",
      "The relative quantization error of layer 13 is 0.12011104077100754.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 682.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 29.325138092041016.\n",
      "The relative quantization error of layer 14 is 0.12511953711509705.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3054.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.1244425773620605.\n",
      "The relative quantization error of layer 15 is 0.12355364859104156.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3273.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8714951276779175.\n",
      "The relative quantization error of layer 16 is 0.08553069084882736.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2685.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.056159257888794.\n",
      "The relative quantization error of layer 17 is 0.11555691063404083.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3506.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.439302444458008.\n",
      "The relative quantization error of layer 18 is 0.12442108988761902.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3339.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.2841272354125977.\n",
      "The relative quantization error of layer 19 is 0.09767826646566391.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2437.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 2.9423394203186035.\n",
      "The relative quantization error of layer 20 is 0.14300328493118286.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3447.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.705671787261963.\n",
      "The relative quantization error of layer 21 is 0.1315036565065384.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3110.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.551530361175537.\n",
      "The relative quantization error of layer 22 is 0.09844392538070679.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2187.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.4728713035583496.\n",
      "The relative quantization error of layer 23 is 0.14665865898132324.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2826.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.088680267333984.\n",
      "The relative quantization error of layer 24 is 0.12228492647409439.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3306.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.475782632827759.\n",
      "The relative quantization error of layer 25 is 0.08521626144647598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3151.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.6358354091644287.\n",
      "The relative quantization error of layer 26 is 0.09390349686145782.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1547.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.175459861755371.\n",
      "The relative quantization error of layer 27 is 0.12055257707834244.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3192.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.3447186946868896.\n",
      "The relative quantization error of layer 28 is 0.09533967077732086.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3147.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5317807197570801.\n",
      "The relative quantization error of layer 29 is 0.04719237983226776.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2222.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.3219484090805054.\n",
      "The relative quantization error of layer 30 is 0.09873534739017487.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3115.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.3187637329101562.\n",
      "The relative quantization error of layer 31 is 0.09625893086194992.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3145.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.540550172328949.\n",
      "The relative quantization error of layer 32 is 0.04343191161751747.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3029.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4501559734344482.\n",
      "The relative quantization error of layer 33 is 0.10977821052074432.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3318.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.748537063598633.\n",
      "The relative quantization error of layer 34 is 0.0955670028924942.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3184.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.48794519901275635.\n",
      "The relative quantization error of layer 35 is 0.03889242932200432.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2813.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.4849191904067993.\n",
      "The relative quantization error of layer 36 is 0.12286675721406937.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3110.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.782719612121582.\n",
      "The relative quantization error of layer 37 is 0.105364128947258.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3029.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5155191421508789.\n",
      "The relative quantization error of layer 38 is 0.040309906005859375.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2693.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.3977233171463013.\n",
      "The relative quantization error of layer 39 is 0.15050429105758667.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3232.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.441890239715576.\n",
      "The relative quantization error of layer 40 is 0.1097654476761818.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2862.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5119075775146484.\n",
      "The relative quantization error of layer 41 is 0.04158853739500046.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2458.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.397707462310791.\n",
      "The relative quantization error of layer 42 is 0.14843830466270447.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2936.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.449901580810547.\n",
      "The relative quantization error of layer 43 is 0.1065330058336258.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3045.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5735602378845215.\n",
      "The relative quantization error of layer 44 is 0.030003249645233154.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3035.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.4688942432403564.\n",
      "The relative quantization error of layer 45 is 0.11495118588209152.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2441.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.1606316566467285.\n",
      "The relative quantization error of layer 46 is 0.14535430073738098.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3313.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.0760273933410645.\n",
      "The relative quantization error of layer 47 is 0.10065959393978119.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3268.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.15947158634662628.\n",
      "The relative quantization error of layer 48 is 0.028267813846468925.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3311.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8134024739265442.\n",
      "The relative quantization error of layer 49 is 0.18243034183979034.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3062.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 6.167665958404541.\n",
      "The relative quantization error of layer 50 is 0.1031554564833641.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3010.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.1593717336654663.\n",
      "The relative quantization error of layer 51 is 0.03217720985412598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2925.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.9019047021865845.\n",
      "The relative quantization error of layer 52 is 0.15668097138404846.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2982.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.365747928619385.\n",
      "The relative quantization error of layer 53 is 0.052428003400564194.\n",
      "\n",
      "Test accuracy: 0.9195\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1799.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 41.67372512817383.\n",
      "The relative quantization error of layer 0 is 0.1436728835105896.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 870.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 18.744873046875.\n",
      "The relative quantization error of layer 1 is 0.16806259751319885.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2288.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 7.597098350524902.\n",
      "The relative quantization error of layer 2 is 0.1253650039434433.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 591.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 16.025564193725586.\n",
      "The relative quantization error of layer 3 is 0.173434779047966.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 739.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 26.985639572143555.\n",
      "The relative quantization error of layer 4 is 0.1641560047864914.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1745.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.631725311279297.\n",
      "The relative quantization error of layer 5 is 0.15086932480335236.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3441.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.174348831176758.\n",
      "The relative quantization error of layer 6 is 0.1433957815170288.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1042.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.8018217086792.\n",
      "The relative quantization error of layer 7 is 0.15722496807575226.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2334.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 14.232416152954102.\n",
      "The relative quantization error of layer 8 is 0.1437041461467743.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3045.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 4.030486583709717.\n",
      "The relative quantization error of layer 9 is 0.12773552536964417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 954.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 7.028641223907471.\n",
      "The relative quantization error of layer 10 is 0.15166234970092773.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1554.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 21.973072052001953.\n",
      "The relative quantization error of layer 11 is 0.136973038315773.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3436.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.989681720733643.\n",
      "The relative quantization error of layer 12 is 0.12176358699798584.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2390.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.088356018066406.\n",
      "The relative quantization error of layer 13 is 0.12323291599750519.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 643.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 29.931568145751953.\n",
      "The relative quantization error of layer 14 is 0.12789775431156158.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3179.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.13428258895874.\n",
      "The relative quantization error of layer 15 is 0.12294823676347733.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3211.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.9610410928726196.\n",
      "The relative quantization error of layer 16 is 0.08973975479602814.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2301.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.029764413833618.\n",
      "The relative quantization error of layer 17 is 0.11513183265924454.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3158.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.625995635986328.\n",
      "The relative quantization error of layer 18 is 0.12736397981643677.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3109.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.2288427352905273.\n",
      "The relative quantization error of layer 19 is 0.09679822623729706.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2224.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 2.988516330718994.\n",
      "The relative quantization error of layer 20 is 0.14495046436786652.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3257.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.524496078491211.\n",
      "The relative quantization error of layer 21 is 0.12814012169837952.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3167.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.6288871765136719.\n",
      "The relative quantization error of layer 22 is 0.10131433606147766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2415.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.3887391090393066.\n",
      "The relative quantization error of layer 23 is 0.14237922430038452.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2808.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 11.998409271240234.\n",
      "The relative quantization error of layer 24 is 0.12133531272411346.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3188.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.3162684440612793.\n",
      "The relative quantization error of layer 25 is 0.08086936920881271.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2842.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.7440760135650635.\n",
      "The relative quantization error of layer 26 is 0.09704805165529251.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1480.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.337142944335938.\n",
      "The relative quantization error of layer 27 is 0.12208902835845947.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3267.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.3144373893737793.\n",
      "The relative quantization error of layer 28 is 0.09336352348327637.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3086.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5220819711685181.\n",
      "The relative quantization error of layer 29 is 0.04616327956318855.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3301.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.3122270107269287.\n",
      "The relative quantization error of layer 30 is 0.09992518275976181.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3077.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.4038503170013428.\n",
      "The relative quantization error of layer 31 is 0.10052657872438431.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3075.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.5685753226280212.\n",
      "The relative quantization error of layer 32 is 0.045746468007564545.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2518.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4394302368164062.\n",
      "The relative quantization error of layer 33 is 0.1095307320356369.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2882.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.743413209915161.\n",
      "The relative quantization error of layer 34 is 0.09696128964424133.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3011.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5042783617973328.\n",
      "The relative quantization error of layer 35 is 0.04064397141337395.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2990.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.4935742616653442.\n",
      "The relative quantization error of layer 36 is 0.1236235573887825.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2927.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.7998299598693848.\n",
      "The relative quantization error of layer 37 is 0.1041913777589798.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3153.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5259150266647339.\n",
      "The relative quantization error of layer 38 is 0.040005192160606384.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2680.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.3695158958435059.\n",
      "The relative quantization error of layer 39 is 0.14754459261894226.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2962.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.5311710834503174.\n",
      "The relative quantization error of layer 40 is 0.11140839755535126.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3032.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5126497149467468.\n",
      "The relative quantization error of layer 41 is 0.04047907888889313.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2826.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.3851900100708008.\n",
      "The relative quantization error of layer 42 is 0.14683598279953003.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3097.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.625594139099121.\n",
      "The relative quantization error of layer 43 is 0.11140096187591553.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3047.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5262105464935303.\n",
      "The relative quantization error of layer 44 is 0.02875661849975586.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3100.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.4713538885116577.\n",
      "The relative quantization error of layer 45 is 0.11253442615270615.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2179.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.099952220916748.\n",
      "The relative quantization error of layer 46 is 0.1427503228187561.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3160.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.057321071624756.\n",
      "The relative quantization error of layer 47 is 0.10151433944702148.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3027.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.16714495420455933.\n",
      "The relative quantization error of layer 48 is 0.029589351266622543.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3195.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8137969970703125.\n",
      "The relative quantization error of layer 49 is 0.1808074712753296.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3103.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 6.312140941619873.\n",
      "The relative quantization error of layer 50 is 0.10775072127580643.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2931.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.16401179134845734.\n",
      "The relative quantization error of layer 51 is 0.03367556631565094.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3111.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.9460256695747375.\n",
      "The relative quantization error of layer 52 is 0.16226983070373535.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2848.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.027889728546143.\n",
      "The relative quantization error of layer 53 is 0.0494123138487339.\n",
      "\n",
      "Test accuracy: 0.9194\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1227.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 43.18962097167969.\n",
      "The relative quantization error of layer 0 is 0.15045958757400513.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 757.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 19.365877151489258.\n",
      "The relative quantization error of layer 1 is 0.17422352731227875.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2439.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.139887809753418.\n",
      "The relative quantization error of layer 2 is 0.13514497876167297.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 703.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 15.794877052307129.\n",
      "The relative quantization error of layer 3 is 0.17166349291801453.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1022.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 27.298768997192383.\n",
      "The relative quantization error of layer 4 is 0.1661035120487213.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2284.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 15.960443496704102.\n",
      "The relative quantization error of layer 5 is 0.14660844206809998.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3028.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 5.956521034240723.\n",
      "The relative quantization error of layer 6 is 0.1394544243812561.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1006.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.614999771118164.\n",
      "The relative quantization error of layer 7 is 0.15443533658981323.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2043.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 13.834009170532227.\n",
      "The relative quantization error of layer 8 is 0.14067044854164124.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2821.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.9519643783569336.\n",
      "The relative quantization error of layer 9 is 0.12701545655727386.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1110.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 7.0485405921936035.\n",
      "The relative quantization error of layer 10 is 0.154655322432518.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1841.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 22.17229652404785.\n",
      "The relative quantization error of layer 11 is 0.13776913285255432.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3094.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.89931583404541.\n",
      "The relative quantization error of layer 12 is 0.12156666070222855.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2057.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.128918647766113.\n",
      "The relative quantization error of layer 13 is 0.12350688129663467.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 630.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 29.79649543762207.\n",
      "The relative quantization error of layer 14 is 0.12618373334407806.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3158.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.145776748657227.\n",
      "The relative quantization error of layer 15 is 0.12275820970535278.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3108.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8619427680969238.\n",
      "The relative quantization error of layer 16 is 0.08467908948659897.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2508.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.0045433044433594.\n",
      "The relative quantization error of layer 17 is 0.11331944912672043.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3334.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.641871929168701.\n",
      "The relative quantization error of layer 18 is 0.12861742079257965.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2835.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.2669858932495117.\n",
      "The relative quantization error of layer 19 is 0.09878014773130417.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2133.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 3.0221002101898193.\n",
      "The relative quantization error of layer 20 is 0.146857351064682.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3355.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.723292827606201.\n",
      "The relative quantization error of layer 21 is 0.13206441700458527.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3151.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.5879501104354858.\n",
      "The relative quantization error of layer 22 is 0.10011767596006393.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2278.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.428445816040039.\n",
      "The relative quantization error of layer 23 is 0.14317317306995392.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2869.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.19491958618164.\n",
      "The relative quantization error of layer 24 is 0.1229715570807457.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3355.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.6253793239593506.\n",
      "The relative quantization error of layer 25 is 0.08748006820678711.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2955.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.7457447052001953.\n",
      "The relative quantization error of layer 26 is 0.09776939451694489.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1460.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.509879112243652.\n",
      "The relative quantization error of layer 27 is 0.12372829765081406.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2893.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.309567928314209.\n",
      "The relative quantization error of layer 28 is 0.0930931493639946.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3233.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5190951824188232.\n",
      "The relative quantization error of layer 29 is 0.04629041999578476.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3166.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.3149139881134033.\n",
      "The relative quantization error of layer 30 is 0.0988726019859314.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3140.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.3279247283935547.\n",
      "The relative quantization error of layer 31 is 0.09737815707921982.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2922.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.5702613592147827.\n",
      "The relative quantization error of layer 32 is 0.046107783913612366.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2767.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4294381141662598.\n",
      "The relative quantization error of layer 33 is 0.10886793583631516.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3224.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.773120403289795.\n",
      "The relative quantization error of layer 34 is 0.0968594178557396.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3117.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5177636742591858.\n",
      "The relative quantization error of layer 35 is 0.04167751595377922.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2649.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.5332812070846558.\n",
      "The relative quantization error of layer 36 is 0.1268572360277176.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2826.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.8544297218322754.\n",
      "The relative quantization error of layer 37 is 0.10783419758081436.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2935.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5263891816139221.\n",
      "The relative quantization error of layer 38 is 0.040880076587200165.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2545.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.407792568206787.\n",
      "The relative quantization error of layer 39 is 0.1474720537662506.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3124.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.506849765777588.\n",
      "The relative quantization error of layer 40 is 0.11049986630678177.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3075.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5151877999305725.\n",
      "The relative quantization error of layer 41 is 0.040005482733249664.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2766.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.3870079517364502.\n",
      "The relative quantization error of layer 42 is 0.14752446115016937.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3046.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.740370273590088.\n",
      "The relative quantization error of layer 43 is 0.11162038892507553.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2940.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5481478571891785.\n",
      "The relative quantization error of layer 44 is 0.029988933354616165.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3178.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.5671569108963013.\n",
      "The relative quantization error of layer 45 is 0.11968936026096344.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2348.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.077876329421997.\n",
      "The relative quantization error of layer 46 is 0.14377173781394958.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3064.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.3990631103515625.\n",
      "The relative quantization error of layer 47 is 0.10808463394641876.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3161.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.1487254500389099.\n",
      "The relative quantization error of layer 48 is 0.026328084990382195.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3073.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8448906540870667.\n",
      "The relative quantization error of layer 49 is 0.18598879873752594.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3076.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 5.918661117553711.\n",
      "The relative quantization error of layer 50 is 0.10434243083000183.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3008.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.1540573239326477.\n",
      "The relative quantization error of layer 51 is 0.0328054279088974.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3112.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.950094997882843.\n",
      "The relative quantization error of layer 52 is 0.1634984016418457.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 2973.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 8.065202713012695.\n",
      "The relative quantization error of layer 53 is 0.05703083053231239.\n",
      "\n",
      "Test accuracy: 0.9201\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2076.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 43.247711181640625.\n",
      "The relative quantization error of layer 0 is 0.1468675136566162.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 677.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 18.78769874572754.\n",
      "The relative quantization error of layer 1 is 0.16853375732898712.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2096.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 7.9630608558654785.\n",
      "The relative quantization error of layer 2 is 0.13187456130981445.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1560.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 15.707551956176758.\n",
      "The relative quantization error of layer 3 is 0.16992458701133728.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1505.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 26.843658447265625.\n",
      "The relative quantization error of layer 4 is 0.16348519921302795.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2767.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.304536819458008.\n",
      "The relative quantization error of layer 5 is 0.14891093969345093.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3167.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.10659122467041.\n",
      "The relative quantization error of layer 6 is 0.1436508595943451.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1523.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.595907211303711.\n",
      "The relative quantization error of layer 7 is 0.15463276207447052.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2828.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 13.808220863342285.\n",
      "The relative quantization error of layer 8 is 0.14019455015659332.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2968.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.8404295444488525.\n",
      "The relative quantization error of layer 9 is 0.12117882817983627.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1306.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 6.951523780822754.\n",
      "The relative quantization error of layer 10 is 0.15384288132190704.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2129.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 21.88240623474121.\n",
      "The relative quantization error of layer 11 is 0.13623975217342377.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3043.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.64808988571167.\n",
      "The relative quantization error of layer 12 is 0.11665424704551697.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2245.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.111725330352783.\n",
      "The relative quantization error of layer 13 is 0.12266719341278076.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 669.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 29.223222732543945.\n",
      "The relative quantization error of layer 14 is 0.12461519241333008.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2840.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.246877193450928.\n",
      "The relative quantization error of layer 15 is 0.12557938694953918.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3281.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8975536823272705.\n",
      "The relative quantization error of layer 16 is 0.08592149615287781.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2461.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 2.9733505249023438.\n",
      "The relative quantization error of layer 17 is 0.11232738941907883.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3471.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.721495628356934.\n",
      "The relative quantization error of layer 18 is 0.12853628396987915.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3248.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.233795642852783.\n",
      "The relative quantization error of layer 19 is 0.09742793440818787.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2415.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 2.9600613117218018.\n",
      "The relative quantization error of layer 20 is 0.14548878371715546.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2997.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.65994930267334.\n",
      "The relative quantization error of layer 21 is 0.1302170604467392.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3141.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.603151559829712.\n",
      "The relative quantization error of layer 22 is 0.09929682314395905.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2225.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.425020694732666.\n",
      "The relative quantization error of layer 23 is 0.14453522861003876.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2675.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.383625984191895.\n",
      "The relative quantization error of layer 24 is 0.1245286837220192.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3012.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.459362268447876.\n",
      "The relative quantization error of layer 25 is 0.08265592902898788.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2860.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.7749359607696533.\n",
      "The relative quantization error of layer 26 is 0.09862345457077026.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1356.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.520596504211426.\n",
      "The relative quantization error of layer 27 is 0.1239272728562355.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3074.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.313727617263794.\n",
      "The relative quantization error of layer 28 is 0.09391351789236069.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2844.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5044248104095459.\n",
      "The relative quantization error of layer 29 is 0.04560494422912598.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2316.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.3576992750167847.\n",
      "The relative quantization error of layer 30 is 0.10273043066263199.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3153.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.281740665435791.\n",
      "The relative quantization error of layer 31 is 0.09632521867752075.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2869.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.5438795685768127.\n",
      "The relative quantization error of layer 32 is 0.04494502395391464.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2078.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4468870162963867.\n",
      "The relative quantization error of layer 33 is 0.11052759736776352.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3025.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.6323060989379883.\n",
      "The relative quantization error of layer 34 is 0.09234171360731125.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2898.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5107223987579346.\n",
      "The relative quantization error of layer 35 is 0.04163733124732971.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2828.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.5046030282974243.\n",
      "The relative quantization error of layer 36 is 0.12388250231742859.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2919.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.80574631690979.\n",
      "The relative quantization error of layer 37 is 0.10574899613857269.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3186.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5333369374275208.\n",
      "The relative quantization error of layer 38 is 0.041718073189258575.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2985.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.4015902280807495.\n",
      "The relative quantization error of layer 39 is 0.14656585454940796.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3127.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.4413530826568604.\n",
      "The relative quantization error of layer 40 is 0.10807542502880096.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2801.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5080375671386719.\n",
      "The relative quantization error of layer 41 is 0.040770720690488815.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2581.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.4237929582595825.\n",
      "The relative quantization error of layer 42 is 0.1503496766090393.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2956.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.505273818969727.\n",
      "The relative quantization error of layer 43 is 0.10648389905691147.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2838.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5067752003669739.\n",
      "The relative quantization error of layer 44 is 0.027967385947704315.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3065.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.435201644897461.\n",
      "The relative quantization error of layer 45 is 0.11140133440494537.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2354.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.135446786880493.\n",
      "The relative quantization error of layer 46 is 0.14212048053741455.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3376.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.135619640350342.\n",
      "The relative quantization error of layer 47 is 0.1042339950799942.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3220.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.15712717175483704.\n",
      "The relative quantization error of layer 48 is 0.028378034010529518.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3195.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8422160148620605.\n",
      "The relative quantization error of layer 49 is 0.184931218624115.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3194.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 5.84510612487793.\n",
      "The relative quantization error of layer 50 is 0.09876147657632828.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3016.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.15212400257587433.\n",
      "The relative quantization error of layer 51 is 0.031078247353434563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3018.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.9642361402511597.\n",
      "The relative quantization error of layer 52 is 0.16813857853412628.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3048.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.296503067016602.\n",
      "The relative quantization error of layer 53 is 0.052779801189899445.\n",
      "\n",
      "Test accuracy: 0.9203\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1671.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 41.90080642700195.\n",
      "The relative quantization error of layer 0 is 0.14633877575397491.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 697.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 19.27316665649414.\n",
      "The relative quantization error of layer 1 is 0.17221523821353912.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2409.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.105504989624023.\n",
      "The relative quantization error of layer 2 is 0.13254640996456146.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 603.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 16.08811378479004.\n",
      "The relative quantization error of layer 3 is 0.17462727427482605.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 670.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 27.434608459472656.\n",
      "The relative quantization error of layer 4 is 0.1668126881122589.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1771.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.440038681030273.\n",
      "The relative quantization error of layer 5 is 0.14957721531391144.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2869.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.244802951812744.\n",
      "The relative quantization error of layer 6 is 0.14677028357982635.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 992.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.7425537109375.\n",
      "The relative quantization error of layer 7 is 0.15589232742786407.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2189.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 14.285429000854492.\n",
      "The relative quantization error of layer 8 is 0.1443796157836914.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3113.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.998199224472046.\n",
      "The relative quantization error of layer 9 is 0.12759502232074738.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1084.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 6.982949733734131.\n",
      "The relative quantization error of layer 10 is 0.15176929533481598.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1746.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 22.136157989501953.\n",
      "The relative quantization error of layer 11 is 0.13802582025527954.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3200.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 7.9803314208984375.\n",
      "The relative quantization error of layer 12 is 0.12231782078742981.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1811.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.223050594329834.\n",
      "The relative quantization error of layer 13 is 0.12607428431510925.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 638.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 31.040817260742188.\n",
      "The relative quantization error of layer 14 is 0.1323835253715515.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3455.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.0335893630981445.\n",
      "The relative quantization error of layer 15 is 0.12153264135122299.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3272.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8754509687423706.\n",
      "The relative quantization error of layer 16 is 0.08561142534017563.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2711.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.130716323852539.\n",
      "The relative quantization error of layer 17 is 0.11812445521354675.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3198.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.773373603820801.\n",
      "The relative quantization error of layer 18 is 0.13063819706439972.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3322.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.2919247150421143.\n",
      "The relative quantization error of layer 19 is 0.09987012296915054.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2285.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 2.9862258434295654.\n",
      "The relative quantization error of layer 20 is 0.14516983926296234.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3073.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.730328559875488.\n",
      "The relative quantization error of layer 21 is 0.13279131054878235.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 2872.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.632529616355896.\n",
      "The relative quantization error of layer 22 is 0.10287272185087204.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1969.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.4283547401428223.\n",
      "The relative quantization error of layer 23 is 0.14341521263122559.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2585.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.045707702636719.\n",
      "The relative quantization error of layer 24 is 0.1219930350780487.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3077.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.4717633724212646.\n",
      "The relative quantization error of layer 25 is 0.08448369055986404.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2925.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.9417061805725098.\n",
      "The relative quantization error of layer 26 is 0.10219459980726242.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1442.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.730621337890625.\n",
      "The relative quantization error of layer 27 is 0.12544743716716766.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2908.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.3539350032806396.\n",
      "The relative quantization error of layer 28 is 0.094586580991745.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2898.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5137887597084045.\n",
      "The relative quantization error of layer 29 is 0.04590591415762901.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3022.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.3073770999908447.\n",
      "The relative quantization error of layer 30 is 0.09891920536756516.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3073.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.361163854598999.\n",
      "The relative quantization error of layer 31 is 0.09868926554918289.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2758.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.540688693523407.\n",
      "The relative quantization error of layer 32 is 0.0433589369058609.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2860.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4588857889175415.\n",
      "The relative quantization error of layer 33 is 0.11176875978708267.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3301.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.6355204582214355.\n",
      "The relative quantization error of layer 34 is 0.0937192291021347.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2992.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5225614309310913.\n",
      "The relative quantization error of layer 35 is 0.04237743839621544.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2597.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.5197339057922363.\n",
      "The relative quantization error of layer 36 is 0.12468378245830536.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2779.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.774207830429077.\n",
      "The relative quantization error of layer 37 is 0.10429248958826065.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2871.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5362281203269958.\n",
      "The relative quantization error of layer 38 is 0.04044678807258606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2378.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.39008367061615.\n",
      "The relative quantization error of layer 39 is 0.1528865396976471.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3056.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.448427438735962.\n",
      "The relative quantization error of layer 40 is 0.10733294486999512.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2878.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5149482488632202.\n",
      "The relative quantization error of layer 41 is 0.04143519699573517.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2521.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.4243593215942383.\n",
      "The relative quantization error of layer 42 is 0.15060581266880035.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3056.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.676679611206055.\n",
      "The relative quantization error of layer 43 is 0.11100926250219345.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 2967.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5448122024536133.\n",
      "The relative quantization error of layer 44 is 0.02887808158993721.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3022.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.4620881080627441.\n",
      "The relative quantization error of layer 45 is 0.1140524223446846.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2254.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.1068289279937744.\n",
      "The relative quantization error of layer 46 is 0.14355340600013733.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3283.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 4.162059307098389.\n",
      "The relative quantization error of layer 47 is 0.10487022250890732.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3206.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.15775851905345917.\n",
      "The relative quantization error of layer 48 is 0.02870531566441059.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3516.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.7806137800216675.\n",
      "The relative quantization error of layer 49 is 0.17684932053089142.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3345.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 5.976052284240723.\n",
      "The relative quantization error of layer 50 is 0.10223807394504547.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3057.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.17385195195674896.\n",
      "The relative quantization error of layer 51 is 0.03596367686986923.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3148.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 0.9615333080291748.\n",
      "The relative quantization error of layer 52 is 0.16666901111602783.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3082.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.570729732513428.\n",
      "The relative quantization error of layer 53 is 0.05422617867588997.\n",
      "\n",
      "Test accuracy: 0.9202\n",
      "Layer indices to quantize [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "Total number of layers to quantize 54\n",
      "\n",
      "Quantizing layer with index: 0\n",
      "Quantization progress: 0 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 3, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 27])\n",
      "shape of quantized_layer_input: torch.Size([3968, 27])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2699.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 0 is 41.097042083740234.\n",
      "The relative quantization error of layer 0 is 0.1460525542497635.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 1\n",
      "Quantization progress: 1 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1066.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 1 is 19.234600067138672.\n",
      "The relative quantization error of layer 1 is 0.17320775985717773.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 2\n",
      "Quantization progress: 2 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 2451.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 2 is 8.331958770751953.\n",
      "The relative quantization error of layer 2 is 0.13624431192874908.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 3\n",
      "Quantization progress: 3 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 417.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 3 is 15.707511901855469.\n",
      "The relative quantization error of layer 3 is 0.16959597170352936.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 4\n",
      "Quantization progress: 4 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 758.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 4 is 27.5125789642334.\n",
      "The relative quantization error of layer 4 is 0.1665160208940506.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 5\n",
      "Quantization progress: 5 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1923.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 5 is 16.377235412597656.\n",
      "The relative quantization error of layer 5 is 0.14850084483623505.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 6\n",
      "Quantization progress: 6 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3405.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 6 is 6.306782245635986.\n",
      "The relative quantization error of layer 6 is 0.14726127684116364.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 7\n",
      "Quantization progress: 7 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 885.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 7 is 9.74241828918457.\n",
      "The relative quantization error of layer 7 is 0.1574542224407196.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 8\n",
      "Quantization progress: 8 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2155.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 8 is 14.16716480255127.\n",
      "The relative quantization error of layer 8 is 0.14333657920360565.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 9\n",
      "Quantization progress: 9 out of 53\n",
      "\n",
      "shape of W: torch.Size([64, 64, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 576])\n",
      "shape of quantized_layer_input: torch.Size([3968, 576])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:00<00:00, 3024.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 9 is 3.8885180950164795.\n",
      "The relative quantization error of layer 9 is 0.1237405315041542.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 10\n",
      "Quantization progress: 10 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 64, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 64])\n",
      "shape of quantized_layer_input: torch.Size([32896, 64])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 1007.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 10 is 7.039865970611572.\n",
      "The relative quantization error of layer 10 is 0.15406586229801178.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 11\n",
      "Quantization progress: 11 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1706.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 11 is 22.467267990112305.\n",
      "The relative quantization error of layer 11 is 0.13969793915748596.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 12\n",
      "Quantization progress: 12 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([3968, 1152])\n",
      "shape of quantized_layer_input: torch.Size([3968, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3324.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 12 is 8.017630577087402.\n",
      "The relative quantization error of layer 12 is 0.1234016939997673.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 13\n",
      "Quantization progress: 13 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2392.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 13 is 6.253878116607666.\n",
      "The relative quantization error of layer 13 is 0.1263604313135147.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 14\n",
      "Quantization progress: 14 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([32896, 256])\n",
      "shape of quantized_layer_input: torch.Size([32896, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 638.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 14 is 30.302936553955078.\n",
      "The relative quantization error of layer 14 is 0.12960579991340637.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 15\n",
      "Quantization progress: 15 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3447.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 15 is 7.151116371154785.\n",
      "The relative quantization error of layer 15 is 0.12292083352804184.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 16\n",
      "Quantization progress: 16 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3413.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 16 is 1.8751991987228394.\n",
      "The relative quantization error of layer 16 is 0.08563543856143951.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 17\n",
      "Quantization progress: 17 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2909.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 17 is 3.038975954055786.\n",
      "The relative quantization error of layer 17 is 0.11458325386047363.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 18\n",
      "Quantization progress: 18 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3176.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 18 is 7.798578262329102.\n",
      "The relative quantization error of layer 18 is 0.130777046084404.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 19\n",
      "Quantization progress: 19 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3287.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 19 is 2.3188586235046387.\n",
      "The relative quantization error of layer 19 is 0.1008749008178711.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 20\n",
      "Quantization progress: 20 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2508.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 20 is 3.0306625366210938.\n",
      "The relative quantization error of layer 20 is 0.14816507697105408.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 21\n",
      "Quantization progress: 21 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3667.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 21 is 7.704315662384033.\n",
      "The relative quantization error of layer 21 is 0.13102495670318604.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 22\n",
      "Quantization progress: 22 out of 53\n",
      "\n",
      "shape of W: torch.Size([128, 128, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 1152])\n",
      "shape of quantized_layer_input: torch.Size([1280, 1152])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 3328.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 22 is 1.5683519840240479.\n",
      "The relative quantization error of layer 22 is 0.09902158379554749.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 23\n",
      "Quantization progress: 23 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 128, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 128])\n",
      "shape of quantized_layer_input: torch.Size([8320, 128])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 2560.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 23 is 2.4515933990478516.\n",
      "The relative quantization error of layer 23 is 0.14484351873397827.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 24\n",
      "Quantization progress: 24 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3186.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 24 is 12.145198822021484.\n",
      "The relative quantization error of layer 24 is 0.12292634695768356.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 25\n",
      "Quantization progress: 25 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([1280, 2304])\n",
      "shape of quantized_layer_input: torch.Size([1280, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3188.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 25 is 3.5191092491149902.\n",
      "The relative quantization error of layer 25 is 0.08516134321689606.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 26\n",
      "Quantization progress: 26 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3340.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 26 is 3.8869519233703613.\n",
      "The relative quantization error of layer 26 is 0.10046440362930298.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 27\n",
      "Quantization progress: 27 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([8320, 512])\n",
      "shape of quantized_layer_input: torch.Size([8320, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 1598.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 27 is 13.471966743469238.\n",
      "The relative quantization error of layer 27 is 0.12306877970695496.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 28\n",
      "Quantization progress: 28 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3036.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 28 is 3.420334815979004.\n",
      "The relative quantization error of layer 28 is 0.09658113867044449.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 29\n",
      "Quantization progress: 29 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 3201.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 29 is 0.5063604116439819.\n",
      "The relative quantization error of layer 29 is 0.04587559774518013.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 30\n",
      "Quantization progress: 30 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 3298.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 30 is 1.322760820388794.\n",
      "The relative quantization error of layer 30 is 0.10054252296686172.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 31\n",
      "Quantization progress: 31 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3041.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 31 is 3.4735822677612305.\n",
      "The relative quantization error of layer 31 is 0.10289585590362549.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 32\n",
      "Quantization progress: 32 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2884.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 32 is 0.5213287472724915.\n",
      "The relative quantization error of layer 32 is 0.042990006506443024.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 33\n",
      "Quantization progress: 33 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2923.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 33 is 1.4335626363754272.\n",
      "The relative quantization error of layer 33 is 0.10917482525110245.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 34\n",
      "Quantization progress: 34 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3196.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 34 is 3.793060064315796.\n",
      "The relative quantization error of layer 34 is 0.09671606868505478.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 35\n",
      "Quantization progress: 35 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2833.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 35 is 0.5084526538848877.\n",
      "The relative quantization error of layer 35 is 0.04081902280449867.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 36\n",
      "Quantization progress: 36 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2497.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 36 is 1.4718668460845947.\n",
      "The relative quantization error of layer 36 is 0.12441448122262955.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 37\n",
      "Quantization progress: 37 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2818.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 37 is 3.926032066345215.\n",
      "The relative quantization error of layer 37 is 0.10929085314273834.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 38\n",
      "Quantization progress: 38 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2952.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 38 is 0.5146239399909973.\n",
      "The relative quantization error of layer 38 is 0.039919186383485794.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 39\n",
      "Quantization progress: 39 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2191.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 39 is 1.3908544778823853.\n",
      "The relative quantization error of layer 39 is 0.15066847205162048.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 40\n",
      "Quantization progress: 40 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3078.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 40 is 3.543180465698242.\n",
      "The relative quantization error of layer 40 is 0.11199300736188889.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 41\n",
      "Quantization progress: 41 out of 53\n",
      "\n",
      "shape of W: torch.Size([256, 256, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 2304])\n",
      "shape of quantized_layer_input: torch.Size([384, 2304])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [00:00<00:00, 2960.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 41 is 0.5177263617515564.\n",
      "The relative quantization error of layer 41 is 0.04052074998617172.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 42\n",
      "Quantization progress: 42 out of 53\n",
      "\n",
      "shape of W: torch.Size([1024, 256, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 256])\n",
      "shape of quantized_layer_input: torch.Size([2176, 256])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2765.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 42 is 1.3951876163482666.\n",
      "The relative quantization error of layer 42 is 0.14976751804351807.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 43\n",
      "Quantization progress: 43 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 3121.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 43 is 4.644730091094971.\n",
      "The relative quantization error of layer 43 is 0.11106063425540924.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 44\n",
      "Quantization progress: 44 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([384, 4608])\n",
      "shape of quantized_layer_input: torch.Size([384, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3137.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 44 is 0.5573192834854126.\n",
      "The relative quantization error of layer 44 is 0.029737362638115883.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 45\n",
      "Quantization progress: 45 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2914.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 45 is 1.4780439138412476.\n",
      "The relative quantization error of layer 45 is 0.11838133633136749.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 46\n",
      "Quantization progress: 46 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 1024, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([2176, 1024])\n",
      "shape of quantized_layer_input: torch.Size([2176, 1024])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2311.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 46 is 3.0643575191497803.\n",
      "The relative quantization error of layer 46 is 0.1405685842037201.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 47\n",
      "Quantization progress: 47 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3241.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 47 is 3.9223368167877197.\n",
      "The relative quantization error of layer 47 is 0.09899084270000458.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 48\n",
      "Quantization progress: 48 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3194.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 48 is 0.15359243750572205.\n",
      "The relative quantization error of layer 48 is 0.027768632397055626.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 49\n",
      "Quantization progress: 49 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 3248.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 49 is 0.8069201111793518.\n",
      "The relative quantization error of layer 49 is 0.17954890429973602.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing layer with index: 50\n",
      "Quantization progress: 50 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 2048, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 2048])\n",
      "shape of quantized_layer_input: torch.Size([640, 2048])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3282.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 50 is 6.477231025695801.\n",
      "The relative quantization error of layer 50 is 0.10609111934900284.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 51\n",
      "Quantization progress: 51 out of 53\n",
      "\n",
      "shape of W: torch.Size([512, 512, 3, 3])\n",
      "shape of analog_layer_input: torch.Size([256, 4608])\n",
      "shape of quantized_layer_input: torch.Size([256, 4608])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [00:01<00:00, 3258.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 51 is 0.14735761284828186.\n",
      "The relative quantization error of layer 51 is 0.031986624002456665.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 52\n",
      "Quantization progress: 52 out of 53\n",
      "\n",
      "shape of W: torch.Size([2048, 512, 1, 1])\n",
      "shape of analog_layer_input: torch.Size([640, 512])\n",
      "shape of quantized_layer_input: torch.Size([640, 512])\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 2825.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 52 is 1.006024956703186.\n",
      "The relative quantization error of layer 52 is 0.1734064668416977.\n",
      "\n",
      "\n",
      "Quantizing layer with index: 53\n",
      "Quantization progress: 53 out of 53\n",
      "\n",
      "The number of groups: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 3156.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantization error of layer 53 is 7.668737888336182.\n",
      "The relative quantization error of layer 53 is 0.05448096990585327.\n",
      "\n",
      "Test accuracy: 0.9196\n"
     ]
    }
   ],
   "source": [
    "from GPFQ.quantize_neural_net import QuantizeNeuralNet\n",
    "\n",
    "# Path to the saved model\n",
    "teacher_path = \"../models/resnet50_cifar10_pretrained.bin\"\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the network\n",
    "teacher_model = models.teachers.TeacherNetworkR50()\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(teacher_path)\n",
    "\n",
    "teacher_model.model.load_state_dict(checkpoint)\n",
    "teacher_model.to(fast_device)\n",
    "# Ensure reproducibility and evaluate pre-trained teacher accuracy\n",
    "reproducibilitySeed()\n",
    "\n",
    "\n",
    "_, test_accuracy = utilities.utils.getLossAccuracyOnDataset(teacher_model, test_loader, fast_device)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "pre_quantization_teacher = test_accuracy\n",
    "post_quantization_teacher = []\n",
    "bits = [2, 3, 4, 6, 8, 12, 16, 20 , 26, 32]\n",
    "scalars = [1.16, 1.16, 1.16, 1.16, 1.2, 1.5, 1.75, 1.75, 2, 2]\n",
    "\n",
    "for bit in bits:\n",
    "\n",
    "    quantizer = QuantizeNeuralNet(teacher_model.model,\n",
    "        'resnet50',  # Default from `-model`\n",
    "        batch_size=128,  # Default from `--batch_size`\n",
    "        data_loader=train_loader,\n",
    "        mlp_bits=bit,  # Default from `--bits`\n",
    "        cnn_bits=bit,  # Default from `--bits`\n",
    "        ignore_layers=[],  # Default from `--ignore_layer`\n",
    "        mlp_alphabet_scalar=1.75,  # Default from `--scalar`\n",
    "        cnn_alphabet_scalar=1.75,  # Default from `--scalar`\n",
    "        mlp_percentile=1,  # Default from `--percentile`\n",
    "        cnn_percentile=1,  # Default from `--percentile`\n",
    "        reg=None,  # Default from `--regularizer`\n",
    "        lamb=0.1,  # Default from `--lamb`\n",
    "        retain_rate=0.25,  # Default from `--retain_rate`\n",
    "        stochastic_quantization=False,  # Default from `--stochastic_quantization`\n",
    "        device=fast_device\n",
    "    )\n",
    "\n",
    "    quantized_model = quantizer.quantize_network()\n",
    "\n",
    "    _, test_accuracy = utilities.utils.getLossAccuracyOnDataset(quantized_model, test_loader, fast_device)\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "    post_quantization_teacher.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 6, 8, 12, 16, 20, 26, 32]\n",
      "[0.521, 0.8923, 0.939, 0.9501, 0.954, 0.9554, 0.9553, 0.9555, 0.9542, 0.9568]\n",
      "0.9577\n",
      "[0.9056, 0.9171, 0.9195, 0.9197, 0.9195, 0.9194, 0.9201, 0.9203, 0.9202, 0.9196]\n",
      "0.9224\n"
     ]
    }
   ],
   "source": [
    "print(bits)\n",
    "print(post_quantization_student)\n",
    "print(pre_quantization_student)\n",
    "print(post_quantization_teacher)\n",
    "print(pre_quantization_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../logs/resnet50_teacher_mixup_cifar10_logs.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    \"bits\": bits,\n",
    "    \"scalars\": scalars,\n",
    "    \"post_quantization_student\": post_quantization,\n",
    "    \"pre_quantization_student\": pre_quantization,  # Add actual data here if available\n",
    "    \"post_quantization_teacher\": post_quantization_teacher,\n",
    "    \"pre_quantization_teacher\": pre_quantization_teacher\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "json_path = \"../logs/resnet50_teacher_mixup_cifar10_logs.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"Data saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data extracted from the image\n",
    "bits = [2, 3, 4, 6, 8, 12, 16, 20, 26, 32]\n",
    "post_quantization_r50 = post_quantization\n",
    "pre_quantization_r50 = pre_quantization\n",
    "#post_quantization_r50 = [0.521, 0.8923, 0.939, 0.9501, 0.954, 0.9533, 0.9523, 0.9539, 0.9518, 0.9519]\n",
    "#pre_quantization_r50 = 0.9577  # A single value, likely a reference line\n",
    "#post_quantization_teacher = [0.9067, 0.9092, 0.9108, 0.9114, 0.9118, 0.9097, 0.9124, 0.9132, 0.9108, 0.9118]\n",
    "#pre_quantization_teacher = 0.9224  # A single value, likely a reference line\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(bits, post_quantization_r50, marker='o', label='Post Quantization Student')\n",
    "plt.plot(bits, post_quantization_teacher, marker='s', label='Post Quantization Teacher')\n",
    "plt.axhline(pre_quantization_r50, color='r', linestyle='--', label='Pre Quantization Student')\n",
    "plt.axhline(pre_quantization_teacher, color='g', linestyle='--', label='Pre Quantization Teacher')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Bits')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Quantization Effects on Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('../images/resnet50.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the total number of trainable parameters in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose parameters need to be counted.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of trainable parameters.\n",
    "    \"\"\"\n",
    "    return sum((p.data != 0).sum().item() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def count_zero_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the number of trainable parameters that are exactly zero in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose zero parameters need to be counted.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of trainable parameters that are exactly zero.\n",
    "    \"\"\"\n",
    "    return sum((p.data == 0).sum().item() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantize_neural_net import QuantizeNeuralNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = quantizer.quantize_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectors\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\"resnet50_cifar100\", pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_val_loader, train_loader, val_loader, test_loader = utilities.data_utils.load_data_CIFAR100()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(fast_device)\n",
    "_, test_test_acc = utilities.utils.getLossAccuracyOnDataset(model, test_loader, fast_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7643\n"
     ]
    }
   ],
   "source": [
    "print(test_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
